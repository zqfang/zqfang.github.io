<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Expectation Maximization - My Computational Genomic Playground</title><meta name="Description" content="My Computational Genomic Playground"><meta property="og:title" content="Expectation Maximization" />
<meta property="og:description" content="Maximum Likelihood Estimation Gaussian Mixture Model Expectation Maximization 1. Probability and likelihood likehood &amp; maximum likehood 在非正式场合似然（likel" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zqfang.github.io/2020-01-26-ml-em/" />
<meta property="og:image" content="https://zqfang.github.io/logo.png"/>
<meta property="article:published_time" content="2020-01-26T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-01-26T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://zqfang.github.io/logo.png"/>

<meta name="twitter:title" content="Expectation Maximization"/>
<meta name="twitter:description" content="Maximum Likelihood Estimation Gaussian Mixture Model Expectation Maximization 1. Probability and likelihood likehood &amp; maximum likehood 在非正式场合似然（likel"/>
<meta name="application-name" content="#root max &gt;">
<meta name="apple-mobile-web-app-title" content="#root max &gt;"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://zqfang.github.io/2020-01-26-ml-em/" /><link rel="prev" href="https://zqfang.github.io/2020-01-26-ml-montecarlo/" /><link rel="next" href="https://zqfang.github.io/2020-01-29-ml-lossfunc/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css" integrity="sha256-HiaUvtFS&#43;iki2&#43;kJpEGDjtaT2IsTMPl0hb&#43;o7XjaQt8="><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Expectation Maximization",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/zqfang.github.io\/2020-01-26-ml-em\/"
        },"image": ["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "Expectation Maximization","wordcount":  2901 ,
        "url": "https:\/\/zqfang.github.io\/2020-01-26-ml-em\/","datePublished": "2020-01-26T00:00:00+00:00","dateModified": "2020-01-26T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/zqfang.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "zqfang"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="My Computational Genomic Playground"><span class="header-title-pre"><i class="fas fa-hashtag"></i></span>MAX <span class="header-title-post"><i class="fas fa-terminal"></i></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/publication/"> Publication </a><a class="menu-item" href="/portfolio/"> Portfolio </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="https://github.com/zqfang" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><a class="menu-item" href="/about/" title="About"> About </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="My Computational Genomic Playground"><span class="header-title-pre"><i class="fas fa-hashtag"></i></span>MAX <span class="header-title-post"><i class="fas fa-terminal"></i></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/publication/" title="">Publication</a><a class="menu-item" href="/portfolio/" title="">Portfolio</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="https://github.com/zqfang" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a class="menu-item" href="/about/" title="About">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Expectation Maximization</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class="post-category">included in <a href="/categories/machine-learning/"><i class="far fa-folder fa-fw"></i>Machine Learning</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-01-26">2020-01-26</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2901 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><p>Maximum Likelihood Estimation<br>
Gaussian Mixture Model<br>
Expectation Maximization</p>

<h2 id="1-probability-and-likelihood">1. Probability and likelihood</h2>

<p><a href="http://fangs.in/post/thinkstats/likelihood/">likehood &amp; maximum likehood</a></p>

<p>在非正式场合似然（likelihood）和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。</p>

<p><strong>概率</strong>: 在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性。</p>

<blockquote>
<p>比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；</p>
</blockquote>

<p><strong>似然</strong>: 刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数）。</p>

<blockquote>
<p>假设随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上，那么两面朝上的概率均为50%。<span style="color: red">运用出现的结果来判断这个事情本身的性质（参数）</span>，也就是似然。</p>
</blockquote>

<p><strong>当结果和参数相互对应，似然和概率在数值上相等</strong>。 用 θ 表示环境对应的参数，x 表示结果，那么概率可以表示为：</p>

<p><span  class="math">\[P(x | \theta )\]</span></p>

<p>$p(x \vert θ)$ 是条件概率的表示方法。θ 是前置条件，理解为在 θ 的前提下，事件 x 发生的概率，相对应的似然可以表示为:</p>

<p><span  class="math">\[\mathcal{L}(\theta | x)\]</span></p>

<p>可以理解为已知结果为 x ，参数为 θ (似然函数里 θ 是变量，这里说的参数和变量是相对与概率而言的)对应的概率，即：</p>

<p><span  class="math">\[\mathcal{L}(\theta | x)=P(x | \theta)\]</span></p>

<p>两者在数值上相等，但是意义并不相同, $\mathcal{L}$ 是关于 θ 的函数，而 P 则是关于 x 的函数。</p>

<h2 id="2-maximum-likelihood-estimation">2. Maximum Likelihood Estimation</h2>

<p>单高斯模型 $x \sim \mathcal{N}(\mu, \Sigma)$, $x_{i} \in \mathcal{D}$, 那么对参数 $\mu$和 $\Sigma$ 进行估计，只需要最大化log-likelihood函数：</p>

<p><span  class="math">\[
\begin{aligned}
\log p(X) &=\sum_{i=1}^{N} \log \mathcal{N}\left(x_{i} | \mu, \Sigma\right) \\
&=\sum_{i=1}^{N} \log \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}} \\
&=\sum_{i=1}^{N} \log \frac{1}{\sqrt{2 \pi} \sigma}+\sum_{i=1}^{N}-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}} \\
&=-\frac{N}{2} \log 2 \pi-\frac{N}{2} \log \sigma^{2}-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}
\end{aligned}
\]</span></p>

<p>求偏导数，得到参数估计：</p>

<p><span  class="math">\[
\begin{aligned}
\frac{\partial \log p(X)}{\partial \mu} &=\frac{1}{\sigma^{2}} \sum_{i=1}^{N}\left(x_{i}-\mu\right)=0 \\
& \Rightarrow \mu=\frac{1}{N} \sum_{i=1}^{N} x_{i} \\
\frac{\partial \log p(X)}{\partial \sigma^{2}} &=-\frac{N}{2 \sigma^{2}}+\frac{1}{2 \sigma^{4}} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}=0 \\
& \Rightarrow \sigma^{2}=\frac{1}{N} \sum_{i=1}^{N}\left(x_{i}-\mu\right)^{2}
\end{aligned}
\]</span></p>

<h2 id="3-gaussian-mixture-model">3. Gaussian Mixture Model</h2>

<p>如果有K个高斯线性叠加:</p>

<p><span  class="math">\[
\begin{aligned}
p(x)=& \sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x | \mu_{k}, \Sigma_{k}\right) \\
& \text { s.t. } \sum_{k=1}^{K} \pi_{k}=1 \\
& 0 \leq \pi_{k} \leq 1
\end{aligned}
\]</span></p>

<p>那么对数似然函数为</p>

<p><span  class="math">\[ 
\log p(X)=\sum_{i=1}^{N} \log \left\{\sum_{k=1}^{K} \pi_{k} \mathcal{N}\left(x_{i} | \mu_{k}, \Sigma_{k}\right)\right\} 
\]</span></p>

<p>因为对数里有求和，因此无法无法直接通过最大似然估计方法进行参数估计。</p>

<p>其中，如果$\pi_{k}$是每个高斯出现的概率$p(k)$，则高斯混合模型分解为以$p(k)$获得一个高斯分布，然后在分布中获得$x$，因此$x$边缘概率分布为：</p>

<p><span  class="math">\[
p(x)=\sum_{k=1}^{K} p(k) p(x | k)
\]</span></p>

<p>后验概率$p(k\vert x)$表示$x$属于每个高斯的概率（离散值）:</p>

<p><span  class="math">\[
\begin{aligned}
p(k | x) &=\frac{p(x | k) p(k)}{\sum_{l} p(x | l) p(l)} \\
&=\frac{\pi_{k} \mathcal{N}\left(x | \mu_{k}, \Sigma_{k}\right)}{\sum_{l} \pi_{l} \mathcal{N}\left(x | \mu_{l}, \Sigma_{l}\right)}
\end{aligned}
\]</span></p>

<h2 id="4-expectation-maximization">4. Expectation Maximization</h2>

<p>思想： 通过引入隐变量，运用迭代方法，求解混合高斯模型</p>

<p><span  class="math">\[
\theta^{(t+1)}=\underset{\theta}{\arg \max } \mathcal{L}(\theta ; X)
\]</span></p>

<p>引入隐变量Zi(状态i）， z服从多项分布，选择zi的概率为p(zi),则高斯混合模型为：</p>

<p><span  class="math">\[
\begin{aligned}
z_{i} & \sim \operatorname{Multinoimal}\left(\pi_{1}, \cdots, \pi_{k}\right) \\
x_{i} | z_{i} & \sim \mathcal{N}\left(\mu_{z_{i}}, \Sigma_{z_{i}}\right)
\end{aligned}
\]</span></p>

<p>步骤：</p>

<ul>
<li>E-Step: 在现有$\theta^{(t)}$下最大化似然下界, 计算隐变量z的期望$Q\left(z_{i}\right)=p\left(z_{i} \vert x_{i}, \theta\right)$ 作为其下界</li>
<li>M-Step: 在上面$Q(z_{i})$下计算参数列表$\theta$来最大化似然</li>
</ul>

<h3 id="0-理解em的前提">(0) 理解EM的前提</h3>

<p><strong>凹凸函数</strong>:<br>
$\forall_{x \in \mathbb{R}}, f^{\prime \prime}(x) \geq 0$,则$f$为凸函数。<br>
当x为向量，如果其hessian矩阵H是半正定的($H \geq 0$),则$f$为凸函数<br>
如果$f^{\prime \prime}(x)&gt;0$或者$H&gt;0$, $f$是严格凸函数。<br>
如果$f^{\prime \prime}(x)<0$或者$H>0$, $f$是凹函数。</p>

<p><strong>Jensen 不等式</strong>:</p>

<ol>
<li>如果$f$为凸函数, 则$E[f(X)] \geq f(E[X])$。当且仅当x是常数时，$E[f(x)]=f(E[x])$。</li>
<li>如果$f$是凹函数, 则$E[f(X)] \leq f(E[X])$。</li>
</ol>

<p>引入隐变量后，变换<strong>对数似然函数</strong>:</p>

<p><span  class="math">\[
\begin{aligned}
\mathcal{L}(\theta ; X) &=\sum_{i=1}^{N} \log p\left(x_{i} | \theta\right) \\
&=\sum_{i=1}^{N} \log \sum_{z_{i}} p\left(x_{i}, z_{i} | \theta\right) \\
&=\sum_{i=1}^{N} \log \sum_{z_{i}} Q\left(z_{i}\right) \frac{p\left(x_{i}, z_{i} | \theta\right)}{Q\left(z_{i}\right)} \\
& \geq \sum_{i=1}^{N} \sum_{z_{i}} Q\left(z_{i}\right) \log \frac{p\left(x_{i}, z_{i} | \theta\right)}{Q\left(z_{i}\right)}
\end{aligned}
\]</span></p>

<p><strong>推导</strong>:</p>

<ol>
<li>把式中的log函数体看成是一个整体，由于log(x)的二阶导数为$-\frac{1}{x^2}$, 小于0，为凹函数。所以使用Jensen不等式时，应用第二条准则：$f(E[X]) \geq E[f(x)]$。</li>
</ol>

<p><span  class="math">\[
f\left(E_{z_{i} \sim Q}\left[\frac{p\left(x_{i}, z_{i} | \theta\right)}{Q\left(z_{i}\right)}\right]\right) \geq E_{z_{i} \sim Q}\left[f\left(\frac{p\left(x_{i}, z_{i} | \theta\right)}{Q\left(z_{i}\right)}\right)\right]
\]</span></p>

<ol start="2">
<li>这里，$Q\left(z_{i}\right)$是$z_{i}$的函数， 且$\sum_{z_{i}} Q\left(z_{i}\right)=1$。<br></li>

<li><p>由数学期望$E_{x \sim p}[g(X)]=\sum_{x} g(x) p(x)$，上式可以理解为: $p(x)$对应$Q\left(z_{i}\right)$, g(x)对应$\log \frac{p\left(x_{i}, z_{i} \vert \theta\right)}{Q\left(z_{i}\right)}$表示$z_{i}$的函数。</p></li>

<li><p>似然函数: $\mathcal{L}(\theta) \geq \mathcal{J}(z,Q)$（$z$为隐含变量），那么我们可以通过不断的最大化$\mathcal{J}$的下界，来使得$\mathcal{L}(\theta)$不断提高，最终达到它的最大值。</p></li>
</ol>

<p>最大化$\mathcal{L}(\theta)$函数的下界，即让$g(x)$为常数c:</p>

<p><span  class="math">\[
\frac{p\left(x_{i}, z_{i} \| \theta\right)}{Q\left(z_{i}\right)}=c
\]</span></p>

<p>Jensen不等式中说到，当自变量X=E(X)时，即为常数的时候，等式成立!</p>

<p>变换公式, 对所有$z$求和得:</p>

<p><span  class="math">\[
\begin{aligned}
p\left(x_{i}, z_{i} | \theta\right) &=c \cdot Q\left(z_{i}\right) \\
\sum_{z_{i}} p\left(x_{i}, z_{i} | \theta\right) &=c \cdot \sum_{z_{i}} Q\left(z_{i}\right) \\
c &=\sum_{z_{i}} p\left(x_{i}, z_{i} | \theta\right) 
\end{aligned}
\]</span></p>

<p>其中，$\sum_{z_{i}} Q\left(z_{i}\right) = 1$, 也得：</p>

<p><span  class="math">\[
\begin{aligned}
Q\left(z_{i}\right) &=\frac{p\left(x_{i}, z_{i} | \theta\right)}{\sum_{z_{i}} p\left(x_{i}, z_{i} | \theta\right)} \\
&=p\left(z_{i} | x_{i}, \theta\right)
\end{aligned}
\]</span></p>

<p>至此，我们推出了在固定参数θ后，使下界拉升的$Q(z)$的计算公式就是后验概率（条件概率），一并解决了$Q(z)$如何选择的问题。此步就是EM算法的<code>E-step</code>。</p>

<p>执行<code>E-Step</code>后与下界重合，此时似然变为：</p>

<p><span  class="math">\[
\mathcal{L}\left(\theta^{(t)} ; X\right)=\sum_{i=1}^{N} \sum_{z_{i}} Q^{(t)}\left(z_{i}\right) \log \frac{p\left(x_{i}, z_{i} | \theta^{(t)}\right)}{Q^{(t)}\left(z_{i}\right)}
\]</span></p>

<p>这时，对公式求导</p>

<p><span  class="math">\[
\theta^{(t+1)}=\underset{\theta}{\arg \max } \mathcal{L}(\theta ; X)
\]</span></p>

<p>得到t+1步的似然函数$\mathcal{L}\left(\theta^{(t+1)} ; X\right)$。<br>
通过不断的迭代，可以得到使似然函数$\mathcal{L}(\theta)$最大化的参数θ，直至函数收敛。
只需要证明$\mathcal{L}\left(\theta^{(t+1)} ; X\right) \geq \mathcal{L}\left(\theta^{(t)} ; X\right)$, 则可证明EM的收敛性:</p>

<p><span  class="math">\[
\begin{aligned}
\mathcal{L}\left(\theta^{(t+1)} ; X\right) &=\sum_{i=1}^{N} \log \sum_{z_{i}} Q^{(t)}\left(z_{i}\right) \frac{p\left(x_{i}, z_{i} | \theta^{(t+1)}\right)}{Q^{(t)}\left(z_{i}\right)} \\
& \geq \sum_{i=1}^{N} \sum_{z_{i}} Q^{(t)}\left(z_{i}\right) \log \frac{p\left(x_{i}, z_{i} | \theta^{(t+1)}\right)}{Q^{(t)}\left(z_{i}\right)} \\
& \geq \sum_{i=1}^{N} \sum_{z_{i}} Q^{(t)}\left(z_{i}\right) \log \frac{p\left(x_{i}, z_{i} | \theta^{(t)}\right)}{Q^{(t)}\left(z_{i}\right)} \\
&=\mathcal{L}\left(\theta^{(t)} ; X\right)
\end{aligned}
\]</span></p>

<h2 id="5-求解gmm">5. 求解GMM</h2>

<h3 id="1-gmm-estep">(1) GMM E-Step:</h3>

<p>已知$\theta^{(t)}$, 求$Q^{(t+1)}\left(z_{i}\right)$:</p>

<p><span  class="math">\[
\begin{aligned}
Q^{(t+1)}\left(z_{i}\right) &=\frac{p\left(x_{i}, z_{i} | \theta^{(t)}\right)}{p\left(x_{i} | \theta^{(t)}\right)} \\
&=\frac{p\left(x_{i}, z_{i} | \theta^{(t)}\right)}{\sum_{l \in z_{i}} p\left(x_{i}, l | \theta^{(t)}\right)} \\
&=\frac{p\left(x_{i} | z_{i}, \theta^{(t)}\right) p\left(z_{i} | \theta^{(t)}\right)}{\sum_{l \in z_{i}} p\left(x_{i} | l, \theta^{(t)}\right) p\left(l | \theta^{(t)}\right)} \\
&=\frac{\mathcal{N}\left(\mu_{z_{i}}, \Sigma_{z_{i}}\right) \pi_{z_{i}}}{\sum_{l \in z_{i}} \mathcal{N}\left(\mu_{l}, \Sigma_{l}\right) \pi_{l}}
\end{aligned}
\]</span></p>

<h3 id="2-gmm-mstep">(2) GMM M-Step:</h3>

<p>已知$Q^{(t+1)}\left(z_{i}\right)$, 求 $\theta^{(t+1)}$:</p>

<p><span  class="math">\[
\begin{aligned}
\mathcal{L}(\theta ; X) &=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \frac{p\left(x_{i}, l | \theta\right)}{Q_{i}(l)} \\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log p\left(x_{i}, l | \theta\right)-\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log Q_{i}(l) \\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log p\left(x_{i}, l | \theta\right)-\text {Constant } \\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \pi_{l} \mathcal{N}\left(\mu_{l}, \Sigma_{l}\right)-\text {Constant } \\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \pi_{l}+\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \mathcal{N}\left(\mu_{l}, \Sigma_{l}\right)-\text {Constant}
\end{aligned}
\]</span></p>

<h3 id="3-求-pi">(3) 求 $\pi$:</h3>

<p><span  class="math">\[
\begin{aligned}
\forall_{l \in\{1, \cdots, K\}}, & \frac{\partial \mathcal{L}(\theta ; X)}{\partial \pi_{l}}=0 \\
& \text { s.t. } \sum_{l}^{K} \pi_{l}=1
\end{aligned}
\]</span></p>

<p>拉格朗日乘法约束</p>

<p><span  class="math">\[
\left\{\begin{aligned}
L_{\pi_{l}} &=\frac{\partial \mathcal{L}(\theta ; X)}{\partial \pi_{l}}+\lambda\left(\sum_{l}^{K} \pi_{l}-1\right)=0 \\
L_{\lambda} &=\sum_{l}^{K} \pi_{l}-1=0
\end{aligned}\right.
\]</span></p>

<p>求导：</p>

<p><span  class="math">\[
\left\{\begin{array}{c}
\frac{1}{\pi_{1}} \sum_{i}^{N} Q_{i}(1)-\lambda=0 \\
\vdots \\
\frac{1}{\pi_{l}} \sum_{i}^{N} Q_{i}(l)-\lambda=0
\end{array}\right.
\]</span></p>

<p>相加得：</p>

<p><span  class="math">\[
\sum_{l}^{K} \sum_{i}^{N} Q_{i}(l)=\lambda \sum_{l}^{K} \pi_{l}=\lambda
\]</span></p>

<p>由  $Q_{i}(l)=p\left(l \vert x_{i}, \theta\right)$, 得</p>

<p><span  class="math">\[
\begin{aligned}
\sum_{l}^{K} \sum_{i}^{N} Q_{i}(l) &=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \\
&=\sum_{i}^{N} \sum_{l}^{K} p\left(l | x_{i}, \theta\right) \\
&=\sum_{i}^{N} 1 \\
&=N
\end{aligned}
\]</span></p>

<p>则</p>

<p><span  class="math">\[
\begin{aligned}
\pi_{l} &=\frac{1}{\lambda} \sum_{i}^{N} Q_{i}(l) \\
&=\frac{1}{N} \sum_{i}^{N} Q_{i}(l) \\
&=\frac{1}{N} \sum_{i}^{N} p\left(l | x_{i}, \theta\right)
\end{aligned}
\]</span></p>

<h3 id="4-计算mu">(4) 计算$\mu$</h3>

<p><span  class="math">\[
\begin{aligned}
&\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \mathcal{N}\left(\mu_{l}, \Sigma_{l}\right)\\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l) \log \frac{1}{\sqrt{2 \pi} \sigma_{l}} e^{-\frac{\left(x_{i}-\mu_{l}\right)^{2}}{2 \sigma_{l}^{2}}}\\
&=\sum_{i}^{N} \sum_{l}^{K} Q_{i}(l)\left\{-\frac{1}{2} \log 2 \pi-\frac{1}{2} \log \sigma_{l}^{2}-\frac{\left(x_{i}-\mu_{l}\right)^{2}}{2 \sigma_{l}^{2}}\right\}
\end{aligned}
\]</span></p>

<p>求偏导：</p>

<p><span  class="math">\[
\begin{aligned}
\frac{\partial \mathcal{L}(\theta ; X)}{\partial \mu_{l}} &=\sum_{i}^{N} Q_{i}(l) \frac{x_{i}-\mu_{l}}{\sigma^{2}} \\
&=0
\end{aligned}
\]</span></p>

<p>得$\mu$：</p>

<p><span  class="math">\[
\mu_{l}=\frac{\sum_{i}^{N} Q_{i}(l) x_{i}}{\sum_{i}^{N} Q_{i}(l)}
\]</span></p>

<p><span  class="math">\[
\begin{aligned}
&\frac{\partial \mathcal{L}(\theta ; X)}{\partial \sigma_{l}^{2}}=\sum_{i}^{N} Q_{i}(l)\left\{-\frac{1}{2 \sigma_{l}^{2}}+\frac{\left(x_{i}-\mu_{l}\right)^{2}}{2 \sigma_{l}^{4}}\right\}\\
&=0
\end{aligned}
\]</span></p>

<h3 id="5-计算sigma">(5) 计算$\sigma$</h3>

<p><span  class="math">\[
\begin{aligned}
\frac{\partial \mathcal{L}(\theta ; X)}{\partial \sigma_{l}^{2}} &=\sum_{i}^{N} Q_{i}(l)\left\{-\frac{1}{2 \sigma_{l}^{2}}+\frac{\left(x_{i}-\mu_{l}\right)^{2}}{2 \sigma_{l}^{4}}\right\} \\
&=0
\end{aligned}
\]</span></p>

<p>得到</p>

<p><span  class="math">\[
\sigma_{l}=\frac{\sum_{i}^{N} Q_{i}(l)\left(x_{i}-\mu_{l}\right)^{2}}{\sum_{i}^{N} Q_{i}(l)}
\]</span></p>

<h2 id="6-从kl散度角度解释em">6 从KL散度角度解释EM</h2>

<p><span  class="math">\[
\begin{aligned}
K L(q \| p) &=\sum_{z} q(z) \log \frac{q(z)}{p(z | x, \theta)} \\
&=\sum_{z} q(z) \log \frac{q(z) p(x | \theta)}{p(z, x | \theta)} \\
&=-\sum_{z} q(z) \log \frac{p(z, x | \theta)}{q(z)}+\sum_{z} q(z) \log p(x | \theta) \\
&=-\sum_{z} q(z) \log \frac{p(z, x | \theta)}{q(z)}+\log p(x | \theta) \sum_{z} q(z) \\
&=-\sum_{z} q(z) \log \frac{p(z, x | \theta)}{q(z)}+\log p(x | \theta) \\
\log p(x | \theta) &=K L(q \| p)+\sum_{z} q(z) \log \frac{p(z, x | \theta)}{q(z)} \\
&=K L(q \| p)+\mathcal{L}(q, \theta)
\end{aligned}
\]</span></p>

<p>参考：</p>

<p><a href="https://www.youtube.com/watch?v=Bq5s80ZCmC0&amp;list=PLyAft-JyjIYpno8IfZZS0mnxD5TYZ6BIc">徐亦达-机器学习-EM</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2020-01-26</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://zqfang.github.io/2020-01-26-ml-em/" data-title="Expectation Maximization" data-hashtags="Expectation Maximization"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://zqfang.github.io/2020-01-26-ml-em/" data-hashtag="Expectation Maximization"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://zqfang.github.io/2020-01-26-ml-em/" data-title="Expectation Maximization"><i class="fab fa-hacker-news fa-fw"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://zqfang.github.io/2020-01-26-ml-em/" data-title="Expectation Maximization"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://zqfang.github.io/2020-01-26-ml-em/" data-title="Expectation Maximization"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/expectation-maximization/">Expectation Maximization</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2020-01-26-ml-montecarlo/" class="prev" rel="prev" title="Mento Carlos"><i class="fas fa-angle-left fa-fw"></i>Mento Carlos</a>
            <a href="/2020-01-29-ml-lossfunc/" class="next" rel="next" title="Loss function for multi-label classification">Loss function for multi-label classification<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">zqfang</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://bioninja-1.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js" integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/&#43;HcLiLAxmjw="></script></body>
</html>
