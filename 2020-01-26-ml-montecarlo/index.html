<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>Markov Chain Mento Carlo (MCMC) - My Computational Genomic Playground</title><meta name=Description content="My Computational Genomic Playground"><meta property="og:title" content="Markov Chain Mento Carlo (MCMC)"><meta property="og:description" content="蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算"><meta property="og:type" content="article"><meta property="og:url" content="https://zqfang.github.io/2020-01-26-ml-montecarlo/"><meta property="og:image" content="https://zqfang.github.io/logo.png"><meta property="article:published_time" content="2020-06-06T00:00:00+00:00"><meta property="article:modified_time" content="2020-06-06T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zqfang.github.io/logo.png"><meta name=twitter:title content="Markov Chain Mento Carlo (MCMC)"><meta name=twitter:description content="蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算"><meta name=application-name content="Pleiades"><meta name=apple-mobile-web-app-title content="Pleiades"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://zqfang.github.io/2020-01-26-ml-montecarlo/><link rel=prev href=https://zqfang.github.io/2020-06-06-ml-svd/><link rel=next href=https://zqfang.github.io/2020-06-13-stats-hierachial-models/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Markov Chain Mento Carlo (MCMC)","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zqfang.github.io\/2020-01-26-ml-montecarlo\/"},"image":["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"Monte Carlo, Statistical Learning","wordcount":2565,"url":"https:\/\/zqfang.github.io\/2020-01-26-ml-montecarlo\/","datePublished":"2020-06-06T00:00:00+00:00","dateModified":"2020-06-06T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/zqfang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"zqfang"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/publication/>Publication </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/ title=About>About </a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/categories/>Categories</a><a class=menu-item href=/publication/>Publication</a><a class=menu-item href=/portfolio/>Portfolio</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/about/ title=About>About</a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">Markov Chain Mento Carlo (MCMC)</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning/><i class="far fa-folder fa-fw"></i>Machine Learning</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-06-06>2020-06-06</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2565 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#蒙特卡罗法monte-carlo>蒙特卡罗法（Monte Carlo）</a><ul><li><a href=#1-蒙特卡罗方法的核心>1. 蒙特卡罗方法的核心</a></li><li><a href=#2-数学期望估计estimation-of-mathematical-expectation>2. 数学期望估计(Estimation of mathematical expectation)</a></li><li><a href=#3-蒙特卡罗积分monte-carlo-intergration>3. 蒙特卡罗积分（Monte carlo intergration）</a></li></ul></li><li><a href=#markov-chain>Markov Chain</a><ul><li><a href=#定义>定义</a><ul><li><a href=#离散状态马可夫链>离散状态马可夫链</a></li><li><a href=#连续状态马可夫链>连续状态马可夫链</a></li><li><a href=#马可夫链的性质>马可夫链的性质</a></li></ul></li></ul></li><li><a href=#markov-chain-monte-carlo>Markov Chain Monte Carlo</a><ul><li><a href=#metropolis-hastings>Metropolis-Hastings</a></li><li><a href=#gibbs-sampling>Gibbs Sampling</a></li></ul></li></ul></nav></div></div><div class=content id=content><p>蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算的方法。<br>马可夫蒙特卡罗法（Markov Chain Monte Carlo, MCMC）则是以马可夫链为概率模型的蒙特卡罗方法。</p><p>Metropolis-Hastings算法是最基本的MCMC。
Gibbs sampling是更简单、使用更广泛的MCMC。</p><h1 id=markov-chain-monte-carlo-mcmc>Markov Chain Monte Carlo (MCMC)</h1><h2 id=蒙特卡罗法monte-carlo>蒙特卡罗法（Monte Carlo）</h2><p>蒙特卡罗法要解决的问题是，假设概率分布的定义己知，<strong>通过抽样获得概率分布的随机样本</strong>，并通过得到的随机样本对概率分布的特征进行分析</p><h3 id=1-蒙特卡罗方法的核心>1. 蒙特卡罗方法的核心</h3><p>蒙特卡罗方法的核心是随机抽样(random sampling)</p><ul><li>直接抽样</li><li>接受-拒绝抽样： 适用于概率密度函数复杂，不能直接抽样的情况</li><li>重要性抽样： 适用于概率密度函数复杂，不能直接抽样的情况</li></ul><p>接受-拒绝抽样思想：找一个可以直接抽样的建议分布（proposal distribution），其概率密度函数为$q(x)$, 并且$q(x)$的$c$倍一定大于$p(x)$， 其中$c > 0$,按照$q(x)$进行抽样，假设得到结果$x^\ast$， 再按照$\frac{p(x^\ast)}{cq(x^\ast )}$的比例随机决定是否接受$x^\ast$。落到$p(x)$范围内的就接受，落到$p(x)$范围外的就拒绝❌。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/stats/rejsmp.png data-srcset="/images/stats/rejsmp.png, /images/stats/rejsmp.png 1.5x, /images/stats/rejsmp.png 2x" data-sizes=auto alt=/images/stats/rejsmp.png title=Sampling></p><p>这些抽样方法的<strong>缺点</strong>：</p><ul><li>抽样效率低， 比如 $p(x)$ 占 $cq(x)$ 涵盖体积比例很低</li><li>当x为高维数据时，很难寻找合适的建议分布</li></ul><p>一个解决办法就是MCMC.</p><h3 id=2-数学期望估计estimation-of-mathematical-expectation>2. 数学期望估计(Estimation of mathematical expectation)</h3><p>按照概率分布 $p(x)$ 独立抽取n个样本后计算函数的样本均值</p><p>$$
\hat f_{n}=\frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right)
$$</p><p>作为数学期望的近似值。</p><p>根据大数定律可知，当样本容量增大是，样本均值以概率1收敛性于数学期望</p><p>$$
\hat f_{n} \rightarrow E_{p(x)}[f(x)], \quad n \rightarrow \infty
$$</p><p>于是，得到数学期望的近似计算方法</p><p>$$
E_{p(x)}[f(x)] \approx \frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right)
$$</p><h3 id=3-蒙特卡罗积分monte-carlo-intergration>3. 蒙特卡罗积分（Monte carlo intergration）</h3><p>计算函数 $h(x)$ 积分</p><p>$$
\int_{\mathcal{X}} h(x) \mathrm{d} x
$$</p><p>将 $h(x)$ 分解成 $f(x)$ 和概率密度函数 $p(x)$ 的乘积，即函数 $h(x)$ 的积分可以表示为函数 $f(x)$ 关于概率密度函数 $p(x)$ 的数学期望：</p><p>$$
\int_{\mathcal{X}} h(x) \mathrm{d} x=\int_{\mathcal{X}} f(x) p(x) \mathrm{d} x=E_{p(x)}[f(x)]
$$</p><p>因此，可利用样本均值计算近似积分：</p><p>$$
\int_{\mathcal{X}} h(x) \mathrm{d} x=E_{p(x)}[f(x)] \approx \frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right)
$$</p><p>更进一步</p><p>$$
\begin{aligned}
E_{p(z)}[f(z)] &= \int f(z) p(z) dz \cr
&= \int \underbrace{f(z) \frac{p(z)}{q(z)}}_{new \tilde{f} (z)} q(z) dz \cr
& \approx \frac{1}{N} \sum_{n=1}^{N} f(z^{i}) \frac{p(z^{i})}{q(z^{i})}
\end{aligned}
$$</p><h2 id=markov-chain>Markov Chain</h2><h3 id=定义>定义</h3><p>马可夫性：
随机变量$X_t$只依赖$X_{t-1}$，而不依赖过去的随机变量 $\lbrace X_{0}, X_{1}, \cdots, X_{t-2} \rbrace$。即</p><p>$$
P\left(X_{t} | X_{0}, X_{1}, \cdots, X_{t-1}\right)=P\left(X_{t} | X_{t-1}\right), \quad t=1,2, \cdots
$$</p><p>马可夫链或马可夫过程（markov process）指：
具有马可夫性的随机序列 $X=\lbrace X_{0}, X_{1}, \cdots, X_{t}, \cdots \rbrace$。</p><p>马可夫链的转移条件概率分布为 $P(X_t | X_{t-1})$ 。转移概率分布决定马可夫链的特性。</p><p>时间齐次马可夫链（time homogenous Markov Chain）是指转移状态分布于t无关的马可夫链</p><h4 id=离散状态马可夫链>离散状态马可夫链</h4><p>状态转移矩阵</p><p>平稳分布：
马可夫链 $X$， 其状态空间为$\mathcal{S}$， 转移矩阵为 $P = (p_{ij})$， 如果存在状态空间 $\mathcal{S}$ 上的一个分布</p><p>$$
\pi = \left[\begin{array}{c}
\pi_1 \cr
\pi_2 \cr
\vdots
\end{array}\right]
$$</p><p>使得 $\pi=P\pi$, 则称$\pi$为马可夫链$X = {X_0, X_1, \cdots, X_t, \cdots }$ 的平稳分布</p><h4 id=连续状态马可夫链>连续状态马可夫链</h4><p>定义在连续状态空间，转移概率分布有概率转移核（trainsition kernel）表示</p><p>$$
P(x, A) = \int_{A} p(x, y) dy
$$</p><p>转移核$P(x, A)$表示转移概率</p><p>$$
P (X_t = A | X_{t-1} = x) = P (x, A)
$$</p><h4 id=马可夫链的性质>马可夫链的性质</h4><ol><li>不可约 (irreducible): 时刻 0 从状态 $j$ 出发，时刻 $t$ 到达状态 $i$ 的概率大于 0 ，则称此马尔可夫链 $X$ 是不可约的</li></ol><p>$$
P(X_t = i | X_0 = j) > 0
$$</p><ol start=2><li><p>非周期：不纯在一个状态，使得再返回到这个状态所经历的时间长呈周期性</p></li><li><p>正常返(positive recurrent): 任意一个状态$i$，从其他任意状态 $j$ 出发，当时间趋近无穷时，首次转移到这个状态$i$的概率 $p^t_{ij}$ 不为0</p></li></ol><p>$$
\lim_{t \rightarrow \infty} p^t_{ij} > 0
$$</p><ol start=4><li>遍历定理：满足相应条件的马尔可夫链，当时间趋于无穷时，马尔可 夫链的状态分布趋近于平稳分布，随机变量的函数的样本均值以概率 1 收敛于该函数 的数学期望</li></ol><p>马可夫链 $X$， 其状态空间为$\mathcal{S}$， 若马可夫链 $X$ 不可约、非周期且正常返， 则马可夫链有唯一的平稳分布 $\pi = (\pi_1, \pi_2, \cdots)^T$， 并且转移概率的极限分布是马可夫链的平稳分布</p><p>$$
\lim_{t \rightarrow \infty} P(X_t = i | X_0 = j) = \pi_i, i = 1,2, \cdots ; j = 1,2,\cdots
$$</p><p>若 $f(X)$是定义在状态空间上的函数 $E_{pi}[ | f(X) | ] &lt; \infty$, 则</p><p>$$
P { \hat{f_t} \rightarrow E_{pi}[ f(X) ] } = 1
$$</p><p>这里，</p><p>$$
\hat{f_t} = \frac{1}{t} \sum^t_{s=1} f(x_s)
$$</p><p>关于平稳分布 $\pi = (\pi_1, \pi_2, \cdots)^T$ 的数学期望 $E_{pi}[f(X)] = \sum f(i)\pi_i$, 有</p><p>$$
\hat{f_t} \rightarrow E_{pi}[ f(X) ], t \rightarrow \infty
$$</p><p>处处成立或以概率1成立。</p><h2 id=markov-chain-monte-carlo>Markov Chain Monte Carlo</h2><p>马可夫蒙特卡罗法更适合随机变量是多元的、密度函数是非标准形式的、随机变量各分量不独立等情况</p><p>基本思想：</p><p>在随机变量$x$的状态空间$\mathcal{S}$上定一个满足遍历定理的马可夫链，使其平稳分布就是抽样的目标分布 $p(x)$， 然后在这个马可夫链上进行随机游走，每个时刻得到一个样本。根据遍历定理，当时间趋于无穷是，样本的分布趋近平稳分布，样本函数均值趋近函数的数学期望</p><p>$$
\hat{E}f = \frac{1}{n-m} \sum^{n}_{i=m+1} f(x_i)
$$</p><p>马尔可夫链蒙特卡罗法的关键是如何构建转移核函数或转移矩阵， 包括： Metropolis-Hastings 和 Gibbs sampling。</p><p>马尔可夫链蒙特卡罗法中得到的样本序列，<strong>相邻的样本点是相关的</strong>，而不是独立的<br>马尔可夫链蒙特卡罗法的<strong>收敛性的判断</strong>通常是<strong>经验性</strong>的</p><p>基本步骤：</p><ol><li><p>在随机变量$x$的状态空间$\mathcal{S}$上构建一个满足遍历定理的马可夫链，使其平稳分布为目标分布 $p(x)$</p></li><li><p>从状态空间的某一点 $X_0$ 出发，用构造的马可夫链进行随机游走，产生样本序列 ${x_0, x_1, \cdots, x_t, \cdots }$。</p></li><li><p>应用马可夫链的遍历定理， 确定正整数 $m$ 和 $n$， $m &lt; n$， 得到样本集合 ${x_{m+1}, x_{m+2}， \cdots, x_n }$ 求得函数f的（遍历）均值</p></li></ol><p>$$
\hat{E}f = \frac{1}{n-m} \sum^{n}_{i=m+1} f(x_i)
$$</p><p>几个重要问题需要注意：</p><ul><li>如何定义马可夫链，保证MCMC成立</li><li>如何确定收敛步数m，保证抽样无偏性</li><li>如何确定迭代步数n， 保证遍历均值的计算精度</li></ul><h3 id=metropolis-hastings>Metropolis-Hastings</h3><p>Metropolis-Hasting是马尔可夫链蒙特卡罗法的代表算法</p><p>可以对多元变量的每一变量的条件分布依次分别进行抽样， 从而实现对整个多元变量的一次抽样，这就是单分量 Metropolis- Hastings (singlecomponent Metropolis- Hastings) 算法。</p><h3 id=gibbs-sampling>Gibbs Sampling</h3><p>吉布斯抽样，可以认为是 Metropolis-Hastings 算法的特殊情况，但是更容易实现，因而被广泛使用。</p><p>吉布斯抽样用于多元变量<strong>联合分布</strong>的抽样和估计。 其基本做法是，从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列。</p><p><code>吉布斯抽样</code>适合于<strong>满条件概率分布</strong> <code>容易抽样</code> 的情况，而<code>单分量MetropolisHastings</code> 算法适合于满条件概率分布<code>不容易抽样</code>的情况，这时使用容易抽样的条件分布作建议分布。</p><p>参考： 李航《统计学习方法》</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-06-06</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://zqfang.github.io/2020-01-26-ml-montecarlo/ data-title="Markov Chain Mento Carlo (MCMC)" data-hashtags="Monte Carlo,Statistical Learning"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://zqfang.github.io/2020-01-26-ml-montecarlo/ data-hashtag="Monte Carlo"><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://zqfang.github.io/2020-01-26-ml-montecarlo/ data-title="Markov Chain Mento Carlo (MCMC)"><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://zqfang.github.io/2020-01-26-ml-montecarlo/ data-title="Markov Chain Mento Carlo (MCMC)"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://zqfang.github.io/2020-01-26-ml-montecarlo/ data-title="Markov Chain Mento Carlo (MCMC)"><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/monte-carlo/>Monte Carlo</a>,&nbsp;<a href=/tags/statistical-learning/>Statistical Learning</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2020-06-06-ml-svd/ class=prev rel=prev title="Singular Value Decomposition (SVD)"><i class="fas fa-angle-left fa-fw"></i>Singular Value Decomposition (SVD)</a>
<a href=/2020-06-13-stats-hierachial-models/ class=next rel=next title="Multilevel (Hierachical) Models">Multilevel (Hierachical) Models<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=disqus_thread class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zqfang</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://bioninja-1.disqus.com/embed.js defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body></html>