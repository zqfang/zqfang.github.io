<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>Hidden Markov Model (HMM) - My Computational Genomic Playground</title><meta name=Description content="My Computational Genomic Playground"><meta property="og:title" content="Hidden Markov Model (HMM)"><meta property="og:description" content="隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。 HMM在语音识别、自然"><meta property="og:type" content="article"><meta property="og:url" content="https://zqfang.github.io/2020-05-03-ml-hmm/"><meta property="og:image" content="https://zqfang.github.io/logo.png"><meta property="article:published_time" content="2020-05-03T00:00:00+00:00"><meta property="article:modified_time" content="2020-05-03T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zqfang.github.io/logo.png"><meta name=twitter:title content="Hidden Markov Model (HMM)"><meta name=twitter:description content="隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。 HMM在语音识别、自然"><meta name=application-name content="#root max >"><meta name=apple-mobile-web-app-title content="#root max >"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://zqfang.github.io/2020-05-03-ml-hmm/><link rel=prev href=https://zqfang.github.io/2020-04-30-ml-lsa/><link rel=next href=https://zqfang.github.io/2020-05-05-ml-boosting/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Hidden Markov Model (HMM)","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zqfang.github.io\/2020-05-03-ml-hmm\/"},"image":["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"Hidden Markov Model, Expectation Maximization, Probabilistic Graphical Model, Statistical Learning","wordcount":2427,"url":"https:\/\/zqfang.github.io\/2020-05-03-ml-hmm\/","datePublished":"2020-05-03T00:00:00+00:00","dateModified":"2020-05-03T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/zqfang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"zqfang"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><i class="fas fa-hashtag"></i></span>MAX <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/publication/>Publication </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/ title=About>About </a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><i class="fas fa-hashtag"></i></span>MAX <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/categories/>Categories</a><a class=menu-item href=/publication/>Publication</a><a class=menu-item href=/portfolio/>Portfolio</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/about/ title=About>About</a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">Hidden Markov Model (HMM)</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning/><i class="far fa-folder fa-fw"></i>Machine Learning</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-05-03>2020-05-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;2427 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static></div></div><div class=content id=content><p>隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。
HMM在语音识别、自然语言处理、生物信息、模式识别等领域由广泛应用。</p><h2 id=1-hmm的定义>1. HMM的定义</h2><p>隐马可夫模型是关于时序的概率模型， 描述由一个隐藏的马可夫链随机生成不可观测的状态，再由各个状态生成一个观测，从而产生观测随机序列的过程。</p><p>简而言之，隐马可夫链随机成状态序列（state sequence），而每个状态生成观测，产生观测序列（observation sequence）。序列的一个位置可以看作一个时刻。</p><p>令$Q$ 表示所有可能状态的集合：$Q = { q_1, q_2, \cdots, q_N }$;<br>令$V$ 表示所有可能的观测集合：$V = {v_1, v_2, \cdots, v_M }$;<br>令$I$ 表示长度为T的状态序列： $I = (i_1, i_2, \cdots, i_T)$;<br>令$O$ 表示对应的是观测序列： $O = (o_1, o_2, \cdots, o_T)$.</p><p>令$A$是转移概率矩阵：</p><p><span class=math>\[A = [a_{ij}]_{N \times N}\]</span></p><p>其中，</p><p><span class=math>\[a_{ij} = P(i_{t+1} = q_j | i_t = q_j), i=1,2, \cdots, N; j = 1,2, \cdots, N\]</span></p><p>是在时刻$t$处于状态$q_i$的条件下生成观测$t +1$转移到状态$q_j$的概率。</p><p>令$B$是观测概率矩阵：</p><p><span class=math>\[B = [b_j(k)]_{N \times M}\]</span></p><p>其中，</p><p><span class=math>\[b_j(k) = P(o_t = v_k | i_t = q_j), k=1,2,\cdots, M; j=1,2,\cdots, N\]</span></p><p>是在时刻$t$处于状态$q_j$的条件下生成观测$v_k$ 的概率。</p><p>令$\pi$是初始状态概率向量：</p><p><span class=math>\[\pi = (\pi_i)\]</span></p><p>其中，</p><p><span class=math>\[\pi_{i} = P(i_1 = q_i),i=1,2,\cdots, N\]</span></p><p>是时刻t=1处于状态$q_i$的概率.</p><p>隐马可夫模型$\lambda$由$\pi$， $A$，$B$决定。</p><p><span class=math>\[\lambda = (A, B, \pi)\]</span></p><p>其中，$\pi$和$A$决定状态序列，$B$决定观测序列。</p><p>隐马可夫模型的两个基本假设</p><ol><li>齐次马可夫性<ul><li>隐马可夫链在任意时刻t的状态前一时刻状态，与其他时刻的隐状态和观测无关， 也与时刻t无关：</li></ul></li></ol><p><span class=math>\[P(i_t | i_{t-1}, O_{t-1}, \cdots, i_1, o_1) = P(i_t | i_{t-1}), t = 1,2,\cdots,T\]</span></p><ol start=2><li><p>观测独立性</p><ul><li>任意时刻的观测只依赖改时刻的马可夫链状态，与其他观测和状态无关:</li></ul><p><span class=math>\[P(o_t | i_{T}, O_{T}, i_{T-1}, o_{T-1}\cdots, i_{t+1}, O_{t+1}, i_{t-1}, O_{t-1}, i_1, o_1) = P(o_t | i_{t})\]</span></p></li></ol><h2 id=2-hmm的3个基本问题>2. HMM的3个基本问题</h2><p>概率计算：给定模型$\lambda = (A, B, \pi)$和观测序列
$O = (o_1, o_2, \cdots, o_T)$， 求概率$P(O | \lambda)$</p><p>学习: 已知观测序列$O = (o_1, o_2, \cdots, o_T)$，估计模型参数$\lambda = (A, B, \pi)$， 使概率$P(O \vert \lambda)$最大（用极大似然估计）。</p><p>预测：给定模型$\lambda = (A, B, \pi)$和观测序列
$O = (o_1, o_2, \cdots, o_T)$，求条件概率$P(I | O)$最大的状态序列 $I = (i_1, i_2, \cdots, i_T)$.</p><h3 id=21-概率计算前向forward和后向backward算法>2.1 概率计算前向（forward）和后向（backward）算法</h3><h4 id=211-前向算法>2.1.1 前向算法</h4><p>给定模型$\lambda$，当时刻$t$时，状态为$q_i$，部分观测序列为$o_1, o_2, \cdots, o_t$，记：</p><p><span class=math>\[\alpha_{t}(i) = P(o_1, o_2, \cdots, o_t, i_t = q_i | \lambda)\]</span></p><p>输入： 隐马可夫模型 $\lambda$， 观测序列$O$;<br>输出： 观测序列概率$P(O | \lambda)$</p><p>（1）初值</p><p><span class=math>\[
\alpha_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \quad i=1,2, \cdots, N
\]</span></p><p>（2）递推 对 $t = 1,2, \cdots, T-1,$</p><p><span class=math>\[
\alpha_{t+1}(i)=\left[\sum_{j=1}^{N} \alpha_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N
\]</span></p><p>（3）终止</p><p><span class=math>\[
P(O | \lambda)=\sum_{i=1}^{N} \alpha_{T}(i)
\]</span></p><h4 id=212-后向算法>2.1.2 后向算法</h4><p>给定模型$\lambda$，当时刻$t$时，状态为$q_i$，部分观测序列为$o_1, o_2, \cdots, o_t$，记：</p><p><span class=math>\[\beta_{t}(i) = P(o_{t+1}, o_{t+2}, \cdots, o_T | i_t = q_i, \lambda)\]</span></p><p>输入： 隐马可夫模型 $\lambda$， 观测序列$O$;<br>输出： 观测序列概率$P(O | \lambda)$</p><p>（1）初始 令最终时刻所有状态$q_i$</p><p><span class=math>\[\beta_T(i) = 1, i=1,2,\cdots, N\]</span></p><p>（2）递推 对$t=T-1, T-2, \cdots, 1$</p><p><span class=math>\[
\beta_{t}(i)=\sum_{j=1}^{N} a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j), \quad i=1,2, \cdots, N
\]</span></p><p>（3）终止</p><p><span class=math>\[
P(O | \lambda)=\sum_{i=1}^{N} \pi_{i} b_{i}\left(o_{1}\right) \beta_{1}(i)
\]</span></p><p>利用前后向概率定义，可以将观测序列概率$P(O \vert \lambda)$统一写成</p><p><span class=math>\[
P(O | \lambda)=\sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{t}(i) a_{i j} b_{j}\left(o_{t+1}\right) \beta_{t+1}(j), \quad t=1,2, \cdots, T-1
\]</span></p><h3 id=22-学习问题的em算法>2.2 学习问题的EM算法</h3><p>实质上求一个隐变量的概率模型的参数估计：</p><p><span class=math>\[
P(O | \lambda)=\sum_{I} P(O | I, \lambda) P(I | \lambda)
\]</span></p><p>参数估计由EM算法实现:
(待续)</p><p>输入：观测数据$O = (o_1, o_2, \cdots, o_T)$;<br>输出：隐马可夫模型参数</p><p>（1）初始化<br>对 n=0， 选取$a_{ij}^{(0)}$, $b_{j}(k)^{(0)}$, $\pi_{i}^{(0)}$, 得到模型$\lambda = (A^{(0)}, B^{(0)}, \pi^{(0)})$.</p><p>（2）递推<br>对$n=1,2, \cdots,$, 有</p><p><span class=math>\[
a_{i j}^{(n+1)}=\frac{\sum_{t=1}^{T-1} \xi_{t}(i, j)}{\sum_{t=1}^{T-1} \gamma_{t}(i)}
\]</span></p><p>另，</p><p><span class=math>\[
b_{j}(k)^{(n+1)}=\frac{\sum_{t=1, o_{t}=v_{k}}^{T} \gamma_{t}(j)}{\sum_{t=1}^{T} \gamma_{t}(j)}
\]</span></p><p><span class=math>\[
\pi_{i}^{(n+1)}=\gamma_{1}(i)
\]</span></p><p>其中，时刻$t$处于$q_i$，且时刻$t+1$处于状态$q_j$的概率, 记</p><p><span class=math>\[
\xi_{t}(i, j)=P\left(i_{t}=q_{i}, i_{t+1}=q_{j} | O, \lambda\right)
\]</span></p><p>那么</p><p><span class=math>\[
\xi_{t}(i, j)=\frac{P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}{P(O | \lambda)}=\frac{P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}{\sum_{i=1}^{N} \sum_{j=1}^{N} P\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \lambda\right)}
\]</span></p><p>和时刻$t$处于$q_i$的概率， 有</p><p><span class=math>\[
\gamma_{t}(i)=P\left(i_{t}=q_{i} | O, \lambda\right)=\frac{P\left(i_{t}=q_{i}, O | \lambda\right)}{P(O | \lambda)}
\]</span></p><p>（3）终止</p><p>得到模型参数$\lambda^{(n+1)} = (A^{(n+1)}, B^{(n+1)}, \pi^{(n+1)})$</p><h3 id=23-预测算法>2.3 预测算法</h3><p>包括近似算法和维特比算法（Viterbi algorithm）</p><h4 id=231-近似算法>2.3.1 近似算法</h4><p>在每个时刻$t$， 选择在该时刻最可能出现的状态 <span class=math>\(i^*_{t}\)</span>从而得到一个状态序列<span class=math>\(I^* = (i^*_i, i^*_i, \cdots, i^*_T)\)</span>，将它最为预测结果。</p><p>给定模型$\lambda$和观测序列$O$， 在时刻$t$处于状态$q_i$的概率$\gamma_t(i)$是</p><p><span class=math>\[
\gamma_{t}(i)=\frac{\alpha_{t}(i) \beta_{t}(i)}{P(O | \lambda)}=\frac{\alpha_{t}(i) \beta_{t}(i)}{\sum_{j=1}^{N} \alpha_{t}(j) \beta_{t}(j)}
\]</span></p><p>而每一时刻$t$最有可能的状态$i_{t}^{*}$是</p><p><span class=math>\[
i_{t}^{*}=\arg \max _{1 \leqslant i \leqslant N}\left[\gamma_{t}(i)\right], \quad t=1,2, \cdots, T
\]</span></p><p>从而得到状态序列<span class=math>\(I^* = (i^*_i, i^*_i, \cdots, i^*_T)\)</span></p><p>缺点： 不能保证预测状态序列整体是最有可能的状态序列，因为预测的状态序列实际可能由不发生的部分。</p><h4 id=232-维特比算法>2.3.2 维特比算法</h4><p>实质是运用<strong>动态规划求概率最大路径</strong>，从而解决HMM的预测问题</p><p><strong>维特比算法</strong>: 只需从时刻$t=1$开始，递推地计算在时刻$t$状态为$q_i$的各条部分路径的最大概率，直至得到时刻$t = T$状态为$i$的各条路径的最大概率。时刻 $t = T$ 的最大概率即为最优路径的概率 <span class=math>\(P^*\)</span>, 最优路径的终结点<span class=math>\(i^* _T\)</span> 也同时得到。之后，为了找出最优路径的各个结点，从终结点<span class=math>\(i^*_T\)</span>开始，由后向前逐步求得结点 <span class=math>\(i^*_{T-1}, \cdots, i^*_1\)</span>，得到最优路径<span class=math>\(I^* = (i^*_i, i^*_i, \cdots, i^*_T)\)</span>。</p><p>定义在时刻$t$状态$i$的所有单个路径中概率最大值为</p><p><span class=math>\[
\delta_{t}(i)=\max _{i_{1}, i_{2}, \cdots, i_{t-1}} P\left(i_{t}=i, i_{t-1}, \cdots, i_{1}, o_{t}, \cdots, o_{1} | \lambda\right), \quad i=1,2, \cdots, N
\]</span></p><p>因此</p><p><span class=math>\[
\begin{aligned}
\delta_{t+1}(i) &=\max _{i_{1}, i_{2}, \cdots, i_{t}} P\left(i_{t+1}=i, i_{t}, \cdots, i_{1}, o_{t+1}, \cdots, o_{1} | \lambda\right) \\
&= \max _{1 \leqslant j \leqslant N}\left[\delta_{t}(j) a_{j i}\right] b_{i}\left(o_{t+1}\right), \quad i=1,2, \cdots, N ; \quad t=1,2, \cdots, T-1
\end{aligned}
\]</span></p><p>定义在时刻t状态i的所有单个路径中概率最大路径的第$t-1$个节点为</p><p><span class=math>\[
\Psi_{t}(i)=\arg \max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N
\]</span></p><p>输入： 隐马可夫模型 $\lambda$， 观测序列$O$;<br>输出： 最优路径<span class=math>\(I^* = (i^*_i, i^*_i, \cdots, i^*_T)\)</span></p><p>(1) 初始化:</p><p><span class=math>\[
\begin{array}{c}
\delta_{1}(i)=\pi_{i} b_{i}\left(o_{1}\right), \quad i=1,2, \cdots, N \\
\Psi_{1}(i)=0, \quad i=1,2, \cdots, N
\end{array}
\]</span></p><p>(2) 递推:</p><p><span class=math>\[
\begin{array}{c}
\delta_{t}(i)=\max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right] b_{i}\left(o_{t}\right), \quad i=1,2, \cdots, N \\
\Psi_{t}(i)=\arg \max _{1 \leqslant j \leqslant N}\left[\delta_{t-1}(j) a_{j i}\right], \quad i=1,2, \cdots, N
\end{array}
\]</span></p><p>(3) 终止</p><p><span class=math>\[
\begin{array}{c}
P^* = \max _{1 \leqslant i \leqslant N} \delta_T(i) \\
i^*_T = \arg \max _{1 \leqslant i \leqslant N} [ \delta_T(i)]
\end{array}
\]</span></p><p>(4) 最优路径回溯 对$t=T-1, T-2, \cdots, 1$,</p><p><span class=math>\[i^*_t = \Psi_{t+1}(i^*_{t+1})\]</span></p><p>参考： 李航《统计学习方法》</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-05-03</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://zqfang.github.io/2020-05-03-ml-hmm/ data-title="Hidden Markov Model (HMM)" data-hashtags="Hidden Markov Model,Expectation Maximization,Probabilistic Graphical Model,Statistical Learning"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://zqfang.github.io/2020-05-03-ml-hmm/ data-hashtag="Hidden Markov Model"><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://zqfang.github.io/2020-05-03-ml-hmm/ data-title="Hidden Markov Model (HMM)"><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://zqfang.github.io/2020-05-03-ml-hmm/ data-title="Hidden Markov Model (HMM)"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://zqfang.github.io/2020-05-03-ml-hmm/ data-title="Hidden Markov Model (HMM)"><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/hidden-markov-model/>Hidden Markov Model</a>,&nbsp;<a href=/tags/expectation-maximization/>Expectation Maximization</a>,&nbsp;<a href=/tags/probabilistic-graphical-model/>Probabilistic Graphical Model</a>,&nbsp;<a href=/tags/statistical-learning/>Statistical Learning</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2020-04-30-ml-lsa/ class=prev rel=prev title="Latent semantic analysis (LSA)"><i class="fas fa-angle-left fa-fw"></i>Latent semantic analysis (LSA)</a>
<a href=/2020-05-05-ml-boosting/ class=next rel=next title=Boosting>Boosting<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=disqus_thread class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zqfang</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://bioninja-1.disqus.com/embed.js defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body></html>