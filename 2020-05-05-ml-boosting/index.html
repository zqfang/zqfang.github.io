<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>Boosting - My Computational Genomic Playground</title><meta name=Description content="My Computational Genomic Playground"><meta property="og:title" content="Boosting"><meta property="og:description" content="提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习n个分类器，并将这些分类器线性"><meta property="og:type" content="article"><meta property="og:url" content="https://zqfang.github.io/2020-05-05-ml-boosting/"><meta property="og:image" content="https://zqfang.github.io/logo.png"><meta property="article:published_time" content="2020-05-05T00:00:00+00:00"><meta property="article:modified_time" content="2020-05-05T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zqfang.github.io/logo.png"><meta name=twitter:title content="Boosting"><meta name=twitter:description content="提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习n个分类器，并将这些分类器线性"><meta name=application-name content="Pleiades"><meta name=apple-mobile-web-app-title content="Pleiades"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://zqfang.github.io/2020-05-05-ml-boosting/><link rel=prev href=https://zqfang.github.io/2020-05-03-ml-hmm/><link rel=next href=https://zqfang.github.io/2020-05-30-swift-cheat-sheet/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Boosting","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zqfang.github.io\/2020-05-05-ml-boosting\/"},"image":["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"Boosting, Statistical Learning","wordcount":1903,"url":"https:\/\/zqfang.github.io\/2020-05-05-ml-boosting\/","datePublished":"2020-05-05T00:00:00+00:00","dateModified":"2020-05-05T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/zqfang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"zqfang"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/publication/>Publication </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/ title=About>About </a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/categories/>Categories</a><a class=menu-item href=/publication/>Publication</a><a class=menu-item href=/portfolio/>Portfolio</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/about/ title=About>About</a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">Boosting</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning/><i class="far fa-folder fa-fw"></i>Machine Learning</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-05-05>2020-05-05</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1903 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1-adaboost>1. AdaBoost</a><ul><li><a href=#11-adaboost算法误差>1.1 AdaBoost算法误差</a></li><li><a href=#12-adaboost算法解释>1.2 AdaBoost算法解释</a><ul><li><a href=#121-前向分步算法>1.2.1 前向分步算法</a></li></ul></li></ul></li><li><a href=#2-boosting-tree>2. Boosting Tree</a><ul><li><a href=#21-提升树模型>2.1 提升树模型</a></li><li><a href=#22-提升树算法>2.2 提升树算法</a><ul><li><a href=#221-回归问题提升树>2.2.1 回归问题提升树</a></li></ul></li></ul></li><li><a href=#3-梯度提升>3. 梯度提升</a></li></ul></nav></div></div><div class=content id=content><p>提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习n个分类器，并将这些分类器线性组合，提高分类性能。</p><h2 id=1-adaboost>1. AdaBoost</h2><p>AdaBoost通过提高被前一轮弱分类器错误分类样本的权值，从而降低被正确分类样本的权值，并采取加权多数表决的方法达到分类目的。</p><p>输入：训练数据集$T={(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)}$, $\mathcal{Y} = {-1,+1}$;<br>输出：分类器$G(x)$</p><p>1). 初始化训练数据权值分布</p><p>$$D_1 = (w_{11}, \cdots, w_{1i}, \cdots, w_{1N}), w_{1i} = \frac{1}{N}, i = 1,2,\cdots,N$$</p><p>2). 对 $m = 1，2，\cdots, M$<br>a.对权值分布$D_m$的训练数据集学习，得到基本分类器</p><p>$$
G_{m}(x): \mathcal{X} \rightarrow{-1,+1}
$$</p><p>b.计算$G(x)$在训练数据集上的分类误差率</p><p>$$
e_{m}=\sum_{i=1}^{N} P\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)=\sum_{i=1}^{N} w_{m i} I\left(G_{m}\left(x_{i}\right) \neq y_{i}\right)
$$</p><p>c. 计算$G(x)$的系数</p><p>$$
\alpha_{m}=\frac{1}{2} \log \frac{1-e_{m}}{e_{m}}
$$</p><p>d. 更新训练数据的权值分布</p><p>$$
D_{m+1}=\left(w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1, N}\right)
$$</p><p>$$
w_{m+1, i} = \frac{w_{m i}}{Z_{m}} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right), \quad i=1,2, \cdots, N
$$</p><p>其中，</p><p>$$
Z_{m}=\sum_{i=1}^{N} w_{m i} \exp \left(-\alpha_{m} y_{i} G_{m}\left(x_{i}\right)\right)
$$</p><p>3）构建基本线性分类器组合</p><p>$$
f(x)=\sum_{m=1}^{M} \alpha_{m} G_{m}(x)
$$</p><p>得到最终分类器</p><p>$$
\begin{aligned}
G(x) &=\operatorname{sign}(f(x)) \cr
&=\operatorname{sign}\left(\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right)
\end{aligned}
$$</p><h3 id=11-adaboost算法误差>1.1 AdaBoost算法误差</h3><p>AdaBoost算法最终分类器训练误差界为</p><p>$$
\frac{1}{N} \sum_{i=1}^{N} I\left(G\left(x_{i}\right) \neq y_{i}\right) \leqslant \frac{1}{N} \sum_{i} \exp \left(-y_{i} f\left(x_{i}\right)\right)=\prod_{m} Z_{m}
$$</p><p>这一定理说明，每一轮选取适当的$G_m$使$Z_m$最小，从而使训练误差下降最快。</p><p>对于二分类问题：</p><p>$$
\begin{aligned}
\prod_{m=1}^{M} Z_{m} &=\prod_{m=1}^{M}[2 \sqrt{e_{m}\left(1-e_{m}\right)}] \cr
&=\prod_{m=1}^{M} \sqrt{\left(1-4 \gamma_{m}^{2}\right)} \cr
& \leqslant \exp \left(-2 \sum_{m=1}^{M} \gamma_{m}^{2}\right)
\end{aligned}
$$</p><p>其中， $\gamma_{m}=\frac{1}{2}-e_{m}$</p><h3 id=12-adaboost算法解释>1.2 AdaBoost算法解释</h3><p>AdaBooost可以认为：模型为加法模型，损失函数为指数函数，学习算法为前向分布算法的二分类学习方法</p><h4 id=121-前向分步算法>1.2.1 前向分步算法</h4><p>考虑加法模型（additive model）</p><p>$$
f(x)=\sum_{m=1}^{M} \beta_{m} b\left(x ; \gamma_{m}\right)
$$</p><p>其中，$b(x; \gamma_m)$为基函数，$gamma_m$为参数， $\beta_m$为系数。</p><p>在给定训练集和损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$成为经验风险极小化（损失函数极小化）问题：</p><p>$$
\min_{\beta_{m}, \gamma_{m}} \sum_{i=1}^{N} L\left(y_{i}, \sum_{m=1}^{M} \beta_{m} b\left(x_{i} ; \gamma_{m}\right)\right)
$$</p><p><strong>前向分布算法思想</strong>是： 从前向后，每一步只学一个基函数及其系数，逐步逼近优化目标函数，达到优化步骤简化的目的。</p><p>因此，每一步只需优化如下损失函数：</p><p>$$
\min_{\beta, \gamma} \sum_{i=1}^{N} L\left(y_{i}, \beta b\left(x_{i} ; \gamma\right)\right)
$$</p><p><strong>算法步骤</strong></p><p>输入：训练数据集$T=\lbrace (x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\rbrace$, 损失函数$L(y,f(x))$;基函数集$\lbrace b(x;\gamma) \rbrace$;<br>输出：加法模型$f(x)$</p><p>1）初始化$f_0(x) = 0$<br>2) 对$m = 1,2,\cdots, M$<br>a.极小化损失函数</p><p>$$
\left(\beta_{m}, \gamma_{m}\right)=\arg \min _{\beta, \gamma} \sum_{i=1}^{N} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+\beta b\left(x_{i} ; \gamma\right)\right)
$$</p><p>得到参数$\beta_m$, $\gamma_m$。</p><p>b.更新</p><p>$$
f_{m}(x)=f_{m-1}(x)+\beta_{m} b\left(x ; \gamma_{m}\right)
$$</p><p>3）得到加法模型</p><p>$$
f(x)=f_{M}(x)=\sum_{m=1}^{M} \beta_{m} b\left(x ; \gamma_{m}\right)
$$</p><h2 id=2-boosting-tree>2. Boosting Tree</h2><p>提升树🌲是以决策树为基本分类器的提升方法</p><h3 id=21-提升树模型>2.1 提升树模型</h3><p>采用加法模型（基函数的线性组合）与前向分布算法：</p><p>$$
f_{M}(x)=\sum_{m=1}^{M} T\left(x ; \Theta_{m}\right)
$$</p><p>其中 $T\left(x ; \Theta_{m}\right)$表示决策树，$\Theta_{m}$决策树参数， $M$为树的个数</p><h3 id=22-提升树算法>2.2 提升树算法</h3><p>采用<strong>加法模型</strong>和<strong>前向分布算法</strong>实现学习优化的过程。</p><p>首先确定提升树$f_{0}(x)=0$， 第$m$步的模型是</p><p>$$
f_{m}(x)=f_{m-1}(x)+T\left(x ; \Theta_{m}\right)
$$</p><p>其中， $f_{m-1}(x)$为当前模型，通过经验风险极小化确定下一刻决策树的参数$\Theta_{m}$：</p><p>$$
\hat \Theta_m = \arg \min_{\Theta_{m}} \sum_{i=1}^{N} L(y_{i}, f_{m-1} (x_{i})+T (x_{i} ; \Theta_{m} ))
$$</p><h4 id=221-回归问题提升树>2.2.1 回归问题提升树</h4><p>训练数据集:
$T=\lbrace (x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\rbrace$, $x_{i} \in \mathcal{X} \subseteq \mathbf{R}^{n}$, $\mathcal{X}$为输入空间， $\mathcal{Y} \subseteq \mathbf{R}$;</p><p>将输入空间划分为$J$个互不相交的区域$R1，R2, \cdots, R_J$， 并且每个区域上确定输出的常量$c_j$，那么树可以表示为：</p><p>$$
T(x ; \Theta)=\sum_{j=1}^{J} c_{j} I\left(x \in R_{j}\right)
$$</p><p>其中，</p><p>$$
\Theta=\lbrace \left(R_{1}, c_{1}\right),\left(R_{2}, c_{2}\right), \cdots,\left(R_{J}, c_{J}\right)\rbrace
$$
表示树的却与划分和各个取悦是那个的常数。</p><p>采用一下前向分布算法</p><p>$$
\begin{aligned}
&f_{0}(x)=0\cr
&\begin{array}{l}
f_{m}(x)=f_{m-1}(x)+T\left(x ; \Theta_{m}\right), \quad m=1,2, \cdots, M \cr
f_{M}(x)=\sum_{m=1}^{M} T\left(x ; \Theta_{m}\right)
\end{array}
\end{aligned}
$$</p><p>求解$\hat \Theta_{m}$，
若用平方误差损失函数：</p><p>$$
L(y, f(x))=(y-f(x))^{2}
$$</p><p>则损失函数为：</p><p>$$
\begin{aligned}
L\left(y, f_{m-1}(x)+T\left(x ; \Theta_{m}\right)\right) &=\left[y-f_{m-1}(x)-T\left(x ; \Theta_{m}\right)\right]^{2} \cr
&=\left[r-T\left(x ; \Theta_{m}\right)\right]^{2}
\end{aligned}
$$</p><p>这里，</p><p>$$
r=y-f_{m-1}(x)
$$</p><p>是当前模型拟合数据的残差（residual）。因此对于回归问题提升树，只需拟合当前模型残差。得到$T\left(x ; \Theta_{m}\right)$，更新模型，得到$f_m(x)$。</p><h2 id=3-梯度提升>3. 梯度提升</h2><p>当损失函数不是简单的平方损失、指数损失时，提升树的优化就很难。梯度提升算法利用最速下降法的近似方法，计算损失函数的负梯度在当前模型的值</p><p>$$
-\left[\frac{\partial L\left(y, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}
$$</p><p>并将其作为回归问题提升树算法中的残差近似值，拟合一个回归树。</p><p>输入： 训练数据集$T=\lbrace (x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)\rbrace$, $x_{i} \in \mathcal{X} \subseteq \mathbf{R}^{n}$,$\mathcal{X}$为输入空间， $\mathcal{Y} \subseteq \mathbf{R}$; 损失函数$L(y,f(x))$<br>输出： 回归树$\hat f(x)$</p><ol><li>初始化</li></ol><p>$$
f_{0}(x)=\arg \min _{c} \sum_{i=1}^{N} L\left(y_{i}, c\right)
$$</p><ol start=2><li>对 $m=1，2，\cdots, M$</li></ol><p>(1) 对 $i=1，2，\cdots, N$计算</p><p>$$
r_{m i}=-\left[\frac{\partial L\left(y_{i}, f\left(x_{i}\right)\right)}{\partial f\left(x_{i}\right)}\right]_{f(x)=f_{m-1}(x)}
$$</p><p>(2) 对$r_{mi}$拟合一个回归树，得到第$m$颗树的节点区域$R_{mj}$</p><p>(3) 对$j=1,2,\cdots, J$, 计算</p><p>$$
c_{m j}=\arg \min _{c} \sum_{x_{i} \in R_{m j}} L\left(y_{i}, f_{m-1}\left(x_{i}\right)+c\right)
$$</p><p>(4)更新</p><p>$$
f_{m}(x)=f_{m-1}(x)+\sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)
$$</p><ol start=3><li>得到回归树</li></ol><p>$$
\hat{f}(x)=f_{M}(x)=\sum_{m=1}^{M} \sum_{j=1}^{J} c_{m j} I\left(x \in R_{m j}\right)
$$</p><p>参考： 李航《统计学习方法》</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-05-05</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://zqfang.github.io/2020-05-05-ml-boosting/ data-title=Boosting data-hashtags="Boosting,Statistical Learning"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://zqfang.github.io/2020-05-05-ml-boosting/ data-hashtag=Boosting><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://zqfang.github.io/2020-05-05-ml-boosting/ data-title=Boosting><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://zqfang.github.io/2020-05-05-ml-boosting/ data-title=Boosting><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://zqfang.github.io/2020-05-05-ml-boosting/ data-title=Boosting><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/boosting/>Boosting</a>,&nbsp;<a href=/tags/statistical-learning/>Statistical Learning</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2020-05-03-ml-hmm/ class=prev rel=prev title="Hidden Markov Model (HMM)"><i class="fas fa-angle-left fa-fw"></i>Hidden Markov Model (HMM)</a>
<a href=/2020-05-30-swift-cheat-sheet/ class=next rel=next title="Swift Cheat Sheet">Swift Cheat Sheet<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=disqus_thread class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zqfang</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://bioninja-1.disqus.com/embed.js defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body></html>