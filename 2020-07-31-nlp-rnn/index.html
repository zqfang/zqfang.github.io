<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>NLP: RNN and Self-attention - My Computational Genomic Playground</title><meta name=Description content="My Computational Genomic Playground"><meta property="og:title" content="NLP: RNN and Self-attention"><meta property="og:description" content="Backpropagation Through Time Long Short-Term Memory  Delete information from the context that is no longer needed: Forget Gate f  $$ f_t = \sigma (U_f h_{t-1} + W_f X_t) $$
$$ k_t = c_{t-1} \odot f_t $$
Compute the actual information we need to extract from the previous hidden stat and current inputs  $$ g_t = \tanh (U_g h_{t-1} + W_g x_t) $$"><meta property="og:type" content="article"><meta property="og:url" content="https://zqfang.github.io/2020-07-31-nlp-rnn/"><meta property="og:image" content="https://zqfang.github.io/logo.png"><meta property="article:published_time" content="2020-07-31T00:00:00+00:00"><meta property="article:modified_time" content="2020-07-31T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zqfang.github.io/logo.png"><meta name=twitter:title content="NLP: RNN and Self-attention"><meta name=twitter:description content="Backpropagation Through Time Long Short-Term Memory  Delete information from the context that is no longer needed: Forget Gate f  $$ f_t = \sigma (U_f h_{t-1} + W_f X_t) $$
$$ k_t = c_{t-1} \odot f_t $$
Compute the actual information we need to extract from the previous hidden stat and current inputs  $$ g_t = \tanh (U_g h_{t-1} + W_g x_t) $$"><meta name=application-name content="Pleiades"><meta name=apple-mobile-web-app-title content="Pleiades"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://zqfang.github.io/2020-07-31-nlp-rnn/><link rel=prev href=https://zqfang.github.io/2020-07-26-dl-gnn/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"NLP: RNN and Self-attention","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zqfang.github.io\/2020-07-31-nlp-rnn\/"},"image":["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"NLP","wordcount":544,"url":"https:\/\/zqfang.github.io\/2020-07-31-nlp-rnn\/","datePublished":"2020-07-31T00:00:00+00:00","dateModified":"2020-07-31T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/zqfang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"zqfang"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/publication/>Publication </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/ title=About>About </a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/categories/>Categories</a><a class=menu-item href=/publication/>Publication</a><a class=menu-item href=/portfolio/>Portfolio</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/about/ title=About>About</a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">NLP: RNN and Self-attention</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class=post-category>included in <a href=/categories/nature-language-processing/><i class="far fa-folder fa-fw"></i>Nature Language Processing</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-07-31>2020-07-31</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;544 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;3 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#backpropagation-through-time>Backpropagation Through Time</a></li><li><a href=#long-short-term-memory>Long Short-Term Memory</a></li><li><a href=#gated-recurrent-units>Gated Recurrent Units</a></li><li><a href=#attention-mechanism>Attention mechanism</a></li><li><a href=#self-attention>Self-Attention</a></li><li><a href=#transformer>Transformer</a></li><li><a href=#reference>Reference</a></li></ul></nav></div></div><div class=content id=content><h2 id=backpropagation-through-time>Backpropagation Through Time</h2><h2 id=long-short-term-memory>Long Short-Term Memory</h2><ol><li>Delete information from the context that is no longer needed: <code>Forget Gate</code> f</li></ol><p>$$
f_t = \sigma (U_f h_{t-1} + W_f X_t)
$$</p><p>$$
k_t = c_{t-1} \odot f_t
$$</p><ol start=2><li>Compute the actual information we need to extract from the previous hidden stat and current inputs</li></ol><p>$$
g_t = \tanh (U_g h_{t-1} + W_g x_t)
$$</p><ol start=3><li>Select the information to add to the current context: <code>Add Gate</code> i</li></ol><p>$$
i_t = \sigma (U_i h_{t-1} + W_i X_t)
$$</p><p>$$
j_t = g_{t} \odot i_t
$$</p><ol start=4><li>Get new context vector</li></ol><p>$$
c_t = j_t + k_t
$$</p><ol start=5><li><code>Output Gate</code> o: decide what information is required for the current hiddent state (as opposed to what information need to be preseved for future decicions)</li></ol><p>$$
o_t = \sigma (U_o h_{t-1} + W_o x_t)
$$</p><p>$$
h_t = o_t \odot \tanh (c_t)
$$</p><h2 id=gated-recurrent-units>Gated Recurrent Units</h2><p>GRU ease the tranning burden by dispensing with the use of a separate context vector, and by reducing the number of gates to 2:</p><ol><li>a reset gate, $r$: decide which aspects of the previous hidden state are relevant to the current context and what can be ignored.</li></ol><p>$$
r_t = \sigma (U_r h_{t-1} + W_r x_t)
$$</p><p>Then computing an intermediate representation for the new hidden stat at time $t$</p><p>$$
\tilde h_t = \tanh (U(r_t \odot h_{t-1}) + Wx_t)
$$</p><ol start=2><li>an update gate, $z$: detemine which aspects of the new intermedicate representation will be used directly and which aspects of the previous stat need to be preseverd for future use</li></ol><p>$$
z_t = \sigma (U_z h_{t-1} + W_z x_t)
$$</p><p>$$
h_t = (1- z_t)h_{t-1} + z_t \tilde h_t
$$</p><h2 id=attention-mechanism>Attention mechanism</h2><p>Consider Encoder to Deconder Network, a decoder</p><p>$$
h_i^d = g(\hat y_{i-1}, h_{i-1}^d, c_i)
$$</p><ol><li>computing context vector $c_i$: a vector of scores that capture the relevance of each encoder hidden state to the decoder state captured in $h_{i-1}^d$. That&rsquo;s, at each state $i$ during decoding, we&rsquo;ll compute $score(h_{i-1}^d, h_j^e)$ for each encoder state $j$. Recall similarity</li></ol><p>$$
score(h_{i-1}^d, h_j^e) = h_{i-1}^d \cdot h_j^e
$$</p><ol start=2><li>make a more robust similarity score by adding a learnable weights, $W_s$:</li></ol><p>$$
score(h_{i-1}^d, h_j^e) = h_{i-1}^d W_s h_j^e
$$</p><ol start=3><li>normalize the scores</li></ol><p>$$
\begin{aligned}
\alpha_{ij} &= \operatorname{softmax} (score(h_{i-1}^d, h_j^e)) \cr
&= \frac {\exp (score(h_{i-1}^d, h_j^e))} {\sum_k score(h_{i-1}^d, h_j^e)}
\end{aligned}
$$</p><ol start=4><li>finally, give $\alpha$,</li></ol><p>$$
c_i = \sum_j \alpha_{ij}h_j^e
$$</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/nlp/encoder-decoder.png data-srcset="/images/nlp/encoder-decoder.png, /images/nlp/encoder-decoder.png 1.5x, /images/nlp/encoder-decoder.png 2x" data-sizes=auto alt=/images/nlp/encoder-decoder.png title=attention></p><h2 id=self-attention>Self-Attention</h2><ol><li><p>create 3 vectors from each of the encoders&rsquo; input vector, a <code>Query</code> vector, a <code>Key</code> vector and a <code>Value</code> vector, then multiplying the embedding (of word) <code>X</code></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/nlp/self-attention-1.png data-srcset="/images/nlp/self-attention-1.png, /images/nlp/self-attention-1.png 1.5x, /images/nlp/self-attention-1.png 2x" data-sizes=auto alt=/images/nlp/self-attention-1.png title=attention1></p></li><li><p>calculate a score by taking the dot product of the <code>Query</code> with the <code>Key</code></p></li><li><p>divide the scores by the square root of the dimension of the key vector (a more stable gradients), then pass the result grought a softmax.</p></li><li><p>multiply each <code>Value</code> vector by the softmax score</p></li><li><p>sum up the weighted value vectors</p></li></ol><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/nlp/self-attention-2.png data-srcset="/images/nlp/self-attention-2.png, /images/nlp/self-attention-2.png 1.5x, /images/nlp/self-attention-2.png 2x" data-sizes=auto alt=/images/nlp/self-attention-2.png title=attention2></p><ol start=6><li><strong>multi-head attention</strong>: to focus on different region and give &ldquo;representation subspace&rdquo;</li></ol><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/nlp/self-attention-3.png data-srcset="/images/nlp/self-attention-3.png, /images/nlp/self-attention-3.png 1.5x, /images/nlp/self-attention-3.png 2x" data-sizes=auto alt=/images/nlp/self-attention-3.png title=multiheads></p><h2 id=transformer>Transformer</h2><p>A transformer of two stacked encoder and decoder looks like this</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/nlp/transformers.png data-srcset="/images/nlp/transformers.png, /images/nlp/transformers.png 1.5x, /images/nlp/transformers.png 2x" data-sizes=auto alt=/images/nlp/transformers.png title=transformer></p><ol><li><p>transformer use <code>positoinal encoding</code> vector to representing the order of the sequence. It follows a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence.</p></li><li><p>transformer use <code>LayerNorm</code></p></li></ol><h2 id=reference>Reference</h2><p><a href=https://jalammar.github.io/illustrated-transformer/ target=_blank rel="noopener noreffer">transformer</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-07-31</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://zqfang.github.io/2020-07-31-nlp-rnn/ data-title="NLP: RNN and Self-attention" data-hashtags=NLP><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://zqfang.github.io/2020-07-31-nlp-rnn/ data-hashtag=NLP><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://zqfang.github.io/2020-07-31-nlp-rnn/ data-title="NLP: RNN and Self-attention"><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://zqfang.github.io/2020-07-31-nlp-rnn/ data-title="NLP: RNN and Self-attention"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://zqfang.github.io/2020-07-31-nlp-rnn/ data-title="NLP: RNN and Self-attention"><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/nlp/>NLP</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2020-07-26-dl-gnn/ class=prev rel=prev title="Graph Neural Network"><i class="fas fa-angle-left fa-fw"></i>Graph Neural Network</a></div></div><div id=comments><div id=disqus_thread class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zqfang</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://bioninja-1.disqus.com/embed.js defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body></html>