<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=x-ua-compatible content="IE=edge, chrome=1"><title>Graph: GCN and GAT - My Computational Genomic Playground</title><meta name=Description content="My Computational Genomic Playground"><meta property="og:title" content="Graph: GCN and GAT"><meta property="og:description" content="Graph Convolutional Network and Graph Attention
Why deep graph encoder ? Limitations of Shallow Encoders (e.g. node2vec)
 $O( | V | )$ parameters are needed:  No sharing of parameters between nodes Every node has its own unique embedding   Inherently &ldquo;transductive&rdquo;:  Can not generate embeddings for nodes that are not seen during training   Do not incorporate node features  Many graphs have features that we can and should leverage    Graph Convolutional Network Could get embedding for unseen nodes!"><meta property="og:type" content="article"><meta property="og:url" content="https://zqfang.github.io/2020-12-12-ml-gcn-gat/"><meta property="og:image" content="https://zqfang.github.io/logo.png"><meta property="article:published_time" content="2020-12-11T00:00:00+00:00"><meta property="article:modified_time" content="2020-12-11T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://zqfang.github.io/logo.png"><meta name=twitter:title content="Graph: GCN and GAT"><meta name=twitter:description content="Graph Convolutional Network and Graph Attention
Why deep graph encoder ? Limitations of Shallow Encoders (e.g. node2vec)
 $O( | V | )$ parameters are needed:  No sharing of parameters between nodes Every node has its own unique embedding   Inherently &ldquo;transductive&rdquo;:  Can not generate embeddings for nodes that are not seen during training   Do not incorporate node features  Many graphs have features that we can and should leverage    Graph Convolutional Network Could get embedding for unseen nodes!"><meta name=application-name content="Pleiades"><meta name=apple-mobile-web-app-title content="Pleiades"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://zqfang.github.io/2020-12-12-ml-gcn-gat/><link rel=prev href=https://zqfang.github.io/2020-12-12-ml-node-classififcation/><link rel=next href=https://zqfang.github.io/2020-12-12-dl-graph-generation/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Graph: GCN and GAT","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zqfang.github.io\/2020-12-12-ml-gcn-gat\/"},"image":["https:\/\/zqfang.github.io\/images\/Apple-Devices-Preview.png"],"genre":"posts","keywords":"Deep Learning, Graph","wordcount":1082,"url":"https:\/\/zqfang.github.io\/2020-12-12-ml-gcn-gat\/","datePublished":"2020-12-11T00:00:00+00:00","dateModified":"2020-12-11T00:00:00+00:00","license":"This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher":{"@type":"Organization","name":"xxxx","logo":"https:\/\/zqfang.github.io\/images\/avatar.png"},"author":{"@type":"Person","name":"zqfang"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':('auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark'))&&document.body.setAttribute('theme','dark');</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/publication/>Publication </a><a class=menu-item href=/portfolio/>Portfolio </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/ title=About>About </a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i></span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="My Computational Genomic Playground"><span class=header-title-pre><span>&#8711;</span></span>Pleiades <span class=header-title-post><i class="fas fa-terminal"></i></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i></a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i></a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/>Posts</a><a class=menu-item href=/categories/>Categories</a><a class=menu-item href=/publication/>Publication</a><a class=menu-item href=/portfolio/>Portfolio</a><a class=menu-item href=/tags/>Tags</a><a class=menu-item href=/about/ title=About>About</a><a class=menu-item href=https://github.com/zqfang title=GitHub rel="noopener noreffer" target=_blank><i class="fab fa-github fa-fw"></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">Graph: GCN and GAT</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>zqfang</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning-with-graph/><i class="far fa-folder fa-fw"></i>Machine Learning with Graph</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2020-12-11>2020-12-11</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1082 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;6 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#why-deep-graph-encoder->Why deep graph encoder ?</a></li><li><a href=#graph-convolutional-network>Graph Convolutional Network</a><ul><li><a href=#training>Training</a></li><li><a href=#graphsage-generalized-neigborhood-aggregation>GraphSAGE: Generalized neigborhood aggregation</a></li></ul></li><li><a href=#graph-attention-network>Graph Attention Network</a><ul><li><a href=#simple-neighorhood-aggregation>Simple Neighorhood Aggregation</a></li><li><a href=#graph-convolutional-operator>Graph convolutional operator</a></li><li><a href=#attention-strategy>Attention strategy</a></li></ul></li><li><a href=#pytorch-geometric>PyTorch Geometric</a><ul><li><a href=#principal>Principal</a></li><li><a href=#gcn>GCN</a></li><li><a href=#graphsage>GraphSAGE</a></li><li><a href=#gat>GAT</a></li></ul></li><li><a href=#reference>Reference</a></li></ul></nav></div></div><div class=content id=content><p>Graph Convolutional Network and Graph Attention</p><h2 id=why-deep-graph-encoder->Why deep graph encoder ?</h2><p>Limitations of Shallow Encoders (e.g. node2vec)</p><ul><li>$O( | V | )$ parameters are needed:<ul><li>No sharing of parameters between nodes</li><li>Every node has its own unique embedding</li></ul></li><li>Inherently &ldquo;transductive&rdquo;:<ul><li>Can not generate embeddings for nodes that are not seen during training</li></ul></li><li>Do not incorporate node features<ul><li>Many graphs have features that we can and should leverage</li></ul></li></ul><h2 id=graph-convolutional-network>Graph Convolutional Network</h2><p>Could get embedding for unseen nodes!!!</p><p><strong>Aggreate Neighbors</strong>: Generate node embeddings based on local network neighborhoods.</p><ol><li><p>Intuition: Nodes aggregate information from their neighors using neural networks.
<img class=lazyload src=/svg/loading.min.svg data-src=/images/ml/gcn1.png data-srcset="/images/ml/gcn1.png, /images/ml/gcn1.png 1.5x, /images/ml/gcn1.png 2x" data-sizes=auto alt=/images/ml/gcn1.png title=GCN1></p></li><li><p>Computation graph: defined by networkneigborhood
<img class=lazyload src=/svg/loading.min.svg data-src=/images/ml/gcn2.png data-srcset="/images/ml/gcn2.png, /images/ml/gcn2.png 1.5x, /images/ml/gcn2.png 2x" data-sizes=auto alt=/images/ml/gcn2.png title=GCN2></p></li><li><p>Layers: Model can be of arbitary depth</p><ul><li>Nodes have embeddings at each layer</li><li>Layer-0 embedding: Node $u$'s input feature $x_u$</li><li>Layer-K embedding gets information from nodes that are K hops away</li></ul></li></ol><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/ml/gcn3.png data-srcset="/images/ml/gcn3.png, /images/ml/gcn3.png 1.5x, /images/ml/gcn3.png 2x" data-sizes=auto alt=/images/ml/gcn3.png title=GCN3></p><h3 id=training>Training</h3><ol><li>Unsuperised training<ul><li>use only the graph structure</li><li>&ldquo;similar: nodes have similar embeddings</li><li>unspuervise loss function could based on:<ul><li>Random walks (node2vec, DeepWalk, struc2vec)</li><li>Graph factorization</li><li>Node proximity in the graph</li></ul></li></ul></li><li>Supervised training<ul><li>directly train the mode for a supervised task (e.g. node classification)</li></ul></li></ol><h3 id=graphsage-generalized-neigborhood-aggregation>GraphSAGE: Generalized neigborhood aggregation</h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/images/ml/gcn4.png data-srcset="/images/ml/gcn4.png, /images/ml/gcn4.png 1.5x, /images/ml/gcn4.png 2x" data-sizes=auto alt=/images/ml/gcn4.png title=GCN4></p><p>where,</p><ul><li>$W_k$, ${B_k}$ is learnable weighted matrices.</li><li>$h_v^0 = x_v$: initial 0-th layer embeddings are equal to node features.</li><li>$\mathbf{h}_{v}^{k-1}$: previous layer embedding of $v$.</li><li>$\mathbf{z} _v = \mathbf{h} _{v}^{k}$: Embedding after $k$ layers of neigborhood aggregation</li><li>$\sigma$: Non-linearity, e.g., ReLU</li></ul><p>AGG:</p><ul><li><p>Mean: take a weighted average of neighbors
$$\text{AGG} = \sum _{u \in N(v)} \frac{ \mathbf{h} _{u}^{k-1} } { | N(v) | }$$</p></li><li><p>Pool: Transform neighbor vectors and apply symmetric vector function
$$\text{AGG} = \gamma ([\mathbf{Q}\mathbf{h}_{u}^{k-1}, \forall u \in (N(v))])$$</p><ul><li>$\gamma$: element-wise mean/max</li></ul></li><li><p>LSTM: Apply LSTM to reshuffled of neighbors
$$\text{AGG} = \text{LSTM} ([\mathbf{h}_{u}^{k-1}, \forall u \in \pi(N(v))])$$</p></li></ul><h2 id=graph-attention-network>Graph Attention Network</h2><h3 id=simple-neighorhood-aggregation>Simple Neighorhood Aggregation</h3><p>The formula</p><p>$$
\mathbf{h} _{v}^{k} = \sigma (\mathbf{W} _{k} \sum _{u \in N(v)} \frac{ \mathbf{h} _{u}^{k-1}}{ | N(v) | } + \mathbf{B} _{k} \mathbf{h} _{v}^{k-1} )
$$</p><p>Equivalently rewritten in vector form:</p><p>$$
\mathbf{H} ^{(l+1)} = \sigma ( \mathbf{H} ^{(l)} \mathbf{W} _{0}^{l} + \tilde{\mathbf{A}} \mathbf{H} ^{(l)} \mathbf{W} _{0}^{l})
$$</p><p>with $\tilde{A} = D^{- \frac{1}{2}} A D^{- \frac{1}{2}}$.</p><h3 id=graph-convolutional-operator>Graph convolutional operator</h3><ul><li>Aggregates messages across neighborhoods. $N(v)$</li><li>$\alpha _{vu} = \frac{1}{ | N(v) |}$ is the <strong>weighting factor</strong> of node $u$'s message to node $v$</li><li>$\alpha _{vu}$ id defined explicitly based on the structural properties of the graph</li><li>All neighbors $u \in N(v$ are equally important to node $v$)</li></ul><h3 id=attention-strategy>Attention strategy</h3><p>Allows for (implicitly) specifying different importance values ($\alpha_{vu}$) to different neighbors</p><p>Compute embedding $\mathbf{h}_{v}^{k}$ of each node in the graph following:</p><ul><li>Nodes attend over their neighorhoods&rsquo; message</li><li>Implicitly specifying different weights to different nodes in a neighborhood</li></ul><ol><li><p>Attention Mechanism</p><ul><li>Compute attention coefficients $e_{vu}$ across pairs of nodes $u$, $v$ based on their messages:
$$e_{vu} = a (\mathbf{W}_{k} \mathbf{h}_{u}^{k-1}, \mathbf{W}_{k} \mathbf{h}_{v}^{k-1})$$</li><li>Normalize coefficients using the softmax function in order to comparable across different neighorhoods:</li></ul><p>$$
\begin{aligned}
\alpha_{vu} &=\frac{ \exp (e_{v u} )} {\sum_{k \in N(v)} \exp (e_{v k} )} \cr
\boldsymbol{h}_{v}^{k} &=\sigma (\sum_{u \in N(v)} \alpha_{v u} \boldsymbol{W}_{k} \boldsymbol{h}_{u}^{k-1} )
\end{aligned}
$$</p></li><li><p>Multi-head attention</p><ul><li>Attention operations in a given layer are independently replicated R times (each replica with different parameters)</li><li>Outputs are aggregated (by concatenating or adding)</li></ul></li></ol><h2 id=pytorch-geometric>PyTorch Geometric</h2><h3 id=principal>Principal</h3><p>Message passing graph neural networks can be descriibe as</p><p>$$
\mathbf{x}_{i}^{(k)}=\gamma^{(k)} (\mathbf{x} _{i}^{(k-1)}, \square _{j \in \mathcal{N}(i)} \phi^{(k)}(\mathbf{x} _{i}^{(k-1)}, \mathbf{x} _{j}^{(k-1)}, \mathbf{e} _{i, j}))
$$</p><ul><li>$x^{k-1}$: node features of node $i$ in layer ($k$−1)</li><li>$e_{j,i} \in R^D$: (optional) edge features from node $j$ to node $i$</li><li>$\square$: aggregation method (permutation invariant function). i.e., mean, sum, max</li><li>$\gamma$, $\phi$: differentiable functions, such as MLP</li></ul><p>In Pytorch Geometric, <code>self.propagate</code> will do the following:</p><ol><li>execute <code>self.message</code>, $\phi$, transform neigbor&rsquo;s message</li><li>execute <code>self.aggregate</code>, $\square$, aggregate message from neigbors</li><li>execute <code>self.update</code>, $\gamma$, aggregated message and self message transformation.</li></ol><h3 id=gcn>GCN</h3><p>For <a href=https://arxiv.org/abs/1609.02907 target=_blank rel="noopener noreffer">GCN</a>,</p><p>$$X^{\prime} = \tilde{D} ^{- \frac{1}{2}} \tilde{A} \tilde{D}^{- \frac{1}{2}} X \Theta$$</p><p>Acutally, it is same as</p><p>$$
\mathbf{x} _{i}^{(k)}=\sum _{j \in \mathcal{N}(i) \cup\lbrace i \rbrace } \frac{1}{\sqrt{\operatorname{deg}(i)} \cdot \sqrt{\operatorname{deg}(j)}} \cdot (\mathbf{\Theta} \cdot \mathbf{x} _{j}^{(k-1)} )
$$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>GCNConv</span><span class=p>(</span><span class=n>pyg_nn</span><span class=o>.</span><span class=n>MessagePassing</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>GCNConv</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>aggr</span><span class=o>=</span><span class=s1>&#39;add&#39;</span><span class=p>)</span> <span class=c1># aggregation </span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lin</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>)</span>
    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>edge_index</span><span class=p>):</span>
        <span class=c1># add self loop</span>
        <span class=n>edge_index</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_self_loops</span><span class=p>(</span><span class=n>edge_index</span><span class=p>,</span> <span class=n>num_nodes</span><span class=o>=</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
        <span class=c1># initial feature transform</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lin</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>propagate</span><span class=p>(</span><span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)),</span> <span class=n>x</span><span class=o>=</span> <span class=n>x</span><span class=p>)</span>
    <span class=k>def</span> <span class=nf>message</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x_j</span><span class=p>,</span> <span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=p>):</span>
        <span class=c1># \phi </span>
        <span class=n>row</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=n>edge_index</span>
        <span class=n>deg</span> <span class=o>=</span> <span class=n>pyg_utils</span><span class=o>.</span><span class=n>degree</span><span class=p>(</span><span class=n>row</span><span class=p>,</span> <span class=n>size</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>x_j</span><span class=o>.</span><span class=n>dtype</span><span class=p>)</span>
        <span class=n>deg_inv_sqrt</span> <span class=o>=</span> <span class=n>deg</span><span class=o>.</span><span class=n>pow</span><span class=p>(</span><span class=o>-</span><span class=mf>0.5</span><span class=p>)</span>
        <span class=n>norm</span> <span class=o>=</span> <span class=n>deg_inv_sqrt</span><span class=p>[</span><span class=n>row</span><span class=p>]</span><span class=o>*</span><span class=n>deg_inv_sqrt</span><span class=p>[</span><span class=n>col</span><span class=p>]</span>
        <span class=k>return</span> <span class=n>norm</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span><span class=n>x_j</span>
    <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>aggr_out</span><span class=p>):</span>
        <span class=c1># \gamma</span>
        <span class=k>return</span> <span class=n>aggr_out</span>
</code></pre></td></tr></table></div></div><h3 id=graphsage>GraphSAGE</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>GraphSage</span><span class=p>(</span><span class=n>pyg_nn</span><span class=o>.</span><span class=n>MessagePassing</span><span class=p>):</span>
    <span class=s2>&#34;&#34;&#34;Non-minibatch version of GraphSage.&#34;&#34;&#34;</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>reducer</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>,</span> 
                 <span class=n>normalize_embedding</span><span class=o>=</span><span class=bp>True</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>GraphSage</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>aggr</span><span class=o>=</span><span class=s1>&#39;mean&#39;</span><span class=p>)</span> <span class=c1># Aggerate</span>

        <span class=k>if</span> <span class=n>normalize_embedding</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>normalize_emb</span> <span class=o>=</span> <span class=bp>True</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>edge_index</span><span class=p>):</span>
        <span class=n>num_nodes</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>propagate</span><span class=p>(</span><span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>num_nodes</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>),</span> <span class=n>x</span><span class=o>=</span><span class=n>x</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>message</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x_j</span><span class=p>,</span> <span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=p>):</span>
         <span class=c1># \phi</span>
         <span class=k>return</span> <span class=n>x_j</span>

    <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>aggr_out</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># \gamma: concate and transform</span>
        <span class=n>concat_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>x</span><span class=p>,</span> <span class=n>aggr_out</span><span class=p>),</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>aggr_out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>agg_lin</span><span class=p>(</span><span class=n>concat_out</span><span class=p>))</span> 
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>normalize_emb</span><span class=p>:</span>
            <span class=n>aggr_out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>normalize</span><span class=p>(</span><span class=n>aggr_out</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> 
        <span class=k>return</span> <span class=n>aggr_out</span>
</code></pre></td></tr></table></div></div><h3 id=gat>GAT</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=k>class</span> <span class=nc>GAT</span><span class=p>(</span><span class=n>pyg_nn</span><span class=o>.</span><span class=n>MessagePassing</span><span class=p>):</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>num_heads</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>concat</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span>
                 <span class=n>dropout</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>GAT</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>aggr</span><span class=o>=</span><span class=s1>&#39;add&#39;</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>in_channels</span> <span class=o>=</span> <span class=n>in_channels</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>out_channels</span> <span class=o>/</span> <span class=n>num_heads</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>heads</span> <span class=o>=</span> <span class=n>num_heads</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>concat</span> <span class=o>=</span> <span class=n>concat</span> 
        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>dropout</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>lin</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span> <span class=o>*</span> <span class=n>num_heads</span><span class=p>)</span> <span class=c1># TODO</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>att</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span> <span class=o>*</span> <span class=mi>2</span><span class=p>))</span> <span class=c1># TODO</span>

        <span class=k>if</span> <span class=n>bias</span> <span class=ow>and</span> <span class=n>concat</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>heads</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span><span class=p>))</span>
        <span class=k>elif</span> <span class=n>bias</span> <span class=ow>and</span> <span class=ow>not</span> <span class=n>concat</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span><span class=p>))</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>register_parameter</span><span class=p>(</span><span class=s1>&#39;bias&#39;</span><span class=p>,</span> <span class=bp>None</span><span class=p>)</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>att</span><span class=p>)</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>


    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=bp>None</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>size</span> <span class=ow>is</span> <span class=bp>None</span> <span class=ow>and</span> <span class=n>torch</span><span class=o>.</span><span class=n>is_tensor</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
            <span class=n>edge_index</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>remove_self_loops</span><span class=p>(</span><span class=n>edge_index</span><span class=p>)</span>
            <span class=n>edge_index</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>add_self_loops</span><span class=p>(</span><span class=n>edge_index</span><span class=p>,</span> <span class=n>num_nodes</span><span class=o>=</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
        <span class=c1># \theta </span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lin</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> 
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>propagate</span><span class=p>(</span><span class=n>edge_index</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>size</span><span class=p>,</span> <span class=n>x</span><span class=o>=</span><span class=n>x</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>message</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>edge_index_i</span><span class=p>,</span> <span class=n>x_i</span><span class=p>,</span> <span class=n>x_j</span><span class=p>,</span> <span class=n>size_i</span><span class=p>):</span>
        <span class=c1># \phi compute attention coefficient</span>
        <span class=n>x_i</span> <span class=o>=</span> <span class=n>x_i</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span><span class=p>)</span>
        <span class=n>x_j</span> <span class=o>=</span> <span class=n>x_j</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span><span class=p>)</span>
        <span class=n>alpha</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x_i</span><span class=p>,</span> <span class=n>x_j</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>att</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>alpha</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>leaky_relu</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>)</span>
        <span class=n>alpha</span> <span class=o>=</span> <span class=n>pyg_utils</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>edge_index_i</span><span class=p>,</span> <span class=n>size_i</span><span class=p>)</span>

        <span class=n>alpha</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>,</span> <span class=n>training</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>x_j</span> <span class=o>*</span> <span class=n>alpha</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>aggr_out</span><span class=p>):</span>
        <span class=c1># \gamma multi-head</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>concat</span> <span class=ow>is</span> <span class=bp>True</span><span class=p>:</span>
            <span class=n>aggr_out</span> <span class=o>=</span> <span class=n>aggr_out</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>heads</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_channels</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>aggr_out</span> <span class=o>=</span> <span class=n>aggr_out</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=bp>None</span><span class=p>:</span>
            <span class=n>aggr_out</span> <span class=o>=</span> <span class=n>aggr_out</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>bias</span>
        <span class=k>return</span> <span class=n>aggr_out</span>
</code></pre></td></tr></table></div></div><h2 id=reference>Reference</h2><p><a href=http://cs224w.stanford.edu target=_blank rel="noopener noreffer">Jure Leskovec, Stanford CS224W: Machine Learning with Graphs</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-12-11</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://zqfang.github.io/2020-12-12-ml-gcn-gat/ data-title="Graph: GCN and GAT" data-hashtags="Deep Learning,Graph"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://zqfang.github.io/2020-12-12-ml-gcn-gat/ data-hashtag="Deep Learning"><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://zqfang.github.io/2020-12-12-ml-gcn-gat/ data-title="Graph: GCN and GAT"><i class="fab fa-hacker-news fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://zqfang.github.io/2020-12-12-ml-gcn-gat/ data-title="Graph: GCN and GAT"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@2.14.0/icons/line.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://zqfang.github.io/2020-12-12-ml-gcn-gat/ data-title="Graph: GCN and GAT"><i class="fab fa-weibo fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/deep-learning/>Deep Learning</a>,&nbsp;<a href=/tags/graph/>Graph</a></section><section><span><a href=javascript:void(0); onclick=window.history.back();>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/2020-12-12-ml-node-classififcation/ class=prev rel=prev title="Graph: Semi-supervised Node Classification"><i class="fas fa-angle-left fa-fw"></i>Graph: Semi-supervised Node Classification</a>
<a href=/2020-12-12-dl-graph-generation/ class=next rel=next title="Graph: GraphRNN">Graph: GraphRNN<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=disqus_thread class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2020 - 2021</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>zqfang</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i></a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css><script type=text/javascript src=https://bioninja-1.disqus.com/embed.js defer></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body></html>