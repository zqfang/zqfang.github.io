<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Machine Learning with Graphs - Category - My Computational Genomic Playground</title><link>https://zqfang.github.io/categories/machine-learning-with-graphs/</link><description>Machine Learning with Graphs - Category - My Computational Genomic Playground</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 07 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://zqfang.github.io/categories/machine-learning-with-graphs/" rel="self" type="application/rss+xml"/><item><title>Graph: MessagePassing in Pytorch Geometric</title><link>https://zqfang.github.io/2021-08-07-graph-pyg/</link><pubDate>Sat, 07 Aug 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-08-07-graph-pyg/</guid><description>How to implement a custom MessagePassing layer in Pytorch Geometric (PyG) ?
Before you start, something you need to know.
special_arguments: e.g. x_j, x_i aggregation: scatter_add, scatter_mean, scatter_min, scatter_max PyG MessagePassing framework only works for node_graph. MessagePassing in PyTorch Geometric Principal Message passing graph neural networks can be described as</description></item><item><title>Graph: Foundation</title><link>https://zqfang.github.io/2021-04-19-graph-foundation/</link><pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-04-19-graph-foundation/</guid><description>Basics.
Definition Graph: $G(V, E)$ Adjacency Matrix: $A$ Degree: $D$, the number of nodes that are adjacent to $v$. Neighbors: $N$, the number of $N_{v(i)}$ is equal to $D_{v(i)}$. Connectivity Walk A walk on a graph is an alternating sequence of nodes and edges, starting with a node and ending with a node where each edge is incident with the nodes immediately preceding and following it.</description></item><item><title>Graph: GraphRNN</title><link>https://zqfang.github.io/2020-12-12-dl-graph-generation/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-dl-graph-generation/</guid><description>Why is it interesting Drug discovery discovery highly drug-like molecules complete an existing molecule to optimize a desired property Discovering novel structures Network science Why is it hard Large and variable output Non-unique representations $n$-node graph can be represented in $n!$ ways Hard to compute/optimize objective functions Complex dependencies edge fprmation has long-range dependencies Graph Generative Model Given: Graphs sampled from $p_{data}(G)$</description></item><item><title>Graph: GCN and GAT</title><link>https://zqfang.github.io/2020-12-12-ml-gcn-gat/</link><pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-ml-gcn-gat/</guid><description>Graph Convolutional Network and Graph Attention
Why deep graph encoder ? Limitations of Shallow Encoders (e.g. node2vec)
$O( | V | )$ parameters are needed: No sharing of parameters between nodes Every node has its own unique embedding Inherently &amp;ldquo;transductive&amp;rdquo;: Can not generate embeddings for nodes that are not seen during training Do not incorporate node features Many graphs have features that we can and should leverage Graph Convolutional Network Could get embedding for unseen nodes!</description></item><item><title>Graph: Semi-supervised Node Classification</title><link>https://zqfang.github.io/2020-12-12-ml-node-classififcation/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-ml-node-classififcation/</guid><description>Problems: Given a network with labels on some nodes, how do we assign labels to all other nodes in the network?
classification label of an object $O$ in network may depend on:
Features of $O$ Labels of the objects in $O$'s neighborhood Features of objects in $O$'s neigborhood Collective classification models Reational clasifiers Iterative classifications Loopy belief propagation Intuition Simultaneous classification of interlinked nodes using correlations</description></item><item><title>Graph: Node2Vec</title><link>https://zqfang.github.io/2020-12-06-ml-node2vec/</link><pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-06-ml-node2vec/</guid><description>Node Embedings are learnt in the same way as word2vec (skip-gram model)
However, graphs could be (un)directed, (un)weighted, (a)cyclic and are basically much more complex than the strucure of a sequence&amp;hellip;
So how do we generate &amp;ldquo;corpus&amp;rdquo; from a graph ?
Random walk on the graph Given a graph and a starting point, we select a neighbor of it at random; then we select a neigbor of this point at random, and move to it, etc.</description></item><item><title>Graph Neural Network: review</title><link>https://zqfang.github.io/2020-07-26-dl-gnn/</link><pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-07-26-dl-gnn/</guid><description>More about Graph Neural Network
Algebra presentation of Graphs 1. Adjacency matrix $$ A_{i j}= \begin{cases} 1 &amp;amp; \text { if }\lbrace v_{i}, v_{j}\rbrace \in E \text { and } i \neq j \cr 0 &amp;amp; \text { otherwise } \end{cases} $$
2. Degree matrix: D is a diagonal matrix, where $$ D_{ii} = d(v_i) $$</description></item><item><title>Graph Neural Networks: basics</title><link>https://zqfang.github.io/2020-07-25-dl-geometric/</link><pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-07-25-dl-geometric/</guid><description>Introduction of Graph Neural Networks
Data Eculidean Structure Data: image, video, voice &amp;hellip; easy to find adjacent neighbors easy to define distance Non-Eculidean data: Graph, Manifold hard to define adjacent neighbors or the numbers of adjacent nodes varies. means hard to define distance, convolution &amp;hellip; Embed (project) Non-Eculidean Data into Eculidean Space using geometric deep learning</description></item></channel></rss>