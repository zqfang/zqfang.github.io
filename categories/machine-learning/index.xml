<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Machine Learning - Category - My Computational Genomic Playground</title><link>https://zqfang.github.io/categories/machine-learning/</link><description>Machine Learning - Category - My Computational Genomic Playground</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 05 May 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://zqfang.github.io/categories/machine-learning/" rel="self" type="application/rss+xml"/><item><title>Boosting</title><link>https://zqfang.github.io/2020-05-05-ml-boosting/</link><pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-05-05-ml-boosting/</guid><description>提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习过个分类器，并将这些分类器线性</description></item><item><title>Hidden Markov Model (HMM)</title><link>https://zqfang.github.io/2020-05-03-ml-hmm/</link><pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-05-03-ml-hmm/</guid><description>隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。 HMM在语音识别、自然</description></item><item><title>Latent semantic analysis (LSA)</title><link>https://zqfang.github.io/2020-04-30-ml-lsa/</link><pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-04-30-ml-lsa/</guid><description>潜在语义分析（LSA）是一种非监督学习方法，用于文本话题分析。其特点是通过矩阵分解发现文本于单词之间</description></item><item><title>Conditional random field (CRF)</title><link>https://zqfang.github.io/2020-04-29-ml-crf/</link><pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-04-29-ml-crf/</guid><description>CRF条件随机场，可应用于标注问题 概率无向图模型Probabilistic undirected graphical model(Markov random field) 是一个可以由无向</description></item><item><title>How to do deep learning using custom Jupyter kernels on Sherlock</title><link>https://zqfang.github.io/2020-02-10-ml-sherlock/</link><pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-02-10-ml-sherlock/</guid><description>A recipe for interactive computing using custom Jupyter kernels on Stanford&amp;rsquo;s Sherlock.
Setting up custom conda environment on Sherlock&amp;rsquo;s login node 1. Download and install Miniconda 1 2 3 4 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh # install bash Miniconda3-latest-Linux-x86_64.sh conda config --set always_yes yes 2. Install jupyter notebook/lab and secure your notebooks with a password 1 2 3 4 # install the default py3 kernel for jupyter notebook conda install ipython jupyter notebook jupyterlab # add password jupyter notebook password 3.</description></item><item><title>Statistical Modeling and Inference</title><link>https://zqfang.github.io/2020-01-30-ml-bayes/</link><pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-30-ml-bayes/</guid><description>A breif review over the foundations of statistical inference
Statistical Models and Inference statistical inference: a formal approach to characterizing a random phenomenon using observations, either by providing a description of a past phenomenon or by giving some predictions about future phenomenon of similar nature.
1. Statistical Models The first step in statistical inference is to specify a statistical model, under some simplifying assumptions (i.</description></item><item><title>Loss function for multi-label classification</title><link>https://zqfang.github.io/2020-01-29-ml-lossfunc/</link><pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-29-ml-lossfunc/</guid><description>Multi-label classification, tasks commonly be seen on health record data (multi symptoms).
Loss function design:
Multi binary cross-entropy
each class has a binary output
Label smoothing, another regularization technique
It’s designed to make the model a little bit less certain of it’s decision by changing a little bit its target: instead of wanting to predict 1 for the correct class and 0 for all the others, we ask it to predict 1-ε for the correct class and ε for all the others, with ε a (small) positive number and N the number of classes.</description></item><item><title>Expectation Maximization</title><link>https://zqfang.github.io/2020-01-26-ml-em/</link><pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-26-ml-em/</guid><description>Maximum Likelihood Estimation Gaussian Mixture Model Expectation Maximization 1. Probability and likelihood likehood &amp;amp; maximum likehood 在非正式场合似然（likelihood）和概率（Probabilit</description></item><item><title>Mento Carlos</title><link>https://zqfang.github.io/2020-01-26-ml-montecarlo/</link><pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-26-ml-montecarlo/</guid><description>蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算</description></item></channel></rss>