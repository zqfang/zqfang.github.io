<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Machine Learning - Category - My Computational Genomic Playground</title><link>https://zqfang.github.io/categories/machine-learning/</link><description>Machine Learning - Category - My Computational Genomic Playground</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 26 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://zqfang.github.io/categories/machine-learning/" rel="self" type="application/rss+xml"/><item><title>Graph Neural Network</title><link>https://zqfang.github.io/2020-07-26-dl-gnn/</link><pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-07-26-dl-gnn/</guid><description>More about Graph Neural Network
Algebra presentation of Graphs 1. Adjacency matrix $$ A_{i j}= \begin{cases} 1 &amp;amp; \text { if }\lbrace v_{i}, v_{j}\rbrace \in E \text { and } i \neq j \cr 0 &amp;amp; \text { otherwise } \end{cases} $$
2. Degree matrix: D is a diagonal matrix, where $$ D_{ii} = d(v_i) $$</description></item><item><title>Geometric Deep Learning</title><link>https://zqfang.github.io/2020-07-25-dl-geometric/</link><pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-07-25-dl-geometric/</guid><description>Introduction of Graph Neural Networks
Data Eculidean Structure Data: image, video, voice &amp;hellip; easy to find adjacent neighbors easy to define distance Non-Eculidean data: Graph, Manifold hard to define adjacent neighbors or the numbers of adjacent nodes varies. means hard to define distance, convolution &amp;hellip; Embed (project) Non-Eculidean Data into Eculidean Space using geometric deep learning</description></item><item><title>Markov Chain Mento Carlo (MCMC)</title><link>https://zqfang.github.io/2020-01-26-ml-montecarlo/</link><pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-26-ml-montecarlo/</guid><description>蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算</description></item><item><title>Singular Value Decomposition (SVD)</title><link>https://zqfang.github.io/2020-06-06-ml-svd/</link><pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-06-06-ml-svd/</guid><description>奇异值分解(SVD)是一种矩阵因子分解方法，在线性代数中，被广泛应用。 奇异值分解也是一种矩阵近似的方</description></item><item><title>Boosting</title><link>https://zqfang.github.io/2020-05-05-ml-boosting/</link><pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-05-05-ml-boosting/</guid><description>提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习n个分类器，并将这些分类器线性</description></item><item><title>Hidden Markov Model (HMM)</title><link>https://zqfang.github.io/2020-05-03-ml-hmm/</link><pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-05-03-ml-hmm/</guid><description>隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。 HMM在语音识别、自然</description></item><item><title>Latent semantic analysis (LSA)</title><link>https://zqfang.github.io/2020-04-30-ml-lsa/</link><pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-04-30-ml-lsa/</guid><description>潜在语义分析（LSA）是一种非监督学习方法，用于文本话题分析。其特点是通过矩阵分解发现文本于单词之间</description></item><item><title>Conditional random field (CRF)</title><link>https://zqfang.github.io/2020-04-29-ml-crf/</link><pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-04-29-ml-crf/</guid><description>CRF条件随机场，可应用于标注问题 概率无向图模型Probabilistic undirected graphical model(Markov random field) 是一个可以由无向</description></item><item><title>How to do deep learning using custom Jupyter kernels on Sherlock</title><link>https://zqfang.github.io/2020-02-10-ml-sherlock/</link><pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-02-10-ml-sherlock/</guid><description>A recipe for interactive computing using custom Jupyter kernels on Stanford&amp;rsquo;s Sherlock.
Setting up custom conda environment on Sherlock&amp;rsquo;s login node 1. Download and install Miniconda 1 2 3 4 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh # install bash Miniconda3-latest-Linux-x86_64.sh conda config --set always_yes yes 2. Install jupyter notebook/lab and secure your notebooks with a password 1 2 3 4 # install the default py3 kernel for jupyter notebook conda install ipython jupyter notebook jupyterlab # add password jupyter notebook password 3.</description></item><item><title>Statistical Modeling and Inference</title><link>https://zqfang.github.io/2020-01-30-ml-bayes/</link><pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-01-30-ml-bayes/</guid><description>A breif review over the foundations of statistical inference
Statistical Models and Inference statistical inference: a formal approach to characterizing a random phenomenon using observations, either by providing a description of a past phenomenon or by giving some predictions about future phenomenon of similar nature.
1. Statistical Models The first step in statistical inference is to specify a statistical model, under some simplifying assumptions (i.</description></item></channel></rss>