---
title: 'Conditional random field (CRF)'
date: 2020-04-29
categories: ["Machine Learning"]
tags: ["Probabilistic Graphical Model"]
comments: true
markup: "mmark"
math: true
---

CRF条件随机场，可应用于标注问题

概率无向图模型Probabilistic undirected graphical model(Markov random field)  
是一个可以由无向图表示的联合概率分布

### 0. 概率图模型分类
概率图模型（probabilistic graphical model, PGM），是一种学习任务的框架描述，它将学习任务归结为计算变量的概率分布。

按照概率图中变量关系的不同，概率图模型可以大致分为两类：

1. 贝叶斯网络：有向图模型，使用有向无环图表达关系（通常，变量间存在显式的因果关系）
2. 马尔科夫网络：无向图模型，使用无图表达关系（通常，变量间存有关系，但是难以显式表达）
3. 同时存有有向边和无向边的模型，如条件随机场（conditional random field）和链图（chain graph），单独看做一类局部有向模型。


贝叶斯网络
  - 可以分为静态贝叶斯网络和动态贝叶斯网络。相比于静态贝叶斯网络，动态（dynamic）贝叶斯网络主要用于时序数据建模（如语音识别、自然语言处理、轨迹数据挖掘等）。其中，一种结构最简单的动态贝叶斯网络就是隐马尔可夫模型（hidden markov model, HMM）。一般来说，贝叶斯网络中每一个结点都对应于一个先验概率分布或者条件概率分布，因此整体的联合分布可以直接分解为所有单个结点所对应的分布的乘积。

马尔可夫网
  - 由于变量之间没有明确的因果关系，它的联合概率分布通常会表达为一系列势函数（potential function）的乘积。通常情况下，这些乘积的积分并不等于1，因此，还要对其进行归一化才能形成一个有效的概率分布——这一点往往在实际应用中给参数估计造成非常大的困难。

按照表示的抽象级别不同，概率图模型可以分为：
  - 基于随机变量的概率图模型，如贝叶斯网、马尔可夫网、条件随机场和链图等
  - 基于**模板**的概率图模型．这类模型根据应用场景不同又可分为两种：
    - 暂态模型，包括动态贝叶斯网（Dynamic Bayesian Network, DBN）和状态观测模型，其中状态观测模型又包括线性动态系统（Linear Dynamic System, LDS）如卡尔曼滤波器，还有隐马尔可夫模型（Hidden Markov Model, HMM）；
    - 对象关系领域的概率图模型，包括盘模型（Plate Model，PM）、概率关系模型（Probabilistic Relational Model, PRM）和关系马尔可夫网（Relational Markov Network, RMN）。

参考：[概率图模型总览](https://longaspire.github.io/blog/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E6%80%BB%E8%A7%88/)



### 1. 模型定义
概率图模型：由图（Graph）表示的概率分布。

令无向图 G = (V, E) 表示联合概率分布P(Y)，即G中，
  - 节点$v \in V$ 表示随机变量$Y_{v}, Y=\left(Y_{v}\right)_{v \in V}$；
  - 边$e \in E$表示随机变量之间的概率依赖关系

无向图表示的随机变量存在:
  - 成对马可夫性 pariwise Markov property
      - 指任意两个没有边连接的节点，在给定随机变量组（其他所有节点）条件下，该两节点是条件独立
  - 局部马可夫性 local Markov property
  - 全局马可夫性 global Markov property

概率无向图模型：无向图 $G = (V, E)$ 表示联合概率分布 $P(Y)$，如果联合概率分布 $P(Y)$ 满足成对、局部或全局马可夫性，就称此联合概率分布 $P(Y)$ 为概率无向图模型，或马可夫随机场

团（clique）：图G中任何两个节点均有边连接的节点子集
最大团（maximal clique）：团C中不能再加任何一个节点使它成为更大的团，则称最大团

### 2. 条件随机场

条件随机场指给定随机变量X条件下， 随机变量Y的马可夫随机场。

#### 2.1 条件随机场：  

若随机变量$Y$构成一个由无向图$G = (V, E)$表示的马可夫随机场，即

$$
P\left(Y_{v} | X, Y_{w}, w \neq v\right)=P\left(Y_{v} | X, Y_{w}, w \sim v\right)
$$

对于任意节点$v$成立， 则称条件概率分布$P(Y\vert X)$为条件随机场。其中$w \sim v$表示在图$G = (V, E)$中与节点$v$有边连接的所有节点$w$， $w \neq v$表示节点v以外的所有节点。

#### 2.2 线性链条件随机场（ linear chain conditional random field）

线性链条件随机场也是对数线性模型(log linear model)，定义为：

$$
P\left(Y_{i} | X, Y_{1}, \cdots, Y_{i-1}, Y_{i+1}, \cdots, Y_{n}\right)=P\left(Y_{i} | X, Y_{i-1}, Y_{i+1}\right) \\
i = 1,2, \cdots, n
$$


在条件概率模型$P(Y\vert X)$中， $Y$是输出变量，表示标记序列（状态序列，参见HMM）；$X$使输入变量，表示需要标注的观测序列。利用训练集，通过极大似然估计或正则化的极大似然估计得到条件概率模型$\hat{P}(Y\vert X)$;预测时，对于给定输入序列$x$，求条件概率$\hat{P}(Y\vert X)$最大的输出序列$\hat{y}$。



#### 2.3 条件随机场的参数化形式

设$P(Y\vert X)$为线性链条件随机场，X取值为x， Y取值为y的条件概率具有如下形式：


$$
P(y | x)=\frac{1}{Z(x)} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, l} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right)
$$

其中，

$$
Z(x)=\sum_{y} \exp \left(\sum_{i, k} \lambda_{k} t_{k}\left(y_{i-1}, y_{i}, x, i\right)+\sum_{i, l} \mu_{l} s_{l}\left(y_{i}, x, i\right)\right)
$$


式中，$t_{k}$和$s_{l}$是特征函数, $\lambda_{k}$和$\mu_{l}$是对应的权值。 $Z(x)$是规范化因子。在所有可能输出的序列上进行求和操作。

关于**特征函数**： 
  - 令$t_{k}$是定义在边上的特征函数，称为转移特征，依赖当前和前一个位置
  - 令$s_{l}$是定义在节点上的特征函数，称为状态特征，依赖当前位置
  - 特征函数$t_{k}$和$s_{l}$取值0或1；满足条件取1，反之0
  - 条件随机长完全由特征函数$t_{k}$和$s_{l}$， 和对应的权值$\lambda_{k}$和$\mu_{l}$确定。


#### 2.4 条件随机场的矩阵形式

对于观测序列x的每个位置，y在m个标记中取值，可以定义一个m阶的矩阵随机变量：

$$
M_{i}(x) = [ M_{i}(y_{i-1}, y_{i}|x)]
$$

矩阵随机变量元素为

$$
\begin{aligned}
&M_{i}\left(y_{i-1}, y_{i} | x\right)=\exp \left(W_{i}\left(y_{i-1}, y_{i} | x\right)\right)\\
&W_{i}\left(y_{i-1}, y_{i} | x\right)=\sum_{k=1}^{K} w_{k} f_{k}\left(y_{i-1}, y_{i}, x, i\right)
\end{aligned}
$$


这里$w_k$为

$$
w_{k}=\left\{\begin{array}{ll}
\lambda_{k}, & k=1,2, \cdots, K_{1} \\
\mu_{l}, & k=K_{1}+l ; l=1,2, \cdots, K_{2}
\end{array}\right.
$$


和$f_k$为

$$
f_{k}\left(y_{i-1}, y_{i}, x, i\right)=\left\{\begin{array}{ll}
t_{k}\left(y_{i-1}, y_{i}, x, i\right), & k=1,2, \cdots, K_{1} \\
s_{l}\left(y_{i}, x, i\right), & k=K_{1}+l ; l=1,2, \cdots, K_{2}
\end{array}\right.
$$



于是，条件概率$P_{w}(y \vert x)$:

$$
P_{w}(y | x)=\frac{1}{Z_{w}(x)} \prod_{i=1}^{n+1} M_{i}\left(y_{i-1}, y_{i} | x\right)
$$

其中，

$$
Z_{w}(x)=\left[M_{1}(x) M_{2}(x) \cdots M_{n+1}(x)\right]_{\mathrm{start}, \mathrm{stop}}
$$

注， 
$y_{0} = \mathrm{start}$，表示开始状态； 
$y_{n+1} = \mathrm{stop}$， 表示终止状态


参考： 李航《统计学习方法》