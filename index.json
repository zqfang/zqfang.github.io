[{"categories":["Statistic"],"content":"Bayesian Data Analysis Notes","date":"2022-02-10","objectID":"/2022-08-10-bda1/","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: Basics","uri":"/2022-08-10-bda1/"},{"categories":["Statistic"],"content":"The three steps of Bayesian data analysis Setting up a full probability model—a joint probability distribution for all observable and unobservable quantities in a problem. Conditioning on observed data: calculating and interpreting the appropriate posterior distribution—the conditional probability distribution of the unobserved quantities of ultimate interest, given the observed data. Evaluating the ﬁt of the model and the implications of the resulting posterior distribution. Bayes’ rule $$ p (\\theta, y) = p(\\theta)p(y | \\theta)$$ $p (\\theta, y)$: joint probability distribution for $\\theta$ and $y$ . $p (\\theta)$: prior distribution $p (\\theta | y)$: sampling distritbuion (data distitbution). Bayesian Inference Simply conditioning on the known value of the data $y$, using the basic property of conditional probability known as Bayes’s rule, yields the posterior density: $$ p(\\theta \\mid y)=\\frac{p(\\theta, y)}{p(y)}=\\frac{p(\\theta) p(y \\mid \\theta)}{p(y)} $$ where $p (y) = \\sum_{\\theta} p(\\theta) p(y \\mid \\theta)$ , and the sum is over all possible values of $\\theta$. or $p(y) = \\int p(\\theta) p(y \\mid \\theta) d \\theta$. $p(y)$ is fixed, thus can be considered a constant, yielding the unnormalized posterior density : $$ p(\\theta \\mid y) \\propto p(\\theta) p(y \\mid \\theta) $$ Prediction To make inferences about an unknown observable, often valled predictive inferences. The distribution of the unknown but observablle $y$ is $$ p(y) = \\int p(y, \\theta) d \\theta = \\int p(\\theta) p (y \\mid \\theta) d \\theta $$ This is often called the marginal distibution of $y$, but a more informative name is the prior predictive distritbuition. prior because it is not conditional on a previous observvation of the process, and predictive because it is the distribution for a quantity that is observable. $\\tilde{y}$ : posterior predictive distribution. posterior because it is conditional on the observed $y$ and predictive because it is a prediction for an observable $\\tilde{y}$. $$ \\begin{aligned} p(\\tilde{y} \\mid y) \u0026=\\int p(\\tilde{y}, \\theta \\mid y) d \\theta \\\\ \u0026=\\int p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y) d \\theta \\\\ \u0026=\\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d \\theta \\end{aligned} $$ Likelihood and odds ratios Using Bayes’ rule with a chosen probability model means that the data $y$ affect the posterior inference only through $p(y| \\theta$, which, when regarded as a function of θ, for fixed $y$, is called the likelihood function. In this way Bayesian inference is obeying what is sometimes called the likelihood principle. the ratio of the posterior density $p(\\theta \\mid y)$ evaluated at the points $\\theta_1$ and $\\theta_2$ under a given model is called the posterior odds for $\\theta_1$ compared to $\\theta_2$ $$ \\frac{p\\left(\\theta_{1} \\mid y\\right)}{p\\left(\\theta_{2} \\mid y\\right)}=\\frac{p\\left(\\theta_{1}\\right) p\\left(y \\mid \\theta_{1}\\right) / p(y)}{p\\left(\\theta_{2}\\right) p\\left(y \\mid \\theta_{2}\\right) / p(y)}=\\frac{p\\left(\\theta_{1}\\right)}{p\\left(\\theta_{2}\\right)} \\frac{p\\left(y \\mid \\theta_{1}\\right)}{p\\left(y \\mid \\theta_{2}\\right)} $$ the posterior odds are equal to the prior odds multiplied byu the likelihood ratio. Probability the mathmatical definition of probabilty: probablities are numerical quantities, defined on a set of “outcomes”, that are non-negative, additive over mutually exclusive outcomes, and sum to 1 over all possible mutally exclusive outcomes. In Bayesian statistics, probability is used as the fundamental measure or yardstick of uncertainty. ","date":"2022-02-10","objectID":"/2022-08-10-bda1/:0:0","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: Basics","uri":"/2022-08-10-bda1/"},{"categories":["Statistic"],"content":"Means and variances of conditional distributions mean and variance: $$ \\mathrm{E}(u)=\\int u p(u) d u, \\quad \\operatorname{var}(u)=\\int(u-\\mathrm{E}(u))^{2} p(u) d u $$ variance matrix (covariance matrix) $$ \\operatorname{var}(u)=\\int(u-\\mathrm{E}(u))(u-\\mathrm{E}(u))^{T} p(u) d u $$ The mean of $u$ can be obtained by averaging the conditional mean over the marginal distributionof $v$. $$ \\mathrm{E}(u)= \\mathrm{E}(\\mathrm{E}( u \\mid v)) $$ and variance $$ \\operatorname{var}(u)=\\mathrm{E}(\\operatorname{var}(u \\mid v))+\\operatorname{var}(\\mathrm{E}(u \\mid v)) $$ Summarizing inference by simulation Simulation forms a central part of much applied Bayesian analysis, because of the relative ease with which samples can often be generated from a probability distribution, even when the density function cannot be explicitly integrated. Another advantage of simulation is that extremely large or small simulated values often ﬂag a problem with model speciﬁcation or parameterization that might not be noticed if estimates and probability statements were obtained in analytic form Generating values from a probability distribution is often straightforward with modern computing techniques based on (pseudo)random number sequences. ","date":"2022-02-10","objectID":"/2022-08-10-bda1/:1:0","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: Basics","uri":"/2022-08-10-bda1/"},{"categories":["Statistic"],"content":"Sampling using the inverse cumulative distribution function A method for sampling from discrete and continuous distributuions using the cumalative distribution function or cdf, $F$, of a one-dimensional distribution, $p(v)$, is defined by $$ \\begin{aligned} F\\left(v_{*}\\right) \u0026=\\operatorname{Pr}\\left(v \\leq v_{*}\\right) \\\\ \u0026= \\begin{cases}\\sum_{v \\leq v_{*}} p(v) \u0026 \\text { if } p \\text { is discrete } \\\\ \\int_{-\\infty}^{v_{*}} p(v) d v \u0026 \\text { if } p \\text { is continuous. }\\end{cases} \\end{aligned} $$ The inverse cdf can be used to obtain random samples from the distribution p, as follows: Draw a random value, $U$, from the uniform distribution on [0, 1], using a table of random numbers. Let $v = F^{-1} (U)$. The value $v$ will be a random draw from $p$, ","date":"2022-02-10","objectID":"/2022-08-10-bda1/:2:0","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: Basics","uri":"/2022-08-10-bda1/"},{"categories":["Statistic"],"content":"Simulation of posterior and posterior predictive quantities In practice, we are most often interested in simulating draws from the posterior distribution of the model parameters $\\theta$, and perhaps from the posterior predictive distribution of unknown observables $\\tilde{y}$. Results from a set of $S$ simulation draws can be stored in the computer in an array, e.g. $$ \\begin{array}{ccccccc} \\begin{array}{c} \\text { Simulation } \\\\ \\text { draw } \\end{array} \u0026 \\multicolumn{2}{c}{\\text { Parameters }} \u0026 \\multicolumn{3}{c}{\\text { Predictive }} \\\\ \u0026 \\theta_{1} \u0026 \\ldots \u0026 \\theta_{k} \u0026 \\tilde{y}_{1} \u0026 \\ldots \u0026 \\tilde{y}_{n} \\\\ \\hline 1 \u0026 \\theta_{1}^{1} \u0026 \\ldots \u0026 \\theta_{k}^{1} \u0026 \\tilde{y}_{1}^{1} \u0026 \\ldots \u0026 \\tilde{y}_{n}^{1} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\mathrm{S} \u0026 \\theta_{1}^{S} \u0026 \\ldots \u0026 \\theta_{k}^{S} \u0026 \\tilde{y}_{1}^{S} \u0026 \\ldots \u0026 \\tilde{y}_{n}^{S} \\end{array} $$ From these simulated values, we can estimate the posterior distribution of any quantity of interest, such as $\\theta_1 / \\theta_2$. We can estimate the posterior probability of any event, such as $Pr (\\tilde{y}_1 + \\tilde{y}_2) \u003e e^{\\theta_1}$ ","date":"2022-02-10","objectID":"/2022-08-10-bda1/:3:0","tags":["Bayesian Data Analysis"],"title":"Bayesian Data Analysis: Basics","uri":"/2022-08-10-bda1/"},{"categories":["Coding"],"content":"Some codesnape for the usage of Trait ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:0:0","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Trait A trait defines functionality a particular type has and can share with other types. ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:0","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Defined and Implement a Trait pubtraitSummary{fn summarize(\u0026self)-\u003e String;}pubstruct Tweet{pubusername: String,pubcontent: String,pubreply: bool,pubretweet: bool,}implSummaryforTweet{fn summarize(\u0026self)-\u003e String {format!(\"{}: {}\",self.username,self.content)}} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:1","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Default Implementataions pubtraitSummary{fn summarize(\u0026self)-\u003e String {String::from(\"(Read more...)\")}} You could overwrite trait methods when implement structs! ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:2","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Trait as Parameters pubfn notify(item: \u0026implSummary){println!(\"Breaking news! {}\",item.summarize());} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:3","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Trait Bound and inherit \u003cT: Trait1 + Trait2\u003e function\u003cT, U\u003e() -\u003e T where T: Trait1, U: Trait2 Inherit traitB{}traitA: B{} Example pubfn notify\u003cT: Summary\u003e(item: \u0026T){println!(\"Breaking news! {}\",item.summarize());}// multiple trait bound pubfn notify\u003cT: Summary+Display\u003e(item: \u0026T){}// where fn some_function\u003cT,U\u003e(t: \u0026T,u: \u0026U)-\u003e i32 whereT: Display+Clone,U: Clone +Debug,{unimplemented!()} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:4","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Returning Instances that implement Traits -\u003e impl SomeTrait pubtraitSummary{fn summarize(\u0026self)-\u003e String;}pubstruct NewsArticle{pubheadline: String,publocation: String,pubauthor: String,pubcontent: String,}implSummaryforNewsArticle{fn summarize(\u0026self)-\u003e String {format!(\"{}, by {} ({})\",self.headline,self.author,self.location)}}pubstruct Tweet{pubusername: String,pubcontent: String,pubreply: bool,pubretweet: bool,}implSummaryforTweet{fn summarize(\u0026self)-\u003e String {format!(\"{}: {}\",self.username,self.content)}}fn returns_summarizable()-\u003e implSummary{Tweet{username: String::from(\"horse_ebooks\"),content: String::from(\"of course, as you probably already know, people\",),reply: false,retweet: false,}} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:5","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Trait Object Define Box\u003cdyn Draw\u003e \u0026dyn Draw impl\u003cT\u003e SomeStruct\u003cT\u003e where T: Draw traitDraw{fn draw(\u0026self)-\u003e String;}// NOTE: Box\u003cdyn Draw\u003e and \u0026dyn Draw are both worked fn draw1(x: Box\u003cdynDraw\u003e){x.draw();// Deref to . }fn draw2(x: \u0026dynDraw){x.draw();}// NOTE: used in a vec pubstruct Screen{pubcomponents: Vec\u003cBox\u003cdynDraw\u003e\u003e,}implScreen{pubfn run(\u0026self){forcomponentinself.components.iter(){component.draw();}}} use generic pubstruct Screen\u003cT: Draw\u003e{pubcomponents: Vec\u003cT\u003e,}impl\u003cT\u003eScreen\u003cT\u003ewhereT: Draw{pubfn run(\u0026self){forcomponentinself.components.iter(){component.draw();}}} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:6","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Associated Type Note: Associated Type has nothing to do with associated function define inside trait has to be assign a type in impl type Ithem // Item has to be defined in the impl pubtraitIterator{type Item;fn next(\u0026mutself)-\u003e Option\u003cSelf::Item\u003e;} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:7","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Default generic type’s parameter // RHS=Self -\u003e default to its own type traitAdd\u003cRHS=Self\u003e{type Output;fn add(self,rhs: RHS)-\u003e Self::Output;}struct Point{x: i32,y: i32,}implAddforPoint{type Output=Point;// defined here fn add(self,other: Point)-\u003e Point{Point{x: self.x+other.x,y: self.y+other.y,}}}fn main(){assert_eq!(Point{x: 1,y: 0}+Point{x: 2,y: 3},Point{x: 3,y: 3});} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:8","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Call method with same name Struct’s member function has priority! traitPilot{fn fly(\u0026self);}traitWizard{fn fly(\u0026self);}struct Human;implPilotforHuman{fn fly(\u0026self){println!(\"This is your captain speaking.\");}}implWizardforHuman{fn fly(\u0026self){println!(\"Up!\");}}implHuman{fn fly(\u0026self){println!(\"*waving arms furiously*\");}} example fn main(){letperson=Human;Pilot::fly(\u0026person);// call Pilot's fly Wizard::fly(\u0026person);// call Wizard's fly person.fly();// call self.fly. Human's fly } ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:9","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Call method (without \u0026self) with same name use as to limit!!! \u003cDog as Animal\u003e::baby_name() traitAnimal{fn baby_name()-\u003e String;}struct Dog;implDog{fn baby_name()-\u003e String {String::from(\"Spot\")}}implAnimalforDog{fn baby_name()-\u003e String {String::from(\"puppy\")}} fn main(){println!(\"A baby dog is called a {}\",\u003cDogasAnimal\u003e::baby_name());} ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:1:10","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"Vec to Array simple case usendarray::{concatenate,s,Axis,Array,Array2,Array3,arr2,arr3};letvec1=vec![[1,2,3,4],[1,2,3,4]];letarray=Array::from_vec(vec1);// ndim = 1, Nd will flatten into 1d by using from_vec. letarray2=Array2\u003ci64\u003e=arr2(\u0026vec1);// ndim = 2 nested Vecs/Arrays see docs here // you know ahead-of-time the shape of the Array letmutarr=Array2::zeros((2,3));for(i,mutrow)inarr.axis_iter_mut(Axis(0)).enumerate(){// Perform calculations and assign to `row`; this is a trivial example: row.fill(i);}assert_eq!(arr,array![[0,0,0],[1,1,1]]);// you don't know ahead-of-time the shape of the Array // append data to a flat Vec, then conert it using ::from_shape_vec() letncols=3;letmutdata=Vec::new();letmutnrows=0;letarr=Array2::from_shape_vec((nrows,ncols),data)?;// If neither of these options works for you // using Iterator::flatten() then ::from_shape_vec() letnested: Vec\u003cArray2\u003ci32\u003e\u003e=vec![array![[1,2,3],[4,5,6]],array![[7,8,9],[10,11,12]],];letinner_shape=nested[0].dim();letshape=(nested.len(),inner_shape.0,inner_shape.1);letflat: Vec\u003ci32\u003e=nested.iter().flatten().cloned().collect();letarr=Array3::from_shape_vec(shape,flat)?;assert_eq!(arr,array![[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]],]); ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:2:0","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Coding"],"content":"indexing and slicing println!(\"slice) ","date":"2022-02-10","objectID":"/2022-02-16-rust-basics/:3:0","tags":["Rust"],"title":"Rust: Advanced Trait","uri":"/2022-02-16-rust-basics/"},{"categories":["Machine Learning with Graphs"],"content":"Link Prediction Link prediction is a common task in knowledgegraph’s link completeion. Link prediction is usually an unsupervised or self-supervised task, which means that sometimes we need to split the dataset and create corresponding labels on our own. ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"How to prepare train, valid, test datasets ? For link prediction, we will split edges twice Step 1: Assign 2 types of edges in the original graph Message edges: Used for GNN message passing Supervision edges: Use for computing objectives After step 1: Only message edges will remain in the graph Supervision edges are used as supervision for edge predictions made by the model, will not be fed into GNN! Step 2: Split edges into train / validation / test ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Option 1: Inductive setting training / validation / test sets are on different graphs The dataset consists of multiple graphs Each split can only observe the graph(s) within the split. A successful model should generalize to unseen graphs Applicable to node / edge / graph tasks ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:2:1","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Option 2: Transductive training / validation / test sets are on the same graph The dataset consists of one graph The entire graph can be observed in all dataset splits, we only split the labels Only applicable to node / edge prediction tasks ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:2:2","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Code Option 1: PyG’s RandomLinkSplit from torch_geometric.transforms import RandomLinkSplit, RandomNodeSplit ## designed for transductive learning tfs = RandomLinkSplit(is_undirected=True, add_negative_train_samples=True, neg_sampling_ratio=1.0, key = \"edge_label\", # supervision label disjoint_train_ratio=0,# disjoint mode if \u003e 0 # edge_types=None, # for heteroData # rev_edge_types=None, # for heteroData ) train_data, val_data, test_data = tfs(data) # Here, *_data.edge_index denotes the graph structure used for message passing, # *_data.edge_label_index and *_data.edge_label denote the training/evaluation edges and their corresponding labels. ## if inductive learning, need subgraph. e.g from torch_geometric.utils import subgraph train_mask = torch.rand(data.num_nodes) \u003c 0.5 test_mask = ~train_mask train_data = copy.copy(data) train_data.edge_index, _ = subgraph(train_mask, data.edge_index, relabel_nodes=True) train_data.x = data.x[train_mask] test_data = copy.copy(data) test_data.edge_index, _ = subgraph(test_mask, data.edge_index, relabel_nodes=True) test_data.x = data.x[test_mask] Option 2: deepsnap's GraphDataset The GraphDataset is compatible with Pytorch Geometric ! from deepsnap.dataset import GraphDataset from deepsnap.hetero_graph import HeteroGraph hetero = HeteroGraph(H) dataset = GraphDataset([hetero], task='link_pred', edge_train_mode=\"disjoint\", edge_message_ratio=0.8, edge_negative_sampling_ratio=2) dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1]) # dataset could be use for PyG or deepsnap's high-level API Check the all docs here The content blew is almost the same as in colab notebooks. It’s just for easy and quick viewing in any devices. ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:2:3","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"General rules In general, edges in the graph will be splitted to two types: message passing edges: used for GNN message passing supervision edges: used in loss function for backpropagation. Need to include negative sampling edges, the edges not existed in the original graph. DeepSNAP’s GraphDataset will automatically generate labels for all edges. Negative edges: label 0. Positive supervision edges: usually label 1. If the original edges already have labels (started from 0), all the labels will be added by 1. In addition to edges split and negative edge sampling, edges in each of the train, validation and test sets usually need to be disjoint. ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:2:4","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Transductive Link Prediction Split DeepSNAP link prediction contains two main split modes (edge_train_mode: all, disjoin) ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Split Mode: All The figure blew shows the supervision edges in train (blue), validation (red) and test (green) sets. Notice that all original edges in all mode will be included in the supervision edges. To be more specific: At training time: the training supervision edges are same with the training message passing edges. The $\\text{training supervision edges} == \\text{training message passing edges}$ At validation time: the message passing edges are the training message passing edges and training supervision edges (still the training message passing edges in this case). The $\\text{validation supervision edges} \\notin \\text{training supervision edges}$: disjoint with training supervision edges: The $\\text{validation message passing edges} = \\text{training message passing edges} + \\text{training supervision edges}$ At test time: the message passing edges are the union of training message passing edges, training supervision edges, and validation supervision edges. The $\\text{test supervision edges} \\notin \\lbrace \\text{training supervision edges}, \\text{valid supervision edges} \\rbrace$: disjoint with training supervision edges and validation supervision edges. The $\\text{test message passing edges} = \\text{validation supervison edges} + \\text{training message passing edges} + \\text{training supervision edges}$ ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Split Mode: Disjoint The figure blow shows the supervision edges in train (blue), validation (red), test (green) sets and the training message passing edges (grey). Notice that not all original edges in disjoint mode will be included in the supervision edges. To be more specific: At training time: the training supervision edges are disjoint with the training message passing edges. The $\\text{training supervision edges} \\notin \\text{training message passing edges}$ At validation time: the message passing edges are the union of training message passing edges and training supervision edges. Notice that the validation supervision edges are disjoint with training supervision edges. The $\\text{validation message passing edges} = \\text{training message passing edges} + \\text{training supervision edges}$ The $\\text{validation supervision edges} \\notin \\text{training supervision edges}$ At test time: the message passing edges are the training message passing edges, training supervision edges, and validation supervision edges. The test supervision edges are disjoint with training supervision edges and validation supervision edges. The $\\text{test message passing edges} = \\text{validation supervison edges} + \\text{training message passing edges} + \\text{training supervision edges}$ The $\\text{validation supervison edges} \\notin \\lbrace \\text{training supervision edges}, \\text{valid supervision edges} \\rbrace$ ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:3:2","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Inductive Link Prediction Split For inductive link prediction in DeepSNAP, graphs will be splitted to different (train, validation and test) sets. Each graph in the same set will have message passing edges and supervision edges (which are same in this case). But supervision and message passing edges in each graph in different sets are disjoint. ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Negative Sampling Ratio and Resampling For link_pred task, DeepSNAP will automatically and randomly sample negative edges when: The dataset is splitted to several datasets, such that one dataset is splitted to train, validation and test. The Batch of the graph is called or used (this will resample all negative edges). The number or ratio of negative edges can be controlled by specifying the edge_negative_sampling_ratio, which has the default value 1. The resampling can be disabled by setting resample_negatives to be False. The example below shows how to set different number or ratio of negative edges. Training set negative edges will be resampled when the Batch object is called However, to reduce the computation cost, the validation and test sets negative edges will not be resampled. dataset = GraphDataset([dg], task=task) dataset_train, dataset_val, dataset_test = dataset.split( transductive=True, split_ratio=[0.8, 0.1, 0.1]) dataloaders = { \"train\": DataLoader( dataset_train, collate_fn=Batch.collate([]), shuffle=True), \"val\": DataLoader( dataset_val, collate_fn=Batch.collate([]), shuffle=True), \"test\": DataLoader( dataset_test, collate_fn=Batch.collate([]), shuffle=True), } ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:5:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Message Passing Ratio Here is an example of adjusting the number of message passing edges and supervision edges in disjoint mode. We can control the number of edges by adjusting the edge_message_ratio, which defines the ratio between message-passing edges and supervision edges in the training set. ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:6:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Node Split See also dataset split for node classification ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:7:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Reference DeepSnap Jure Leskovec, Stanford CS224W: Machine Learning with Graphs ","date":"2021-08-12","objectID":"/2021-08-12-graph-linkpredict/:8:0","tags":["Deep Learning","Graph"],"title":"Graph: Train, valid, and test dataset split for link prediction","uri":"/2021-08-12-graph-linkpredict/"},{"categories":["Machine Learning with Graphs"],"content":"Mini-batch Sampling Real world graphs can be very large with millions or even billions of nodes and edges. But the naive full-batch implementation of GNN cannot be feasible to these large-scale graphs. Two frequently used methods are summarized here: Neighbor Sampling (Hamilton et al. (2017)) torch_geometric.loader.NeighborLoader Cluster-GCN (Chiang et al. (2019)). torch_geometric.loader.ClusterLoader Other samplers in PyG HGTLoader GraphSAINTLoader Overall, all heterogeneous graph loaders will produce a HeteroData object as output, holding a subset of the original data, and mainly differ in the way their sampling procedures works ","date":"2021-08-11","objectID":"/2021-08-11-graph-minibatch/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Mini-batch sampling in large-scale graphs","uri":"/2021-08-11-graph-minibatch/"},{"categories":["Machine Learning with Graphs"],"content":"Neighbor Sampling with Different Ratios In PyG 2.0, NeighborLoader allows for mini-batch training of GNNs on large-scale graphs where full-batch training is not feasible #import torch_geometric.transforms as T from torch_geometric.loader import NeighborLoader train_loader = NeighborLoader( data, # Sample 15 neighbors for each node and each edge type for 2 iterations: num_neighbors= {key: [15] * 2 for key in data.edge_types}[15] * 2 # heterograph # Use a batch size of 128 for sampling training nodes of type \"paper\": batch_size=128, input_nodes='paper', data['paper'].train_mask, ) batch = next(iter(train_loader)) Please see the full deepsnap’s docs here The content blew is almost the same as in colab notebooks. It’s just for easy and quick viewing in any devices. ","date":"2021-08-11","objectID":"/2021-08-11-graph-minibatch/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: Mini-batch sampling in large-scale graphs","uri":"/2021-08-11-graph-minibatch/"},{"categories":["Machine Learning with Graphs"],"content":"1. Neighbor Sampling sampling code using networkX as backend def sample_neighbors(nodes, G, ratio, all_nodes): # This fuction takes a set of nodes, a NetworkX graph G and neighbor sampling ratio. # It will return sampled neighbors (unioned with input nodes) and edges between neighbors = set() edges = [] for node in nodes: neighbors_list = list(nx.neighbors(G, node)) # We only sample the (ratio * number of neighbors) neighbors num = int(len(neighbors_list) * ratio) if num \u003e 0: # Random shuffle the neighbors random.shuffle(neighbors_list) neighbors_list = neighbors_list[:num] for neighbor in neighbors_list: # Add neighbors neighbors.add(neighbor) edges.append((neighbor, node)) return neighbors, neighbors.union(all_nodes), edges def nodes_to_tensor(nodes): # This function transform a set of nodes to node index tensor node_label_index = torch.tensor(list(nodes), dtype=torch.long) return node_label_index def edges_to_tensor(edges): # This function transform a set of edges to edge index tensor edge_index = torch.tensor(list(edges), dtype=torch.long) edge_index = torch.cat([edge_index, torch.flip(edge_index, [1])], dim=0) edge_index = edge_index.permute(1, 0) return edge_index def relable(nodes, labeled_nodes, edges_list): # Relable the nodes, labeled_nodes and edges_list relabled_edges_list = [] sorted_nodes = sorted(nodes) node_mapping = {node : i for i, node in enumerate(sorted_nodes)} for orig_edges in edges_list: relabeled_edges = [] for edge in orig_edges: relabeled_edges.append((node_mapping[edge[0]], node_mapping[edge[1]])) relabled_edges_list.append(relabeled_edges) relabeled_labeled_nodes = [node_mapping[node] for node in labeled_nodes] relabeled_nodes = [node_mapping[node] for node in nodes] return relabled_edges_list, relabeled_nodes, relabeled_labeled_nodes def neighbor_sampling(graph, K=2, ratios=(0.1, 0.1, 0.1)): # This function takes a DeepSNAP graph, K the number of GNN layers, and neighbor # sampling ratios for each layer. This function returns relabeled node feature, # edge indices and node_label_index assert K + 1 == len(ratios) labeled_nodes = graph.node_label_index.tolist() random.shuffle(labeled_nodes) num = int(len(labeled_nodes) * ratios[-1]) if num \u003e 0: labeled_nodes = labeled_nodes[:num] nodes_list = [set(labeled_nodes)] edges_list = [] all_nodes = labeled_nodes for k in range(K): # Get nodes and edges from the previous layer nodes, all_nodes, edges = \\ sample_neighbors(nodes_list[-1], graph.G, ratios[len(ratios) - k - 2], all_nodes) nodes_list.append(nodes) edges_list.append(edges) # Reverse the lists nodes_list.reverse() edges_list.reverse() relabled_edges_list, relabeled_all_nodes, relabeled_labeled_nodes = \\ relable(all_nodes, labeled_nodes, edges_list) node_index = nodes_to_tensor(relabeled_all_nodes) # All node features that will be used node_feature = graph.node_feature[node_index] edge_indices = [edges_to_tensor(edges) for edges in relabled_edges_list] node_label_index = nodes_to_tensor(relabeled_labeled_nodes) log = \"Sampled {} nodes, {} edges, {} labeled nodes\" print(log.format(node_feature.shape[0], edge_indices[0].shape[1] // 2, node_label_index.shape[0])) return node_feature, edge_indices, node_label_index ","date":"2021-08-11","objectID":"/2021-08-11-graph-minibatch/:2:1","tags":["Deep Learning","Graph"],"title":"Graph: Mini-batch sampling in large-scale graphs","uri":"/2021-08-11-graph-minibatch/"},{"categories":["Machine Learning with Graphs"],"content":"Sampling with Clusters Instead of the Neighbor Sampling, we can use another approach, subgraph (cluster) sampling, to scale up GNNs. This approach is proposed in Cluster-GCN (Chiang et al. (2019)). see PyG’s torch_geometric.loader.ClusterLoader ","date":"2021-08-11","objectID":"/2021-08-11-graph-minibatch/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: Mini-batch sampling in large-scale graphs","uri":"/2021-08-11-graph-minibatch/"},{"categories":["Machine Learning with Graphs"],"content":"1. Partition the Graph into Clusters Three community detection / partition algorithms to partition the graph into different clusters: Kernighan–Lin algorithm (bisection) Clauset-Newman-Moore greedy modularity maximization Louvain algorithm To make the training more stable, we discard the cluster that has less than 10 nodes. use networkx as backend # the package name on pip is python-louvain but it is imported as community in python # pip install python-louvain import community as community_louvain def preprocess(G, node_label_index, method=\"louvain\"): graphs = [] labeled_nodes = set(node_label_index.tolist()) if method == \"louvain\": community_mapping = community_louvain.best_partition(G, resolution=10) communities = {} for node in community_mapping: comm = community_mapping[node] if comm in communities: communities[comm].add(node) else: communities[comm] = set([node]) communities = communities.values() elif method == \"bisection\": communities = nx.algorithms.community.kernighan_lin_bisection(G) elif method == \"greedy\": communities = nx.algorithms.community.greedy_modularity_communities(G) for community in communities: nodes = set(community) subgraph = G.subgraph(nodes) # Make sure each subgraph has more than 10 nodes if subgraph.number_of_nodes() \u003e 10: node_mapping = {node : i for i, node in enumerate(subgraph.nodes())} subgraph = nx.relabel_nodes(subgraph, node_mapping) # Get the id of the training set labeled node in the new graph train_label_index = [] for node in labeled_nodes: if node in node_mapping: # Append relabeled labeled node index train_label_index.append(node_mapping[node]) # Make sure the subgraph contains at least one training set labeled node if len(train_label_index) \u003e 0: dg = Graph(subgraph) # Update node_label_index dg.node_label_index = torch.tensor(train_label_index, dtype=torch.long) graphs.append(dg) return graphs ","date":"2021-08-11","objectID":"/2021-08-11-graph-minibatch/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: Mini-batch sampling in large-scale graphs","uri":"/2021-08-11-graph-minibatch/"},{"categories":["Machine Learning with Graphs"],"content":"How to implement a custom MessagePassing layer in Pytorch Geometric (PyG) ? Before you start, something you need to know. special_arguments: e.g. x_j, x_i, edge_index_j, edge_index_i aggregate: scatter_add, scatter_mean, scatter_min, scatter_max PyG MessagePassing framework only works for node_graph. x = ... # Node features of shape [num_nodes, num_features] edge_index = ... # Edge indices of shape [2, num_edges] x_j = x[edge_index[0]] # Source node features [num_edges, num_features] x_i = x[edge_index[1]] # Target node features [num_edges, num_features] ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"MessagePassing in PyTorch Geometric ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"Principal Message passing graph neural networks can be described as $$ \\mathbf{x}_{i}^{(k)}=\\gamma^{(k)} (\\mathbf{x} _{i}^{(k-1)}, \\square _{j \\in \\mathcal{N}(i)} \\phi^{(k)}(\\mathbf{x} _{i}^{(k-1)}, \\mathbf{x} _{j}^{(k-1)}, \\mathbf{e} _{i, j})) $$ $x^{k-1}$: node features of node $i$ in layer ($k$−1) $e_{j,i} \\in R^D$: (optional) edge features from node $j$ to node $i$ $\\square$: aggregation method (permutation invariant function). i.e., mean, sum, max $\\gamma$, $\\phi$: differentiable functions, such as MLP In Pytorch Geometric, self.propagate will do the following: execute self.message, $\\phi$: construct the message of node pairs (x_i, x_j) execute self.aggregate, $\\square$, aggregate message from neigbors. Internally, the aggregate works like this from torch_scatter import scatter_add num_nodes = 4 embed_size = 5 src = torch.randint(0, num_nodes, (num_nodes, embed_size)) src_index = torch.tensor([0,0,0,1,1,2,3,3]) tmp = torch.index_select(src, 0, src_index) # shape [num_edges, embed_size ] print(\"input: \") print(tmp) target_index = torch.tensor([1,2,3,3,0,0,0,2]) aggr = scatter_add(tmp, target_index, 0) # shape [num_nodes, embed_size] # print(\"agg out:\") print(aggr) # behind the sence, torch.scatter_add is used # repeat the edge_index index2 = target_index.expand((embed_size, target_index.size(0))).T # same result by using torch.scatter_add aggr2 = torch.zeros(num_nodes, embed_size, dtype=tmp.dtype).scatter_add(0, index2, tmp) see torch_scatter execute self.update, $\\gamma$. update embedding of Node i with aggregated message , $i \\in \\mathcal{V}$ e.g. aggregated neighbor message and self message ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:1:1","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"Aggregate ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:1:2","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"Propogate when propogate is called, the excution as follow: __check_input__(**kwargs): check SparseTensor or not __collect__(**kwargs): Construct the message of node i, $i \\in \\mathcal{V}$ Take care the direction of message. flow='source_to_target: $j \\rightarrow i$, that’s $(j, i) \\in \\mathcal{E}$ flow='target_to_source: $i \\rightarrow j$, that’s $(i, j) \\in \\mathcal{E}$ construct message data with variable name suffixed with _i, _j x_j, x_i with shape: [num_edges, embed_size] Even more, try z_i, z_j if you’ve defined them in propogate. # example code # src: node_attr # args: arugments defined in `message()`, e.g, x_j, x_i # 1. direction i, j = (1, 0) if self.flow == 'source_to_target' else (0, 1) out={} # 2. construct message x_j, x_i. Both with shape [num_edge, embed_size] for arg in args: if arg.endswith(\"_i\") or arg.endswith(\"_j\"): dim = j if arg[-2:] == '_j' else i index = edge_index[dim] out[arg] = src.index_select(0, index) out['edge_index_i'] = edge_index[i] out['edge_index_j'] = edge_index[j] # return out generate edge_index_j, edge_index_i return a dict message(**kwargs): arguments: the output of __collect__, and kwargs in propogate. e.g x_j, edge_attr, size construct node i's messages by using variables suffixed with _i, _j. that’s why your see arugments with suffix _i, _j aggregate(**kwargs) arguments: the output of step 3: message, and kwargs in propogate aggreate method: mean, add, max, min update(**kwargs) arguments: the output of step 4: aggregate, and kwargs in propogate update Code snippets of MessagePassing. See full source code here import inspect from inspect import Parameter import torch from torch import Tensor from torch_sparse import SparseTensor def __collect__(self, args, edge_index, size, kwargs): # i, j = (1, 0) if self.flow == 'source_to_target' else (0, 1) out = {} for arg in args: if arg[-2:] not in ['_i', '_j']: out[arg] = kwargs.get(arg, Parameter.empty) else: dim = 0 if arg[-2:] == '_j' else 1 data = kwargs.get(arg[:-2], Parameter.empty) if isinstance(data, (tuple, list)): assert len(data) == 2 if isinstance(data[1 - dim], Tensor): self.__set_size__(size, 1 - dim, data[1 - dim]) data = data[dim] if isinstance(data, Tensor): self.__set_size__(size, dim, data) data = self.__lift__(data, edge_index, j if arg[-2:] == '_j' else i) out[arg] = data if isinstance(edge_index, Tensor): out['adj_t'] = None out['edge_index'] = edge_index out['edge_index_i'] = edge_index[i] out['edge_index_j'] = edge_index[j] out['ptr'] = None elif isinstance(edge_index, SparseTensor): out['adj_t'] = edge_index out['edge_index'] = None out['edge_index_i'] = edge_index.storage.row() out['edge_index_j'] = edge_index.storage.col() out['ptr'] = edge_index.storage.rowptr() out['edge_weight'] = edge_index.storage.value() out['edge_attr'] = edge_index.storage.value() out['edge_type'] = edge_index.storage.value() out['index'] = out['edge_index_i'] out['size'] = size out['size_i'] = size[1] or size[0] out['size_j'] = size[0] or size[1] out['dim_size'] = out['size_i'] return out def __set_size__(self, size: List[Optional[int]], dim: int, src: Tensor): the_size = size[dim] if the_size is None: size[dim] = src.size(self.node_dim) elif the_size != src.size(self.node_dim): raise ValueError( (f'Encountered tensor with size {src.size(self.node_dim)} in ' f'dimension {self.node_dim}, but expected size {the_size}.')) def __lift__(self, src, edge_index, dim): if isinstance(edge_index, Tensor): index = edge_index[dim] return src.index_select(self.node_dim, index) elif isinstance(edge_index, SparseTensor): if dim == 1: rowptr = edge_index.storage.rowptr() rowptr = expand_left(rowptr, dim=self.node_dim, dims=src.dim()) return gather_csr(src, rowptr) elif dim == 0: col = edge_index.storage.col() return src.index_select(self.node_dim, col) raise ValueError ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:1:3","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"Code Example: GCN import torch from torch_geometric.nn import MessagePassing from torch_geometric.utils import add_self_loops, degree class GCNConv(MessagePassing): def __init__(self, in_channels, out_channels): super(GCNConv, self).__init__(aggr='add') # \"Add\" aggregation. self.lin = torch.nn.Linear(in_channels, out_channels) def forward(self, x, edge_index): # x has shape [num_nodes, in_channels] # edge_index has shape [2, E] # Step 1: Add self-loops to the adjacency matrix. edge_index = add_self_loops(edge_index, num_nodes=x.size(0)) # Step 2: Linearly transform node feature matrix. x = self.lin(x) # Step 3-5: Start propagating messages. return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x) def message(self, x_j, edge_index, size): # x_j has shape [num_edges, out_channels] # Step 3: Normalize node features. row, col = edge_index deg = degree(row, size[0], dtype=x_j.dtype) deg_inv_sqrt = deg.pow(-0.5) norm = deg_inv_sqrt[row] * deg_inv_sqrt[col] return norm.view(-1, 1) * x_j def update(self, aggr_out): # aggr_out has shape [num_nodes, out_channels] # Step 5: Return new node embeddings. return aggr_out ","date":"2021-08-07","objectID":"/2021-08-07-graph-pyg/:1:4","tags":["Deep Learning","Graph"],"title":"Graph: Implement a MessagePassing layer in Pytorch Geometric","uri":"/2021-08-07-graph-pyg/"},{"categories":["Machine Learning with Graphs"],"content":"Basics. ","date":"2021-04-19","objectID":"/2021-04-19-graph-foundation/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: Concepts","uri":"/2021-04-19-graph-foundation/"},{"categories":["Machine Learning with Graphs"],"content":"Definition Graph: $G(V, E)$ Adjacency Matrix: $A$ Degree: $D$, the number of nodes that are adjacent to $v$. Neighbors: $N$, the number of $N_{v(i)}$ is equal to $D_{v(i)}$. ","date":"2021-04-19","objectID":"/2021-04-19-graph-foundation/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Concepts","uri":"/2021-04-19-graph-foundation/"},{"categories":["Machine Learning with Graphs"],"content":"Connectivity Walk A walk on a graph is an alternating sequence of nodes and edges, starting with a node and ending with a node where each edge is incident with the nodes immediately preceding and following it. A walk starting at node $u$ and ending at node $v$ is called a $u$-$v$ walk. The length of a walk: the number of edges in this walk. Trail: A trail is a walk whose edges are distinct Path: A path is a walk whose nodes are distinct Subgraph Connected Component: Given a graph $G(V,E)$, a subgraph $G \\prime (V \\prime, E \\prime)$ is said to be a connected component if there is at least one path between any pair of nodes in the graph and the nodes in $V \\prime$ are not adjacent to any vertices in $V/V\\prime$. Connected Graph Shortest Path: The shortest path between node $v_s$ and node $v_t$ is defined as: $$ p^{sp}_{st} = \\arg \\min _{ p \\in paths} \\vert p \\vert $$ Diameter: the diameter of a graph is defined as the length of the longest shortest path in the graph. ","date":"2021-04-19","objectID":"/2021-04-19-graph-foundation/:1:1","tags":["Deep Learning","Graph"],"title":"Graph: Concepts","uri":"/2021-04-19-graph-foundation/"},{"categories":["Machine Learning with Graphs"],"content":"Centrality In a graph, the centrality of a node measures the importance of the node in the graph. Degree Centrality: measure the centrality of a given node based on its degree The eigenvector centrality: (Bonacich, 1972, 2007) defines the centrality score of a given node $v_i$ by considering the centrality scores of its neighboring nodes as: $$ \\boldsymbol c_{e} (v_i) = \\frac{1} {\\lambda} \\sum^{N}_{j=1} A_{i,j} \\cdot \\boldsymbol{c}_{e} {v_j} $$ or reform: $$ \\lambda \\boldsymbol{c}_e = \\boldsymbol{A} \\cdot \\boldsymbol{c}_e $$ Clearly, $\\boldsymbol{c}_e$ is an eigenvector of the matrix $\\boldsymbol{A}$ with its corresponding eigenvalue $\\lambda$. Katz centrality: It’s a variant of the eigenvector centrality, which not only considers the centrality scores of the neighbors but also includes a small constant for the central node itself. $$ c_{k} (v_i) = \\alpha \\sum^{N}_{j=1} A_{i,j} c_k (v_j) + \\beta $$ where $\\beta$ is a constant. the Katz centrality is reformed as: $$ \\bold{c}_k = \\alpha \\bold{A} \\bold{c}_k + \\boldsymbol{\\beta} $$ $$ (\\bold I - \\alpha \\cdot A )\\bold{c}_k = \\boldsymbol{\\beta} $$ Betweenness Centrality: Another way to measure the importance of a node is to check whether it is at an important position in the graph. Specifically, if there are many paths passing through a node, it is at an important position in the graph. ","date":"2021-04-19","objectID":"/2021-04-19-graph-foundation/:1:2","tags":["Deep Learning","Graph"],"title":"Graph: Concepts","uri":"/2021-04-19-graph-foundation/"},{"categories":["Machine Learning with Graphs"],"content":"Spectral Graph Theory Laplacian Matrix: $L = D -A$ Normalized Laplacian Matrix: $$ \\begin{aligned} L \u0026=D^{-\\frac{1}{2}} (D - A) D^{-\\frac{1}{2}} \\cr \u0026=I-D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}} \\end{aligned} $$ ","date":"2021-04-19","objectID":"/2021-04-19-graph-foundation/:1:3","tags":["Deep Learning","Graph"],"title":"Graph: Concepts","uri":"/2021-04-19-graph-foundation/"},{"categories":["Machine Learning with Graphs"],"content":"Why is it interesting Drug discovery discovery highly drug-like molecules complete an existing molecule to optimize a desired property Discovering novel structures Network science ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Why is it hard Large and variable output Non-unique representations $n$-node graph can be represented in $n!$ ways Hard to compute/optimize objective functions Complex dependencies edge fprmation has long-range dependencies ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Generative Model Given: Graphs sampled from $p_{data}(G)$ Goal: learn the distribution $p_{model}(G)$ sample from $p_{model}(G)$ Setup: Assume we try to learn a generative model from a set of points (i.e., graphs) $\\lbrace x_i \\rbrace$ $p_{data}(x)$ is the data distribution, which is never known to us, but we have sampled $ \\boldsymbol{x}_{i} \\sim p_{data}(\\boldsymbol{x})$. $p_{model}(\\boldsymbol{x}; \\theta)$ it the model, parametrized by $\\theta$, that we use to approximate $p_{data}(x)$. Auto-regressive models $p_{model}(\\boldsymbol{x}; \\theta)$ is used for both density estimation and sampling (from the probability density) Apply chain rule: Joint distritbution is a product of conditional distribution $$ p_{\\text {model}}(\\boldsymbol{x} ; \\theta)=\\prod_{t=1}^{n} p_{\\text {model}}\\left(x_{t} \\mid x_{1}, \\ldots, x_{t-1} ; \\theta\\right) $$ $\\boldsymbol{x}$ is a vector, $x_t$ it the $t$-th dimension. E.g. $\\boldsymbol{x}$ is a sentence, $x_t$ is the $t$-th word. For graph generation,$x_t$ will be the $t$-th action (add node, add edge) ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"GraphRNN: Generating Graph Idea: Generating graphs via sequentially adding nodes and edges. ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Model Graphs as Sequences Graphs $G$ with node ordering $\\pi$ can be uniquely mapped into a sequence of node and edge additions $S^{\\pi}$. The sequence $S^{\\pi}$ has two levels: Node-level: add nodes, one at a time Edge-level: add edges between existing nodes We transformed graph generation problem into a sequence generation problem. Need to model 2 processes generate a state for a new node (node-level sequence) Generate edges for the new node based on its state (Edge-level sequence) ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:4:1","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"GraphRNN Relationship between node-level RNN and edge-level RNN Node-level RNN generate the initial state for edge-level RNN Edge-level RNN generates edges for the new node, then updates node-level RNN state using generated results ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:4:2","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Issue: Tractability Any node can connect to any prior node Too many step for edge generation need to generate full adjacency matrix complex too-long edge dependencies Solution: Tractablity via BFS Breadth-First Search node ordering Benefits: Reduce possible node orderings From $O(n!)$ to number of distinct BFS orderings Reduce steps for edge generation reducing nuber of previous nodes to look at ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:4:3","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Evaluating generated graphs Challege: There is no efficient Graph isomorphism test that can be applied to any class of graphs Solution: Visual similarity Graph statistics similarity ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:5:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Reference Jure Leskovec, Stanford CS224W: Machine Learning with Graphs ","date":"2020-12-12","objectID":"/2020-12-12-dl-graph-generation/:6:0","tags":["Deep Learning","Graph"],"title":"Graph: GraphRNN","uri":"/2020-12-12-dl-graph-generation/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Convolutional Network and Graph Attention ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Why deep graph encoder ? Limitations of Shallow Encoders (e.g. node2vec) $O( | V | )$ parameters are needed: No sharing of parameters between nodes Every node has its own unique embedding Inherently “transductive”: Can not generate embeddings for nodes that are not seen during training Do not incorporate node features Many graphs have features that we can and should leverage ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Convolutional Network Could get embedding for unseen nodes!!! Aggreate Neighbors: Generate node embeddings based on local network neighborhoods. Intuition: Nodes aggregate information from their neighors using neural networks. Computation graph: defined by networkneigborhood Layers: Model can be of arbitary depth Nodes have embeddings at each layer Layer-0 embedding: Node $u$'s input feature $x_u$ Layer-K embedding gets information from nodes that are K hops away ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Training Unsuperised training use only the graph structure “similar: nodes have similar embeddings unspuervise loss function could based on: Random walks (node2vec, DeepWalk, struc2vec) Graph factorization Node proximity in the graph Supervised training directly train the mode for a supervised task (e.g. node classification) ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:2:1","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"GraphSAGE: Generalized neigborhood aggregation where, $W_k$, ${B_k}$ is learnable weighted matrices. $h_v^0 = x_v$: initial 0-th layer embeddings are equal to node features. $\\mathbf{h}_{v}^{k-1}$: previous layer embedding of $v$. $\\mathbf{z} _v = \\mathbf{h} _{v}^{k}$: Embedding after $k$ layers of neigborhood aggregation $\\sigma$: Non-linearity, e.g., ReLU AGG: Mean: take a weighted average of neighbors $$\\text{AGG} = \\sum _{u \\in N(v)} \\frac{ \\mathbf{h} _{u}^{k-1} } { | N(v) | }$$ Pool: Transform neighbor vectors and apply symmetric vector function $$\\text{AGG} = \\gamma ([\\mathbf{Q}\\mathbf{h}_{u}^{k-1}, \\forall u \\in (N(v))])$$ $\\gamma$: element-wise mean/max LSTM: Apply LSTM to reshuffled of neighbors $$\\text{AGG} = \\text{LSTM} ([\\mathbf{h}_{u}^{k-1}, \\forall u \\in \\pi(N(v))])$$ ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:2:2","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Attention Network ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Simple Neighorhood Aggregation The formula $$ \\mathbf{h} _{v}^{k} = \\sigma (\\mathbf{W} _{k} \\sum _{u \\in N(v)} \\frac{ \\mathbf{h} _{u}^{k-1}}{ | N(v) | } + \\mathbf{B} _{k} \\mathbf{h} _{v}^{k-1} ) $$ Equivalently rewritten in vector form: $$ \\mathbf{H} ^{(l+1)} = \\sigma ( \\mathbf{H} ^{(l)} \\mathbf{W} _{0}^{l} + \\tilde{\\mathbf{A}} \\mathbf{H} ^{(l)} \\mathbf{W} _{0}^{l}) $$ with $\\tilde{A} = D^{- \\frac{1}{2}} A D^{- \\frac{1}{2}}$. ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Graph convolutional operator Aggregates messages across neighborhoods. $N(v)$ $\\alpha _{vu} = \\frac{1}{ | N(v) |}$ is the weighting factor of node $u$'s message to node $v$ $\\alpha _{vu}$ id defined explicitly based on the structural properties of the graph All neighbors $u \\in N(v$ are equally important to node $v$) ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:2","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Attention strategy Allows for (implicitly) specifying different importance values ($\\alpha_{vu}$) to different neighbors Compute embedding $\\mathbf{h}_{v}^{k}$ of each node in the graph following: Nodes attend over their neighorhoods’ message Implicitly specifying different weights to different nodes in a neighborhood Attention Mechanism Compute attention coefficients $e_{vu}$ across pairs of nodes $u$, $v$ based on their messages: $$e_{vu} = a (\\mathbf{W}_{k} \\mathbf{h}_{u}^{k-1}, \\mathbf{W}_{k} \\mathbf{h}_{v}^{k-1})$$ Normalize coefficients using the softmax function in order to comparable across different neighorhoods: $$ \\begin{aligned} \\alpha_{vu} \u0026=\\frac{ \\exp (e_{v u} )} {\\sum_{k \\in N(v)} \\exp (e_{v k} )} \\cr \\boldsymbol{h}_{v}^{k} \u0026=\\sigma (\\sum_{u \\in N(v)} \\alpha_{v u} \\boldsymbol{W}_{k} \\boldsymbol{h}_{u}^{k-1} ) \\end{aligned} $$ Multi-head attention Attention operations in a given layer are independently replicated R times (each replica with different parameters) Outputs are aggregated (by concatenating or adding) ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:3","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"GCN For GCN, $$X^{\\prime} = \\tilde{D} ^{- \\frac{1}{2}} \\tilde{A} \\tilde{D}^{- \\frac{1}{2}} X \\Theta$$ Acutally, it is same as $$ \\mathbf{x} _{i}^{(k)}=\\sum _{j \\in \\mathcal{N}(i) \\cup\\lbrace i \\rbrace } \\frac{1}{\\sqrt{\\operatorname{deg}(i)} \\cdot \\sqrt{\\operatorname{deg}(j)}} \\cdot (\\mathbf{\\Theta} \\cdot \\mathbf{x} _{j}^{(k-1)} ) $$ class GCNConv(pyg_nn.MessagePassing): def __init__(self, in_channels, out_channels): super(GCNConv, self).__init__(aggr='add') # aggregation self.lin = torch.nn.Linear(in_channels, out_channels) def forward(self, x, edge_index): # add self loop edge_index, _ = self.add_self_loops(edge_index, num_nodes=x.size(0)) # initial feature transform x = self.lin(x) return self.propagate(edge_index, size=(x.size(0), x.size(0)), x= x) def message(self, x_j, edge_index, size): # \\phi row, col = edge_index deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype) deg_inv_sqrt = deg.pow(-0.5) norm = deg_inv_sqrt[row]*deg_inv_sqrt[col] return norm.view(-1, 1) *x_j def update(self, aggr_out): # \\gamma return aggr_out ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:4","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"GraphSAGE class GraphSage(pyg_nn.MessagePassing): \"\"\"Non-minibatch version of GraphSage.\"\"\" def __init__(self, in_channels, out_channels, reducer='mean', normalize_embedding=True): super(GraphSage, self).__init__(aggr='mean') # Aggerate if normalize_embedding: self.normalize_emb = True def forward(self, x, edge_index): num_nodes = x.size(0) return self.propagate(edge_index, size=(num_nodes, num_nodes), x=x) def message(self, x_j, edge_index, size): # \\phi return x_j def update(self, aggr_out, x): # \\gamma: concate and transform concat_out = torch.cat((x, aggr_out), 1) aggr_out = F.relu(self.agg_lin(concat_out)) if self.normalize_emb: aggr_out = F.normalize(aggr_out, p=2, dim=1) return aggr_out ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:5","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"GAT class GAT(pyg_nn.MessagePassing): def __init__(self, in_channels, out_channels, num_heads=1, concat=True, dropout=0, bias=True, **kwargs): super(GAT, self).__init__(aggr='add', **kwargs) self.in_channels = in_channels self.out_channels = int(out_channels / num_heads) self.heads = num_heads self.concat = concat self.dropout = dropout self.lin = nn.Linear(in_channels, self.out_channels * num_heads) # TODO self.att = nn.Parameter(torch.Tensor(1, self.heads, self.out_channels * 2)) # TODO if bias and concat: self.bias = nn.Parameter(torch.Tensor(self.heads * self.out_channels)) elif bias and not concat: self.bias = nn.Parameter(torch.Tensor(self.out_channels)) else: self.register_parameter('bias', None) nn.init.xavier_uniform_(self.att) nn.init.zeros_(self.bias) def forward(self, x, edge_index, size=None): if size is None and torch.is_tensor(x): edge_index, _ = remove_self_loops(edge_index) edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0)) # \\theta x = self.lin(x) return self.propagate(edge_index, size=size, x=x) def message(self, edge_index_i, x_i, x_j, size_i): # \\phi compute attention coefficient x_i = x_i.view(-1, self.heads, self.out_channels) # split hidden into multi-heads x_j = x_j.view(-1, self.heads, self.out_channels) # concat, then cosine similarity (vector inner product) on last axis. alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1) alpha = F.leaky_relu(alpha, 0.2) # pyg softmax: called scatter_add internaly alpha = pyg_utils.softmax(alpha, edge_index_i, size_i) alpha = F.dropout(alpha, p=self.dropout, training=self.training) return x_j * alpha.view(-1, self.heads, 1) # weighted input def update(self, aggr_out): # \\gamma multi-head if self.concat is True: aggr_out = aggr_out.view(-1, self.heads * self.out_channels) else: aggr_out = aggr_out.mean(dim=1) if self.bias is not None: aggr_out = aggr_out + self.bias return aggr_out ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:3:6","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Reference Jure Leskovec, Stanford CS224W: Machine Learning with Graphs ","date":"2020-12-11","objectID":"/2020-12-12-ml-gcn-gat/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: GCN and GAT","uri":"/2020-12-12-ml-gcn-gat/"},{"categories":["Machine Learning with Graphs"],"content":"Problems: Given a network with labels on some nodes, how do we assign labels to all other nodes in the network? classification label of an object $O$ in network may depend on: Features of $O$ Labels of the objects in $O$'s neighborhood Features of objects in $O$'s neigborhood ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Collective classification models Reational clasifiers Iterative classifications Loopy belief propagation ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Intuition Simultaneous classification of interlinked nodes using correlations ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:1:1","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Applications Document classification Part of speech tagging Link prediction Optical character recognition Entity resolution in sensor networks Image/3D data segmentation Spam and fraud detection ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:1:2","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Markov Assumption The label ${Y_i}$ of one onde $i$ depends on the labels of its neighbors ${N_i}$. $$P(Y_i \\vert i ) = P (Y_i \\vert N_i)$$ ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:1:3","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Steps Local Classifier: Assign initial labels predicts label based on node attributes/ features standard classification task Does not use network information Retional Classifier: Capture correlations based on the network learns a classifer to label one node based on the labels and /or attributes of tis neighbors This is where network information is used Collective Inference: Propagate correlations through networks Apply relational classifier to each node iteratively Iterate until the inconsistency between neighboring labels is minimized Network structure substantially affects the final prediction ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:1:4","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Relational classifers Basic idea: Class probability of ${Y_i}$ is a weighted average of class probabilities of its neigbors. Iteration labeled nodes: initialize with ground-truth Y labels unlabeled nodes: initialize Y uniformly Update all nodes in a random order until convergence or until maximum number of iteration is reached Repeat for eahc node $i$ and label $c$ $$ P( Y_i = c) = \\frac{1}{\\sum_{(i,j) \\in E}W(i,j)}\\sum_{(i,j) \\in E}W(i,j)P(Y_j=c) $$ $W(i,j)$ is the edge strength from $i$ to $j$ However, Model cannot use node feature information Convergence is not guaranteed ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Iterative classification ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Main idea Classify node $i$ based on its attributes as well as labels of neigbor set $N_i$. Create a flat vector $a_i$ for each node $i$ Train a classifier to classify using $a_i$ Aggregate various numbers of neighbors using: count, mode, proportion, mean, exists, etc. ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Basic architecture of iterative classifers Bootstrap phase Convert each node $i$ to a flat vector $a_i$ Use local classifier $f(a_i)$ to compute best value for $Y_i$ Iteration phase: iterate till convergence Repeat for each node $i$ Update node vector $a_i$ Update label $Y_i$ to $f(a_i)$. This is a hard assignment Iterate until class labels stabilized or max number of iterations is reached However, Convergence is not guaranteed. Run for max number of iterations ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:3:2","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Applications fake reviewer/review detction ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:3:3","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Belief propagation Belief propagation is a dynamic programming approach to answering conditional probability queries in a graphical model Notation Label-label potential matrix $\\psi$: Dependency between a node and its neigbor $\\phi(Y_i, Y_j)$ equals the probability of a node $j$ being in state $Y_j$ given that it has a $i$ neigbbor in state $Y_i$ Prior belief $\\phi$: Probability $\\phi _i (Y_i)$ of node $i$ being in state ${Y_i}$ $m_{i \\rightarrow j}(Y_j)$ is $i$'s estimate of $j$ being in state $Y_j$ $\\mathcal{L}$ is the set of all states ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Reference Jure Leskovec, Stanford CS224W: Machine Learning with Graphs ","date":"2020-12-10","objectID":"/2020-12-12-ml-node-classififcation/:5:0","tags":["Deep Learning","Graph"],"title":"Graph: Semi-supervised Node Classification","uri":"/2020-12-12-ml-node-classififcation/"},{"categories":["Machine Learning with Graphs"],"content":"Node Embedings are learnt in the same way as word2vec (skip-gram model) However, graphs could be (un)directed, (un)weighted, (a)cyclic and are basically much more complex than the strucure of a sequence… So how do we generate “corpus” from a graph ? ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Random walk on the graph Given a graph and a starting point, we select a neighbor of it at random; then we select a neigbor of this point at random, and move to it, etc. The (random) sequence of points selected this way is a random walk on the graph ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Why Random walks Expressivity: Flexible stochastic definition of node similarity that incorporates both local and higher-order neighborhood information Efficiency: Do not need to consider all node pairs when training; only need to consider pairs that co-occur on random walks ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:1:1","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Sampling strategy Node2vec’s sampling strategy accepts 4 argument: Number of walks: number of random walks to be generated from each node in the graph Walk length: how many nodes are in each random walk P: return hyperparameter return back to the previous node Q: Inout hyperparameter Moving outwards : (DFS biased or BFS baised control) intuitively, q is the “ratio” of BFS vs. DFS Also, the standard skip-gram parameters context window size number of iterations etc. ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Node2Vec: Biased Walks ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:2:1","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Principal Idea: use flexible, biased random walks that can trade off between local and global views of the network. Consider you are on the random walk, and have just transitioned from node $t$ to node $v$ in the above diagram the probability to transition from $v$ to any neighbors is edge $\\alpha$, where $\\alpha$ is depened on the hyperparameters. $\\bold{P}$: controls the probability to go back to $t$ after visiting $v$ $\\bold{Q}$: controls the probability to go explore undiscovered parts of the graphs. So, the final travel probability is a function of $$ \\alpha_{p q}(t, x)=\\begin{cases} \\frac{1}{p} \u0026 \\text { if } d_{t x}=0 \\cr 1 \u0026 \\text { if } d_{t x}=1 \\cr \\frac{1}{q} \u0026 \\text { if } d_{t x}=2 \\end{cases} $$ where, $d_{tx}$: the length of shortest path of $t$ and $v$. 0: $x$ is $t$ 1: $x$ is neighbor to $t$ 2: $x$ and $t$ not connected Using the sampling strategy, node2vec will generate “senences” (the directed subgraphs) which are will be used for embedding just like text sentences are used in word2vec. ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Alias Sampling Preproccsing of transition probabilities for guiding random walk Alias Sampling: sampling of nodes while simulating the random walk can be done efficiently in $O(1)$. Understand Alias Method What’s really going on ? ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Applications Clustering/community detection Node classification Link prediction: predict edge $(i,j)$ based on $f(z_i,z_j)$ where we can: concatenate: $f(z_i,z_j) = g([z_i, z_j])$ Hadamard: $f(z_i,z_j) = g( z_i \\star z_j)$ (per coordinate product) Sum/Avg: $f(z_i,z_j) = g(z_i + z_j)$ Distance: $f(z_i,z_j) = g( || z_i - z_j || _2$ ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Machine Learning with Graphs"],"content":"Reference Jure Leskovec, Stanford CS224W: Machine Learning with Graphs node2vec: Scalable Feature Learning for Networks Embeddings for Graph Data ","date":"2020-12-06","objectID":"/2020-12-06-ml-node2vec/:5:0","tags":["Deep Learning","Graph"],"title":"Graph: Node2Vec","uri":"/2020-12-06-ml-node2vec/"},{"categories":["Nature Language Processing"],"content":"Word2Vec ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:0:0","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"CBOW Continuous Bag of Words Model (CBOW) When trainning, use N-gram language model. That’s for a target word, select $m$ (window) words before and after. Model one-hot encoding get $2m$ vectors: $$X = (x^{c-m}, \\cdots, x^{c-1}, x^{c+1}, \\cdots, x^{c+m})$$ Embeding Vector $\\mathcal{V} \\in R^{n \\times \\mathcal{V}}$, $$ \\left(v_{(c-m)}=\\mathcal{V} x^{(c-m)}, v_{(c-m+1)}=\\mathcal{V} x^{(c-m+1)}, \\ldots, v_{(c+m)}=\\mathcal{V} x^{(c+m)}\\right) $$ average $$ \\hat{v}=\\frac{v_{c-m}+v_{c-m+1}+\\ldots+v_{c-m}}{2 m} $$ multiplut output layer matrix $\\mathcal{U} \\in R^{n \\times \\mathcal{V}}$, $$ z = \\mathcal{U} \\hat{v} $$ then $\\hat{y}$, $$ \\hat{y} = \\operatorname{softmax}(z)$$ optimization: cross-entropy $$ \\begin{aligned} \\operatorname{minimize} \\mathcal{J} \u0026=-\\log P (w_{c} \\mid w_{c-m}, \\cdots, w_{c-1}, w_{c+1}, \\cdots, w_{c+m}) \\cr \u0026=-\\log P\\left(u_{c} \\mid \\hat{v}\\right) \\cr \u0026=-\\log \\frac{\\exp \\left(u_{c}^{T} \\hat{v}\\right)}{\\sum_{j=1}^{|V|} \\exp \\left(u_{j}^{T} \\hat{v}\\right)} \\cr \u0026=-u_{c}^{T} \\hat{v}+\\log \\sum_{j=1}^{|V|} \\exp \\left(u_{j}^{T} \\hat{v}\\right) \\end{aligned} $$ ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:1:0","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Skip-gram it’s on the opposite of CBOW generate one-hot encoding for $x$ multiply embeding $$v_c = \\mathcal{V}x$$ multiply output matrix $\\mathcal{U}$, get $2m$ vectors. $$ u = \\mathcal{U}v_c = u_{c-m}, \\cdots, u_{c-1}, u_{c+1, \\cdots, u_{c+m}} $$ for each vector, apply softmax, get $$ y^{(c-m)}, \\cdots, y^{(c-1)}, y^{(c+1)}, \\cdots, y^{(c+m)} $$ loss $$ \\begin{aligned} \\text { minimize } J \u0026=-\\log P (w_{c-m}, \\ldots, w_{c-1}, w_{c+1}, \\ldots, w_{c+m} ) \\cr \u0026=-\\log \\prod_{j=0, j \\neq m} P\\left(w_{c-m+j} \\mid w_{c}\\right) \\cr \u0026=-\\log \\prod_{j=0, j \\neq m}^{2 m} P\\left(u_{c-m+j} \\mid v_{c}\\right) \\cr \u0026=-\\log \\prod_{j=0, j \\neq m} \\frac{2 m}{\\sum_{k=1}^{|V|} \\exp \\left(u_{k}^{T} v_{c}\\right)} \\cr \u0026=-\\sum_{j=0, j \\neq m}^{2 m} u_{c-m+j}^{T} v_{c}+2 m \\log \\sum_{k=1}^{|V|} \\exp \\left(u_{k}^{T} v_{c}\\right) \\end{aligned} $$ ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:2:0","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Others ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:3:0","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Sub-sampling use probability $P$ to random delete words, e.g. “the”, “a”. $$ P = 1 - \\sqrt{\\frac{\\text{sample}}{\\text{freq}(w)}} $$ ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:3:1","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Neagtive sampling When training, update postive word and partial of negative words. ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:3:2","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Hiearchical Softmax build Huffman Tree acroding to the word freqencies. the higer freq of words, the higher word levels, then the learning become easier and faster. ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:3:3","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Nature Language Processing"],"content":"Reference Word2Vec- The Skip-Gram Model word2vec ","date":"2020-12-05","objectID":"/2020-12-05-nlp-word2vec/:4:0","tags":["Deep Learning","NLP"],"title":"NLP: Word2Vec","uri":"/2020-12-05-nlp-word2vec/"},{"categories":["Machine Learning"],"content":"概率图模型（probabilistic graphical model, PGM），是一种学习任务的框架描述，它将学习任务归结为计算变量的概率分布。 ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:0","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Machine Learning"],"content":"1. 概率图基础 按照概率图中变量关系的不同，概率图模型可以大致分为两类： 贝叶斯网络：有向图模型，使用有向无环图表达关系（通常，变量间存在显式的因果关系） 马尔科夫网络：无向图模型，使用无图表达关系（通常，变量间存有关系，但是难以显式表达） 同时存有有向边和无向边的模型，如条件随机场（conditional random field）和链图（chain graph），单独看做一类局部有向模型。 贝叶斯网络 可以分为静态贝叶斯网络和动态贝叶斯网络。相比于静态贝叶斯网络，动态（dynamic）贝叶斯网络主要用于时序数据建模（如语音识别、自然语言处理、轨迹数据挖掘等）。其中，一种结构最简单的动态贝叶斯网络就是隐马尔可夫模型（hidden markov model, HMM）。一般来说，贝叶斯网络中每一个结点都对应于一个先验概率分布或者条件概率分布，因此整体的联合分布可以直接分解为所有单个结点所对应的分布的乘积。 马尔可夫网 由于变量之间没有明确的因果关系，它的联合概率分布通常会表达为一系列势函数（potential function）的乘积。通常情况下，这些乘积的积分并不等于1，因此，还要对其进行归一化才能形成一个有效的概率分布——这一点往往在实际应用中给参数估计造成非常大的困难。 按照表示的抽象级别不同，概率图模型可以分为： 基于随机变量的概率图模型，如贝叶斯网、马尔可夫网、条件随机场和链图等 基于模板的概率图模型．这类模型根据应用场景不同又可分为两种： 暂态模型，包括动态贝叶斯网（Dynamic Bayesian Network, DBN）和状态观测模型，其中状态观测模型又包括线性动态系统（Linear Dynamic System, LDS）如卡尔曼滤波器，还有隐马尔可夫模型（Hidden Markov Model, HMM）； 对象关系领域的概率图模型，包括盘模型（Plate Model，PM）、概率关系模型（Probabilistic Relational Model, ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:1","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Machine Learning"],"content":"2. 概率图表示 ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:2","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Machine Learning"],"content":"3. 概率图推断 ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:3","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Machine Learning"],"content":"4. 概率图学习 ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:4","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Machine Learning"],"content":"参考 概率图模型总览 ","date":"2020-11-20","objectID":"/2020-11-20-ml-pgm/:0:5","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Probabilistic Graphical Model","uri":"/2020-11-20-ml-pgm/"},{"categories":["Make bioinfo uncool again"],"content":"Config IGV on the server. I have to share the inteactive results with my colleague. But I don’t like to install UCSC genomebrower in local. Instead, a light-weight one is what I need. ","date":"2020-11-16","objectID":"/2020-11-16-igvweb/:0:0","tags":["Bioinformatics"],"title":"Deploy IGV webapp on linux server","uri":"/2020-11-16-igvweb/"},{"categories":["Make bioinfo uncool again"],"content":"1. Installation Install nodejs if you have conda, just conda install -c conda-forge nodejs build igv-webapp git clone https://github.com/igvteam/igv-webapp.git cd ./igv-webapp npm install npm run build ","date":"2020-11-16","objectID":"/2020-11-16-igvweb/:1:0","tags":["Bioinformatics"],"title":"Deploy IGV webapp on linux server","uri":"/2020-11-16-igvweb/"},{"categories":["Make bioinfo uncool again"],"content":"2. Running the app npx http-server -p 5000 path/to/igv_webapp ","date":"2020-11-16","objectID":"/2020-11-16-igvweb/:2:0","tags":["Bioinformatics"],"title":"Deploy IGV webapp on linux server","uri":"/2020-11-16-igvweb/"},{"categories":["Make bioinfo uncool again"],"content":"3. Configuration (Example) gtf, bed, bam, bigwig … in resource directory fisrt. prepare a json file contain all the required information of tracks. see also igv.js wiki. E.g. mm10_igv-lab.sv.json import json tracks = [] for b in ['a1.bed','a2.bed','c1.bed','c2.bed']: bed = os.path.basename(b) track = { \"name\": bed.replace(\".bed\",\"\"), \"type\": \"annotation\", \"format\": \"bed\", \"sourceType\": \"file\", \"url\": f\"http://igv-app-03:5000/resources/{bed}\", # your server name + port + file path #order: Number.MAX_VALUE, #\"visibilityWindow\": 300000000, \"displayMode\": \"EXPANDED\" } tracks.append(track) sv = { \"label\": \"IGV-Lab\", # name will be shown under track's menu. \"description\": \"Any descriptions\", \"link\": \"\", \"tracks\": tracks } with open('./resources/tracks/mm10_igv-lab.json', 'w') as outfile: json.dump(sv, outfile) add the json to trackRegistry.json in the resource/tracks. \"mm10\": [ \"resources/tracks/mm10_annotations.json\", \"resources/tracks/mm10_encode.json\", \"resources/tracks/mm10_igv-lab.json\" # add ] load files select the correct genome, e.g. mm10 In the dropdown menu of tracks, you’ll see IGV-Lab. Click it, and select the files you’ve just add. ","date":"2020-11-16","objectID":"/2020-11-16-igvweb/:3:0","tags":["Bioinformatics"],"title":"Deploy IGV webapp on linux server","uri":"/2020-11-16-igvweb/"},{"categories":["Machine Learning"],"content":"典型相关分析(CCA) ，一种常用降维算法，也可以用于多个线性空间相关性计算。比如同一对象的多模态数据，单细胞多组学数据整合等。 ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:0:0","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"原理 ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:1:0","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"定义 假设有两个特征空间， $S1 = x_1 \\in R^{d1}$, $S2 = x_2 \\in R^{d2}$, 将两个特征向量合并，有 $$ \\mathbf{x} = [\\begin{array}{c} \\mathbf{x}_1 \\cr \\mathbf{x}_2 \\end{array} ] $$ $$ E(\\mathbf{x})=[ \\begin{array}{c} \\mu_{1} \\cr \\mu_{2} \\end{array} ] $$ $$ \\Sigma=\\bigg[ \\begin{array}{cc} \\Sigma_{11} \u0026 \\Sigma_{12} \\cr \\Sigma_{21} \u0026 \\Sigma_{22} \\end{array} \\bigg] $$ 其中， $\\Sigma$ 为协方差矩阵， 且$\\Sigma_{12} = \\Sigma_{21}^T$。 ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:1:1","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"计算相关系数 令 $\\mathbf{a}$, $\\mathbf{b}$, 且满足 $$ u = \\mathbf{a}^T \\mathbf{x}_1 \\\\ v = \\mathbf{b}^T \\mathbf{x}_2 $$ 计算 u, v 的方差和协方差 $$ \\operatorname{var}(u) = a^T \\Sigma_{11} a \\\\ \\operatorname{var}(v) = b^T \\Sigma_{22}b \\\\ \\operatorname{cov}(u, v) = a^T \\Sigma_{12} b $$ 因此，u 和 v的相关系数为： $$ \\operatorname{Corr}(u, v)=\\frac{\\operatorname{cov}(u, v)}{\\sqrt{\\operatorname{var}(u)} \\sqrt{\\operatorname{var}(v)}} $$ 代入 a， b $$ \\operatorname{Corr}(u, v)=\\frac{\\mathbf{a}^{T} \\Sigma_{12} \\mathbf{b}}{\\sqrt{\\mathbf{a}^{T} \\Sigma_{11} \\mathbf{a}} \\sqrt{\\mathbf{b}^{T} \\Sigma_{22} \\mathbf{b}}} $$ ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:1:2","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"求解 目标： 最大化 $\\operatorname{Corr}(u,v)$ 方法： ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:0","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"1. 固定分母，最大化分子 $$ \\max_{\\mathbf{a}, \\mathbf{b}} \\mathbf{a}^{T} \\Sigma_{12} \\mathbf{b} $$ $$ \\text { s.t. } \\quad \\mathbf{a}^{T} \\Sigma_{11} \\mathbf{a}=1, \\quad \\mathbf{b}^{T} \\Sigma_{22} \\mathbf{b}=1 $$ ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:1","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"2. 构造拉格朗日等式 $$ L=\\mathbf{a}^{T} \\Sigma_{12} \\mathbf{b}-\\frac{\\lambda_{1}}{2}\\left(\\mathbf{a}^{T} \\Sigma_{11} \\mathbf{a}-1\\right)-\\frac{\\lambda_{2}}{2}\\left(\\mathbf{b}^{T} \\Sigma_{22} \\mathbf{b}-1\\right) $$ ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:2","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"3. 求导 $$ \\begin{array}{l} \\frac{\\partial L}{\\partial \\mathbf{a}}=\\Sigma_{12} \\mathbf{b}-\\lambda_{1} \\Sigma_{11} \\mathbf{a}=0 \\\\ \\frac{\\partial L}{\\partial \\mathbf{b}}=\\Sigma_{21} \\mathbf{a}-\\lambda_{2} \\Sigma_{22} \\mathbf{b}=0 \\end{array} $$ 得： $\\lambda_{1}=\\lambda_{2}=\\mathbf{a}^{T} \\Sigma_{12} \\mathbf{b}$ ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:3","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"4. 求得最大相关系数 令 $\\lambda = \\lambda_1 = \\lambda_2$， 有： $$ \\begin{array}{l} \\Sigma_{11}^{-1} \\Sigma_{12} \\mathbf{b}=\\lambda \\mathbf{a} \\\\ \\Sigma_{22}^{-1} \\Sigma_{21} \\mathbf{a}=\\lambda \\mathbf{b} \\end{array} $$ 即 $$ \\left(\\begin{array}{cc} \\Sigma_{11}^{-1} \u0026 0 \\\\ 0 \u0026 \\Sigma_{22}^{-1} \\end{array}\\right)\\left(\\begin{array}{cc} 0 \u0026 \\Sigma_{12} \\\\ \\Sigma_{21} \u0026 0 \\end{array}\\right)\\left(\\begin{array}{l} \\mathbf{a} \\\\ \\mathbf{b} \\end{array}\\right)=\\lambda\\left(\\begin{array}{l} \\mathbf{a} \\\\ \\mathbf{b} \\end{array}\\right) $$ 令 $$ B=\\left(\\begin{array}{cc} \\Sigma_{11} \u0026 0 \\\\ 0 \u0026 \\Sigma_{22} \\end{array}\\right), \\quad A=\\left(\\begin{array}{cc} 0 \u0026 \\Sigma_{12} \\\\ \\Sigma_{21} \u0026 0 \\end{array}\\right) \\quad \\mathbf{w}=\\left(\\begin{array}{l} \\mathbf{a} \\\\ \\mathbf{b} \\end{array}\\right) $$ 上式表示为： $$B^{-1}A\\mathbf{w} = \\lambda \\mathbf{w}$$ 因此，求解 $B^{-1}A$ 的特征值和特征向量，将原来的$x_1$, $x_2$做映射。 $\\lambda$ 就是相关系数u和v的相关系数， u和v 就是一对典型变量(canonical variables). ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:4","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"求解方法2 从偏导数等式得到 $$ \\Sigma_{11}^{-1} \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21} \\mathbf{a}=\\lambda^{2} \\mathbf{a} $$ 因此，求出$\\lambda$ 和 $\\mathbf{a}$, 再代入，求$\\mathbf{b}$. ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:2:5","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"参考 典型关联分析 ","date":"2020-11-02","objectID":"/2020-08-27-ml-cca/:3:0","tags":["CCA","Statistical Learning"],"title":"Canonical Correlation Analysis (CCA)","uri":"/2020-08-27-ml-cca/"},{"categories":["Machine Learning"],"content":"A biologist like me might have never had a numerical computing training. I don’t even known what a complex number really means. Here are some useful basics to keep in mind. ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:0:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Machine Learning"],"content":"Complex number complex number $a+bi$ lives in a 2d complex plane, including real axis: $a$ imagnary axis: $i$ orthognal to real axis $i \\rightarrow 90 \\degree \\text{rotation}$ ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:1:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Machine Learning"],"content":"2 ways of representation $z = a + bi$ $z = r \\cos(\\phi) + r \\sin(\\phi) i = r e^{i \\phi}$ ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:2:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Machine Learning"],"content":"3 Facts about Multiplication $z \\cdot 1 = z$ $z \\cdot i = \\operatorname{Rot90}(z)$ e.g. $i \\cdot i = -1$ $z \\cdot ( c + di) = c \\cdot z + d \\cdot (zi)$ e.g. $(2+i)(2-i) = 2 \\cdot 2 + 2i -2i - i^2 = 5 + 0i$ ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:3:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Machine Learning"],"content":"expotential form: $$ \\exp (i \\theta)=1+i \\theta+\\frac{(i \\theta)^{2}}{2}+\\frac{(i \\theta)^{3}}{6}+\\frac{(i \\theta)^{4}}{24}+\\cdots $$ derivative: $$ \\frac{d}{d t} e^{i t}=i \\cdot e^{ i \\cdot t} $$ $$ i^n \\cdot i^k = i^{n+k} $$ ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:4:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Machine Learning"],"content":"expotential form to find complex roots Example: ","date":"2020-10-01","objectID":"/2020-08-15-ml-complexnumber/:5:0","tags":["Deep Learning","Complex"],"title":"Complex number for biologist","uri":"/2020-08-15-ml-complexnumber/"},{"categories":["Make bioinfo uncool again"],"content":"The right way to deploy your snakemake pipeline","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Make bioinfo uncool again"],"content":"The best part of snakemake is allowed you to run your pipeline on HPC automatically. It save you a lot of time. ","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/:0:0","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Make bioinfo uncool again"],"content":"How to run snakemake on HPC there are two ways to configure use --cluster: works on different HPC system, e.g. slurm, SGE. assign resource in params directive explicitly. or provide a config file by --cluster-config use --profile: (recommend way) assign resource in resource directive explicitly. or provide a profile file. ","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/:1:0","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Make bioinfo uncool again"],"content":"Snakemake and slurm ","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/:2:0","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Make bioinfo uncool again"],"content":"the --cluster way An example for Stanford Sherlock. 1. define resource in params directive rule eblocks: input: \"...\" output: \"...\" params: time = \"30:00\", mem = \"4g\" threads: 8 shell: \"...\" run snakemake -s Snakefile --cluster 'sbatch -t {params.time} --mem={params.mem} -c {threads}' -j 10 2. define resource in cluster_config.yaml # slurm_config.yaml - cluster configuration for Stanford Sherlock__default__:partition:normaltime_min:\"01:00:00\"# time limit for each jobcpus:1mem:\"1g\"#ntasks-per-node: 14 #Request n cores be allocated per node.output:\"logs_slurm/{rule}.{wildcards}.out\"## redirect slurm-JOBID.txt to your directorystrain2trait:time_min:\"30:00\"eblocks:mem:\"4g\"cpus:\"{threads}\"## =\u003e use `threads` define in rule run snakemake -s Snakefile --cluster-config cluster.yaml \\ --cluster 'sbatch -t {cluster.time_min} --mem={cluster.mem} -c {cluster.cpus} -o {cluster.output} -e {cluster.output}' \\ -j 10 3. deploy your pipleline on HPC make a submit.sh script #!/bin/bash #SBATCH -J snakeflow #SBATCH --time=120:00:00 #SBATCH --qos long #SBATCH -N 1 #SBATCH -n 1 #SBATCH -c 1 #SBATCH -p normal #SBATCH --mem=1g ####SBATCH --mail-type=FAIL ####SBATCH --mail-user=xxx@gmail.com # activate conda enviroment source activate base # run jobs snakemake -j 666 -s haplomap.smk \\ --configfile config.yaml \\ --cluster \"sbatch --time={cluster.time_min} -p {cluster.partition} --mem={cluster.mem} -c {cluster.cpus} \" \\ --cluster-config slurm_config.yaml submit this script to cluster using sbatch submit.sh ","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/:2:1","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Make bioinfo uncool again"],"content":"the --profile way It’s more universal and versatile. 1. create a directory for slurm mkdir -p ~/.config/snakemake/slurm 2. create config.yaml in the slurm directory Note: resource directive for clusters only allow integer now. jobs:10# maximun job numbers submitted each timecluster:\"sbatch -p normal -t {resources.time_min} --mem={resources.mem} -c {resources.cpus} -o logs_slurm/{rule}_{wildcards} -e logs_slurm/{rule}_{wildcards} --mail-type=FAIL --mail-user=user@mail.com\"default-resources:[cpus=1,mem=2000,time_min=60] 3. assign resource if different from default rule eblocks: input: \"...\" output: \"...\" resources: mem = 4000 # only allow integers shell: \"...\" 4. run snakemake --profile slurm -s haplomap.smk --configfile config.yaml -j 666 ","date":"2020-08-19","objectID":"/2020-08-19-hpc-snakemake/:2:2","tags":["Bioinformatics"],"title":"Deploy snakemake pipeline on HPC","uri":"/2020-08-19-hpc-snakemake/"},{"categories":["Machine Learning"],"content":"A biologist’s way to learn Fourier transform ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:0:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Visual intuition in 3D This is an awesome introduction ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:1:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Fourier Series Discrete Fourier transform (DFT) A Fourier series is a periodic function composed of harmonically related sinusoids, combined by a weighted summation. 周期性函数可以变换为正余弦函数的和 $$ \\begin{aligned} f(t) \u0026= \\frac {a_0}{2} + \\sum_n a_n \\sin(n\\omega t + \\varphi_n) \\cr \u0026= \\frac {a_0}{2} + \\sum_n a_n \\sin(n\\omega t) + \\sum_n b_n \\cos(n\\omega t) \\end{aligned} $$ Note: 3 orthogonal bases ( 1, sin, cos ) ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:2:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Fourier Transform ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:3:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Euler’s formula For any real number $x$, $$ e^{i\\varphi} = \\cos \\varphi + i \\sin \\varphi $$ $i$ is the imagenary unit. let $\\varphi = \\omega t$, get complex exponentials $$ e^{i\\omega t} = \\cos (\\omega t) + i \\sin (\\omega t) $$ clockwise roation: $e^{i\\omega t}$ counter-clockwise roation: $e^{ - i\\omega t}$ when $\\varphi = \\pi$, Eluer's identity $$ e^{i\\pi} + 1 = 0 $$ ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:3:1","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Fourier transform for non-periodic function For non-periodic function $f(t)$, we multiply $e^{ - i\\omega t}$ to get signals only present in $e^{ - i\\omega t}$, then $$ \\int_{-\\infty}^{+\\infty} f(t) e^{ - j\\omega t} dt \\rightarrow \\begin{cases} = 0, \\text{without } \\omega \\cr \\neq 0, \\text{with } \\omega \\end{cases} $$ Note: the bases of $e^{ - j\\omega t}$ are orthogonal, if a signal is orthogonal to these bases, their dot product equal to 0. if a signal in $f(t)$ not present in $e^{ - j\\omega t}$: $$\\int_{-\\infty}^{+\\infty} f(t) e^{ - j\\omega t} dt = 0$$ if a signal in $f(t)$ present in $e^{ - j\\omega t}$: $$\\int_{-\\infty}^{+\\infty} f(t) e^{ - j\\omega t} dt \\neq 0$$ Now, the Fourier transform definition: $$ F(\\omega) = \\int_{-\\infty}^{+\\infty} f(t) e^{ - j\\omega t} dt $$ and inverse Fourier transform: $$ f(t) = \\int_{-\\infty}^{+\\infty} F(\\omega) e^{ - j\\omega t}d \\omega $$ ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:3:2","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"2D Fourier transform $$ F(u, v) = \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} f(x,y) e^{ - j(ux + vy)} dxdy $$ Now, the orthogonal bases become (1, $\\sin(ux + vy)$, $\\cos(ux + vy)$), which could be further decomposited into: $\\sin(ux)\\sin(vy)$ $\\sin(ux)\\cos(vy)$ $\\cos(ux)\\sin(vy)$ $\\cos(ux)\\cos(vy)$ ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:3:3","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Common application audio: $t$ is the time domain image: now $t$ become the location in the image low freq: contour high freq: detail 图像频率特性分析: 频谱图上的每一个像素点都代表一个频率值，幅值由像素点亮度变码而得。对于一幅图像，图像信号的频率特性如下： 直流分量: 表示预想的平均灰度 低频分量: 代表了大面积背景区域和缓慢变化部分 高频分量: 代表了它的边缘、细节、跳跃部分以及颗粒噪声 振幅: 描述了图像灰度的亮度 相位: 决定了图像是什么样子 ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:3:4","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Laplace Transform Euler’s Formula: $$ e^{i\\omega t} = \\cos (\\omega t) + i \\sin (\\omega t) $$ we get $$ \\cos(\\omega t) = \\frac{1}{2} (e^{j\\omega t} + e^{-j\\omega t}) $$ $$ j\\sin(\\omega t) = \\frac{1}{2} (e^{j\\omega t} - e^{-j\\omega t}) $$ Fourier transform: $$ F(\\omega) = \\int_{-\\infty}^{+\\infty} f(t) e^{ - j\\omega t} dt $$ The problem of Fourier transformation is that each component of sinusoids keep constant magnitude while oscillating. For $f(t)$ like $y = x^2$, when $x \\rightarrow \\infty$, FT do not perform well To solve this problem, we could multiply a decay fuction $e^{-\\sigma t}$, $\\sigma \u003e 0$. $$ \\begin{aligned} F(\\omega) \u0026= \\int_{-\\infty}^{+\\infty} f(t) e^{-\\sigma t} e^{ - j\\omega t} dt \\cr \u0026= \\int_{-\\infty}^{+\\infty} f(t) e^{-t(\\sigma + j\\omega)} dt \\end{aligned} $$ With a decay fuction, FT perform well when $x \\rightarrow \\infty$. Let complex number $s = \\sigma + j\\omega$, then Laplace Transform is $$ F(s) = \\int_{-\\infty}^{+\\infty} f(t) e^{-st} dt $$ Laplace Transform: A generalized Fourier transform The magnitude keep increasing/decreasing as oscillation continue. if the real componet of $s$ is 0 ( $\\sigma = 0$ ), then the magnitude will stay constant Inverse Laplace transform: $$ f(t) = \\frac {1}{2 \\pi i} \\int_{c - i\\infty}^{c + i\\infty} F(s)e^{st} ds $$ A visual intution of Laplace Transform: ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:4:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Fourier Transform and Convolution Convolution: $$ h(x) = (f \\star g)(x) = \\int_{-\\infty}^{+\\infty} f(u)(g(x-u))du $$ discrete form: $$ h[n] = (f \\star g)[n] = \\sum_{u = -\\infty}^{+\\infty} f[u]g[n-u] $$ 时域卷积定理：时域上的卷积对应频域上的乘积 $$ F[f(t) \\star g(t)] = F_f(\\omega) \\cdot F_g (\\omega) $$ 频域卷积定理：频域内的卷积对应时域内的乘积 $$ F[f(t) \\cdot g(t)] = \\frac {1} {2\\pi} F_f(\\omega) \\star F_g (\\omega) $$ Examlple： import numpy as np f=np.array([1,1,1]) g=np.array([2,3,2,6]) fg=np.convolve(f,g) # convolute n = len(f)+len(g)-1 N = 2**(int(np.log2(n))+1) a=np.fft.rfft(f,N) # make f and g have equal length N, and tranform b=np.fft.rfft(g,N) c=a*b # note here: just element wise multiplication after FT fft_fg=np.fft.irfft(c)[:n] # inverse FT, only top n are valided. print(fg) print(fft_fg) the output is [2 5 7 11 8 6] [2. 5. 7. 11. 8. 6.] Summary: Weighted sum =\u003e convolution =\u003e multiplication after fourier tranform. A short animation explained what convolution is ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:5:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Machine Learning"],"content":"Reference 傅立叶变换（李永乐老师） Fourier Series Euler’s formula ","date":"2020-08-01","objectID":"/2020-08-01-dl-fourier/:6:0","tags":["Deep Learning","Computer Vison"],"title":"Fourier transform for biologist","uri":"/2020-08-01-dl-fourier/"},{"categories":["Nature Language Processing"],"content":"Structure of Sentences: Parse trees Shallow parsing identifies phrasal units, the task of identifying the relationship between them is called parsing. Parse trees indicate how different grammatical units in a sentence are related hierachically. (aslo refer to constituent parse, chart-based ) dependency parsing: directed graph (graph-based) node -\u003e word edge -\u003e relation all the words have one incoming edge, except ROOT there is a unique path from each word to ROOT Contex-free grammars common application: grammer checking semantic analysis question anwsering information extraction ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:1:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Constituency parsing (Syntatic parsing) The task of recognizing a sentence and assigning a syntactic structure to it. ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:2:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"CKY Parsing The most widely used dynamic-porgramming based approach to parsing. See also Earley algorithm and chart parsing ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:2:1","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Dependency parsing Dependency grammars grammatical relation provides the basis for the binary relations that comprise dependency structures. Dependency grammars allow to classify the kinds of grammatical relations, or mammatical function ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:3:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Dependency Formalisms dependency structures are simply directed graphs: $G = (V,A)$, which refer to as arcs Dependency tree is a directed graph that statisfies the following constrains: there is a single designated root node that has no incoming arcs with teh exception of the root node, each vertex has exactly one incoming arc. there is a unique path from the root node to each vertex in $V$ ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:4:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Transition-Based Dependency parsing Shift-reduce parsing SyntaxNet: ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:5:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Graph-Based Dependency parsing motivations: capable of producing non-projective trees parsing accuarcy, particularly with respect to longer dependencies. ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:6:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Maximun spanning tree (MST) construct a fully-connected, weighted, directed, rooted graph where the vertices are input words and the directed edges represent all possible head-dependent assignments. The weights reflect the score for each possible head-dependent relation. every vertex in a spanning tree has exactly one incoming edge absolute values of the edge scores are not critical to determining its maximum spanning tree. But relative weights of the edges entering each vertex that matters ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:6:1","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Reference Hung-yi Lee: Deep Learning for human language processing ","date":"2020-08-01","objectID":"/2020-08-01-nlp-constituency-and-depenency-parsing/:7:0","tags":["Deep Learning","NLP"],"title":"NLP: Parse trees","uri":"/2020-08-01-nlp-constituency-and-depenency-parsing/"},{"categories":["Nature Language Processing"],"content":"Backpropagation Through Time ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:1:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Long Short-Term Memory Delete information from the context that is no longer needed: Forget Gate f $$ f_t = \\sigma (U_f h_{t-1} + W_f X_t) $$ $$ k_t = c_{t-1} \\odot f_t $$ Compute the actual information we need to extract from the previous hidden stat and current inputs $$ g_t = \\tanh (U_g h_{t-1} + W_g x_t) $$ Select the information to add to the current context: Add Gate i $$ i_t = \\sigma (U_i h_{t-1} + W_i X_t) $$ $$ j_t = g_{t} \\odot i_t $$ Get new context vector $$ c_t = j_t + k_t $$ Output Gate o: decide what information is required for the current hiddent state (as opposed to what information need to be preseved for future decicions) $$ o_t = \\sigma (U_o h_{t-1} + W_o x_t) $$ $$ h_t = o_t \\odot \\tanh (c_t) $$ ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:2:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Gated Recurrent Units GRU ease the tranning burden by dispensing with the use of a separate context vector, and by reducing the number of gates to 2: a reset gate, $r$: decide which aspects of the previous hidden state are relevant to the current context and what can be ignored. $$ r_t = \\sigma (U_r h_{t-1} + W_r x_t) $$ Then computing an intermediate representation for the new hidden stat at time $t$ $$ \\tilde h_t = \\tanh (U(r_t \\odot h_{t-1}) + Wx_t) $$ an update gate, $z$: detemine which aspects of the new intermedicate representation will be used directly and which aspects of the previous stat need to be preseverd for future use $$ z_t = \\sigma (U_z h_{t-1} + W_z x_t) $$ $$ h_t = (1- z_t)h_{t-1} + z_t \\tilde h_t $$ ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:3:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Example: Text Classification import torch import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, num_layers, num_classes): super(RNN, self).__init__() self.num_layers = num_layers self.hidden_size = hidden_size ## MARK: work with nn.RNN, nn.GRU, nn.LSTM self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True) # Batch x Seq_len x embeding_size (input_size) self.fc = nn.Linear(hidden_size, num_classes) def forward(self, inputs): ## MARK: init hidden state (h0) hidden = torch.zeros(self.num_layers, inputs.size(0), self.hidden_size) # if LSTM, need init cell state (c0) # cell = torch.zeros(self.num_layers, inputs.size(0), self.hidden_size) out, hidden = self.rnn(inputs, hidden) # out: B x S x hidden_size # out, (hidden, cell) = self.rnn(inputs, (hidden, cell)) ## Mark: only need last output for sentence classification out = out[:,-1,:] # out: B x hidden_size out = self.fc(out) return out ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:3:1","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Attention mechanism Consider Encoder to Deconder Network, a decoder $$ h_i^d = g(\\hat y_{i-1}, h_{i-1}^d, c_i) $$ computing context vector $c_i$: a vector of scores that capture the relevance of each encoder hidden state to the decoder state captured in $h_{i-1}^d$. That’s, at each state $i$ during decoding, we’ll compute $score(h_{i-1}^d, h_j^e)$ for each encoder state $j$. Recall similarity $$ score(h_{i-1}^d, h_j^e) = h_{i-1}^d \\cdot h_j^e $$ make a more robust similarity score by adding a learnable weights, $W_s$: $$ score(h_{i-1}^d, h_j^e) = h_{i-1}^d W_s h_j^e $$ normalize the scores $$ \\begin{aligned} \\alpha_{ij} \u0026= \\operatorname{softmax} (score(h_{i-1}^d, h_j^e)) \\cr \u0026= \\frac {\\exp (score(h_{i-1}^d, h_j^e))} {\\sum_k score(h_{i-1}^d, h_j^e)} \\end{aligned} $$ finally, give $\\alpha$, $$ c_i = \\sum_j \\alpha_{ij}h_j^e $$ ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:4:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Self-Attention create 3 vectors from each of the encoders’ input vector, a Query vector, a Key vector and a Value vector, then multiplying the embedding (of word) X calculate a score by taking the dot product of the Query with the Key divide the scores by the square root of the dimension of the key vector (a more stable gradients), then pass the result grought a softmax. multiply each Value vector by the softmax score sum up the weighted value vectors multi-head attention: to focus on different region and give “representation subspace” ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:5:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Transformer A transformer of two stacked encoder and decoder looks like this ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:6:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Positoinal encoding Transformer use positoinal encoding vector to representing the order of the sequence. It follows a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. let $t$ be the position in an input sentence, $\\overrightarrow{p_{t}} \\in R^d$ be the encoding, $d$ be the encoding dimension, then $$ \\overrightarrow{p_{t}}^{(i)}=f(t)^{(i)}:= \\begin{cases} \\sin (\\omega_{k} \\cdot t), \u0026 \\text { if } i=2 k \\cr \\cos (\\omega_{k} \\cdot t), \u0026 \\text { if } i=2 k+1 \\end{cases} $$ where $$ \\omega_{k}=\\frac{1}{10000^{2 k / d}} $$ image that the positional embeding look like this: $$ \\overrightarrow{p_{t}}=\\left[\\begin{array}{c} \\sin \\left(\\omega_{1} \\cdot t\\right) \\cr \\cos \\left(\\omega_{1} \\cdot t\\right) \\cr \\sin \\left(\\omega_{2} \\cdot t\\right) \\cr \\cos \\left(\\omega_{2} \\cdot t\\right) \\cr \\vdots \\cr \\sin \\left(\\omega_{d / 2} \\cdot t\\right) \\cr \\cos \\left(\\omega_{d / 2} \\cdot t\\right) \\end{array}\\right]_{d \\times 1} $$ Word embeding + Positional encoding: For every word $\\omega_{t}$ in a sentence, calculating the correspondent embedding which is fed to the model is as follows: $$ \\psi^{\\prime}\\left(w_{t}\\right)=\\psi\\left(w_{t}\\right)+\\overrightarrow{p_{t}} $$ To make this summation possible, keep $$d_{\\text{word embed}} = d_{\\text {pos embed}}$$ ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:6:1","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Encoder: Self-attention: 计算的是src或trg自身的词与词之间的依赖关系 (之前教程的Attention则是计算src的词与trg的词之间的依赖关系) 每个input token转成w2v 用w2v乘以三个权重矩阵(Wq,Wk,Wv)得到三个(Query,Key,Value)向量, q,k,v 用该位置token的q乘以自己以及其他token的k, 得到self-attention分数值 分数值除以一个常数(default 8), 让梯度更稳定, 然后放入softmax, 得到自己与其他每个token的权重 所有位置的权重乘以v并相加, 得到self-attention在该位置的输出 Z $$A(Q,K,V)= \\operatorname{softmax} ( \\frac{QK^{T}}{ \\sqrt d_{k}})V=Z$$ Multi-Headed Attention - 扩展了模型专注于不同位置的能力: 把上述Self-attention的过程做8次, 即开始就初始化8组权重矩阵(Wq,Wk,Wv), 得到8个Q,K,V矩阵, 通过上述计算最后得到8个 Z 将8个Z合并, 并乘以另一权重矩阵Wo, 最终得到一个Z矩阵 Positional Encoding - 表示序列的顺序将src的position放入到embedding layer Layer Normalization - 解决多层神经网络训练困难的问题，通过将前一层的信息无差的传递到下一层, 使特征的平均值为0, 标准差为1, 更容易训练 ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:6:2","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Decoder 与 Encoder 相似, 但比Encoder多了一层Multi-Headed Attention 一层是src或trg自身的词与词之间的依赖关系, 另一层是是计算src的词与trg的词之间的依赖关系 Mask Padding Mask - Encoder和Decoder都会用到, 大小与batch size对齐后序列一致, 的部分为0, 其余为1 Sequence/Subsequent Mask - Decoder会用到, 为了使其看不到未来的信息(使Decoder输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 和 t 之后的输出), 通过下三角矩阵解决, 且下三角矩阵应与decoder的padding mask 结合 ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:6:3","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"PositionwiseFeedforwardLayer: after attetnion operation, apply a fc layer first to transformed from hid_dim to pf_dim (512 to 2048) apply relu activation function (In BERT, use glue activation function) apply dropout apply another fc layer to transformed from pf_dim to hid_dim ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:6:4","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Nature Language Processing"],"content":"Reference GRU and LSTM transformer transformer code breakdown: pytorch what and why postional encoding ","date":"2020-07-31","objectID":"/2020-07-31-nlp-rnn/:7:0","tags":["Deep Learning","NLP"],"title":"NLP: RNN and Transformers","uri":"/2020-07-31-nlp-rnn/"},{"categories":["Machine Learning with Graphs"],"content":"More about Graph Neural Network ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Algebra presentation of Graphs ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"1. Adjacency matrix $$ A_{i j}= \\begin{cases} 1 \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise } \\end{cases} $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:1","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"2. Degree matrix: D is a diagonal matrix, where $$ D_{ii} = d(v_i) $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:2","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"3. Laplacian matrix What and why Laplacian matrix if we consider all edges in graph $G$ to be undirected, then Laplacian matrix $L$ could be defined as $$ L = D-A $$ Thus, we have the elements: $$ L_{i j}=\\begin{cases} d\\left(v_{i}\\right) \u0026 \\text { if } i=j \\cr -1 \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise. } \\end{cases}. $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:3","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"4. Symmetric normalized Laplacian the symmetric normalized Laplacian is define as: $$ \\begin{aligned} L^{sym} \u0026=D^{-\\frac{1}{2}} L D^{-\\frac{1}{2}} \\cr \u0026=I-D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}} \\end{aligned} $$ The elements are given by: $$ L_{i j}^{s y m}=\\begin{cases} 1 \u0026 \\text { if } i=j \\text { and } d\\left(v_{i}\\right) \\neq 0 \\cr -\\frac{1}{\\sqrt{d\\left(v_{i}\\right) d\\left(v_{j}\\right)}} \u0026 \\text { if } \\lbrace v_{i}, v_{j} \\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise. } \\end{cases} $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:4","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"5. Random walk nmormalized Laplacian $$ L^{rw} = D^{-1}L = I - D^{-1}A $$ The elements can be computed by: $$ L_{i j}^{r w}= \\begin{cases} 1 \u0026 \\text { if } i=j \\text { and } d\\left(v_{i}\\right) \\neq 0 \\cr -\\frac{1}{d\\left(v_{i}\\right)} \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise } \\end{cases} $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:5","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"6. Incidence Matrix $$ M_{i j}= \\begin{cases} 1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{i}, v_{k} \\rbrace \\cr -1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{k}, v_{i} \\rbrace \\cr 0 \u0026 \\text { otherwise. } \\end{cases} $$ for undrected graph, the corresponding incidence matrix statisfies that $$ M_{i j}=\\begin{cases} 1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{i}, v_{k}\\rbrace \\cr 0 \u0026 \\text { otherwise. } \\end{cases}. $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:1:6","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Vanilla Graph Neural Networks A node is defined by its features and related nodes in the graph. The aim of GNN is to lean a state embedding $h_v \\in R^s$, which encodes the information of the neighborhood, for each node. The state embedding $h_v$ is used to produce an output $O_v$, such as the distribution of the predicted node lable. ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Model $$ h_v = f(X_v, X_{co[v]}, h_{ne[v]}, X_{ne[v]}) $$ $$ o_v = g(h_v, X_v) $$ $f$: local transition function, shared amoing all nodes $g$: local output function $X$: the input feature $h$: hidden state $co[v]$: the set of edges connected to node v $ne[v]$: the set of neighbors of node $v$ Now, we have a compact form as $$ H = F(H,X) \\\\ O = G(H, X_N) $$ $F$: the global transition function $G$: the global output funciton GNN use the classic iterative scheme to compute the state $$ H^{t+1} = F(H^t, X) $$ Next question is how to learn parameters of $f$ and $g$. The loss can be written as $$ loss = \\sum_{i = 1}^p(t_i - o_i) $$ where $p$: the number of supervised nodes the state $h_{v}^{t}$ are iteratively updated until a time step $T$. ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:2:1","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Convolutional Networks Spectral approaches and spatial approaches. Four calssic models (Spectral Network, ChebNet, GCN, and AGCN) ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Spectral approaches Spectral Network the convolution operation is defined in the Fourier domain by computing the eigendecomposition of the graph Laplacian. The operation can be defined as multiplication of a signal x (a scalar for each node) with a filter $g_{\\theta} = \\text{diag}(\\theta)$: $$ \\mathbf{g_{\\theta}} \\star \\mathbf{x}=\\mathbf{U g}_{\\theta}(\\Lambda) \\mathbf{U}^{T} \\mathbf{x} $$ $\\mathbf{U}$: the matrix of eigenvectors of the normalized graph Laplacian $L = I_N - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} = \\mathbf{U}\\Lambda\\mathbf{U}^T$ This operation results in potentially intense computations and non-spatially localized filters CHEBNET the operation is $$ \\mathbf{g_\\theta} \\star \\mathbf{x} \\approx \\sum_{k=0}^{K} \\boldsymbol{\\theta}_{k} \\mathbf{T}_{k}(\\tilde{\\mathbf{L}}) \\mathbf{x} $$ $\\tilde{\\mathbf{L}} = \\frac{2}{\\lambda_{max}}L - I_N$ $\\lambda_{max}$: the largest eigenvalue of $L$. $\\theta$: a vector of Chebyshev coefficients $T_{k}(x)$: the Chebyshev ploynomials $T_k(x) = 2xT_{k-1}(x) -T_{k-2}(x)$. $T_0(x) = 1$, $T_1(x) = x$. GCN $$ \\mathbf{g_\\theta^{\\prime}} \\star \\mathbf{x} \\approx \\theta_{0}^{\\prime} \\mathbf{x}+\\theta_{1}^{\\prime}\\left(\\mathbf{L}-\\mathbf{I}_{N}\\right) \\mathbf{x}=\\theta_{0}^{\\prime} \\mathbf{x}-\\theta_{1}^{\\prime} \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{x} $$ then, constraining the number of parameters with $\\theta = \\theta_{0}^{\\prime} = - \\theta_{1}^{\\prime}$, get $$ \\mathbf{g_\\theta} \\star \\mathbf{x} \\approx \\theta\\left(\\mathbf{I}_{N}+\\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}\\right) \\mathbf{x} $$ this operator could lead to numberical instabilities and exploding/vanishing gradients. Finally, introudce the renormalization trick: $I_N + \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\rightarrow \\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}}$, with $\\tilde{A} = A + I_N$, and $\\tilde{D} = \\sum_j\\tilde{A}_{ij}$. Finally $$ \\mathbf{Z}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\mathbf{X} \\Theta $$ $\\Theta \\in \\mathbb{R}^{C \\times F}$: a matrix of filter paramters $\\mathbf{Z} \\in \\mathbb{R}^{N \\times F}$: the convolved signal matrix AGCN Adaptive Graph Convolution Network (AGCN) is proposed to learn the underlying relations. AGCN learns a “residual” graph Laplacian $\\mathbf{L}_{res}$ and add it to the original Lapalcian matrix $$ \\widehat{\\mathbf{L}}=\\mathbf{L}+\\alpha \\mathbf{L}_{r e s} $$ $\\mathbf{L}_{res}$ is computed by learned graph adjacency matrix $\\widehat{\\mathbf{A}}$ $$ \\begin{aligned} \\mathbf{L_{res}} \u0026=\\mathbf{I}-\\widehat{\\mathbf{D}}^{-\\frac{1}{2}} \\widehat{\\mathbf{A}} \\widehat{\\mathbf{D}}^{-\\frac{1}{2}} \\cr \\widehat{\\mathbf{D}} \u0026=\\operatorname{degree}(\\widehat{\\mathbf{A}}) \\end{aligned} $$ $\\widehat{\\mathbf{A}}$ is computed via a learned metric The idea behind the adaptive metric is that Euclidean distance is not suitatble for graph structured data and the metric should be adaptive the the task and input features. ACGN use the generalized Mahalanobis distance $$ D(\\mathbf x_{i}, \\mathbf x_{j})= \\sqrt{ (\\mathbf x_{i}-\\mathbf x_{j})^{T} \\mathbf{M}(\\mathbf x_{i}-\\mathbf x_{j})} $$ where M is a learned prameter taht statisfies $M = W_d W_{d}^T$. ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Spatial Methods spatial approches defined convolutions directly on the graph, operating on spatially close neighbors. The major challenge of spatial approches is defining the convolution operation with differently sized neighborhoods and maintaining the local invariance of CNNs. Nerual FPS Use different weight matris for nodes with different degrees $$ \\begin{aligned} \\mathbf{x} \u0026=\\mathbf{h}{v}^{t-1}+\\sum{i=1}^{\\left|N_{v}\\right|} \\mathbf{h}_{i}^{t-1} \\ \\mathbf{h}_{v}^{t} \u0026=\\sigma\\left(\\mathbf{x} \\mathbf{W}_{t}^{\\left|N_{v}\\right|}\\right) \\end{aligned} $$ Patchy-SAN first selects and normalized exactly k neigbors for each node, then normalized neighhorhos servers as the receptive filed and the convolutional operation is applied. Node sequence selection Neighorhood assembly Graph normalization Convolution architecture. DCNN the diffusion-convolution neural network (DCNN) for node classification $$ H = \\sigma(W^c \\odot P^*X) $$ P*: N x K x N tensor, contains the power series $\\lbrace P, P^2, \\cdots, P^K \\rbrace$ X: N x F tensor of input features for graph classification $$ H = \\sigma(W^c \\odot 1^T_N P^* X /N) $$ $1_N$: N x 1 vector of ones. DGCN dual grpah convolutional network, which jointly consider the local consistency and global consitency on graphs. It use 2 convolutional networks to capture the local/global consistency and adopts an unsupervised loss to ensemble them. first network: $$ \\mathbf{Z}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\mathbf{X} \\Theta $$ second network replace the adjacency matrix with positive pointwise mutual information (PPMI) matrix $$ \\mathbf H^{\\prime}=\\sigma(\\mathbf D_{P}^{-\\frac{1}{2}} \\mathbf{X}_{P} \\mathbf D_{P}^{-\\frac{1}{2}} \\mathbf H \\Theta) $$ Assemble these two convolutions via the final loss function $$ L=L_{0}\\left(\\operatorname{Conv}_{A}\\right)+\\lambda(t) L_{r e g}\\left(\\operatorname{Conv}_{A}, \\operatorname{Conv}_{P}\\right) $$ $\\lambda(t)$ is the dynamic weight to blance the importance of these two loss functions. $$ L_{0}\\left(\\operatorname{Conv}_{A}\\right)=-\\frac{1}{\\left|y_{L}\\right|} \\sum_{l \\in y_{L}} \\sum_{i=1}^{c} Y_{l, i} \\ln \\left(\\widehat{Z}_{l, i}^{A}\\right) $$ $$ L_{r e g}\\left(\\operatorname{Conv}_{A}, \\operatorname{Conv}_{P}\\right)=\\frac{1}{n} \\sum_{i=1}^{n}\\left|\\widehat{Z}_{i,:}^{P}-\\widehat{Z}_{i,:}^{A}\\right|^{2} $$ LGCN learnable graph conovlutional networks MONET A propose spatial-domain model (MoNet) on non-Euclidean domains which could generalized serveal previous network. GCNN, ACNN, GCN, DCNN GRAPHSAGE a general inductive framework. $$ \\begin{aligned} \\mathbf h_{N_{v}}^{t} \u0026=\\text { AGGREGATE }_{t}\\left(\\lbrace \\mathbf{h}_{u}^{t-1}, \\forall u \\in N_{v}\\rbrace \\right) \\cr \\mathbf{h}_{v}^{t} \u0026=\\sigma\\left(\\mathbf{W}^{t} \\cdot\\left[\\mathbf{h}_{v}^{t-1} | \\mathbf{h}_{N_{v}}^{t}\\right]\\right) \\end{aligned} $$ Mean aggregator $$ \\mathbf h_{v}^{t}=\\sigma\\left(\\mathbf{W} \\cdot \\operatorname{MEAN}\\left(\\lbrace \\mathbf{h}_{v}^{t-1}\\rbrace \\cup\\lbrace \\mathbf{h}_{u}^{t-1}, \\forall u \\in N_{v}\\rbrace \\right)\\right. $$ LSTM aggregator Pooling aggregator $$ \\mathbf h_{N_{v}}^{t} =\\max \\left(\\lbrace \\sigma\\left(\\mathbf{W}_{\\mathrm{pool}} \\mathbf{h}_{u}^{t-1}+\\mathbf{b}\\right), \\forall u \\in N_{v}\\rbrace \\right) $$ an unsupervised loss function which encouage nearby nodes to have similar representations while distant nodes have different representations: $$ J_{G}\\left(\\mathbf{z}_{u}\\right)=-\\log \\left(\\sigma\\left(\\mathbf{z}_{u}^{T} \\mathbf{z}_{v}\\right)\\right)-Q \\cdot E_{v_{n} \\sim P_{n}(v)} \\log \\left(\\sigma\\left(-\\mathbf{z}_{u}^{T} \\mathbf{z}_{v_{n}}\\right)\\right) $$ ","date":"2020-07-26","objectID":"/2020-07-26-dl-gnn/:3:2","tags":["Deep Learning","Graph"],"title":"Graph: GNN review","uri":"/2020-07-26-dl-gnn/"},{"categories":["Machine Learning with Graphs"],"content":"Introduction of Graph Neural Networks ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:0:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Data Eculidean Structure Data: image, video, voice … easy to find adjacent neighbors easy to define distance Non-Eculidean data: Graph, Manifold hard to define adjacent neighbors or the numbers of adjacent nodes varies. means hard to define distance, convolution … ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:1:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Embed (project) Non-Eculidean Data into Eculidean Space using geometric deep learning ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:2:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Graph Neural Network ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:3:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Common tasks graph classification: classcify graphs according to its topology. each graph has a label. most common definition: graph $G = (A, F)$ Adjacency matrix (of G): $A \\in \\lbrace 0,1 \\rbrace ^{n \\times n}$ Feature matrix (of nodes): $F \\in R^{n \\times d}$, with n nodes, d features Given $\\mathcal{D} = \\lbrace (G_1, y_1), \\cdots, (G_n, y_n) \\rbrace$, learn $$ f: \\mathcal{G} \\rightarrow \\mathcal{Y} $$ node classification: each node has a label generative graph (models): e.g. virtual drug screen ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:3:1","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Algebra Presentation of Graphs Adjacency matrix $$ A_{i j}= \\begin{cases} 1 \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise } \\end{cases} $$ Degree matrix: D is a diagonal matrix, where $$ D_{ii} = d(v_i) $$ Laplacian matrix: if we consider all edges in graph $G$ to be undirected, then Laplacian matrix $L$ could be defined as $$ L = D-A $$ Thus, we have the elements: $$ L_{i j}=\\begin{cases} d\\left(v_{i}\\right) \u0026 \\text { if } i=j \\cr -1 \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise. } \\end{cases}. $$ What and why Laplacian matrix The key to understand Laplacian is PDE or Heat equation $$ \\frac{\\partial T}{\\partial t}(x, t)=\\alpha \\cdot \\frac{\\partial^{2} T}{\\partial x^{2}}(x, t) $$ Symmetric normalized Laplacian the symmetric normalized Laplacian is define as: $$ \\begin{aligned} L^{sym} \u0026=D^{-\\frac{1}{2}} L D^{-\\frac{1}{2}} \\cr \u0026=I-D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}} \\end{aligned} $$ The elements are given by: $$ L_{i j}^{s y m}=\\begin{cases} 1 \u0026 \\text { if } i=j \\text { and } d\\left(v_{i}\\right) \\neq 0 \\cr -\\frac{1}{\\sqrt{d\\left(v_{i}\\right) d\\left(v_{j}\\right)}} \u0026 \\text { if } \\lbrace v_{i}, v_{j} \\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise. } \\end{cases} $$ Random walk nmormalized Laplacian $$ L^{rw} = D^{-1}L = I - D^{-1}A $$ The elements can be computed by: $$ L_{i j}^{r w}= \\begin{cases} 1 \u0026 \\text { if } i=j \\text { and } d\\left(v_{i}\\right) \\neq 0 \\cr -\\frac{1}{d\\left(v_{i}\\right)} \u0026 \\text { if }\\lbrace v_{i}, v_{j}\\rbrace \\in E \\text { and } i \\neq j \\cr 0 \u0026 \\text { otherwise } \\end{cases} $$ Incidence Matrix $$ M_{i j}= \\begin{cases} 1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{i}, v_{k} \\rbrace \\cr -1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{k}, v_{i} \\rbrace \\cr 0 \u0026 \\text { otherwise. } \\end{cases} $$ for undrected graph, the corresponding incidence matrix statisfies that $$ M_{i j}=\\begin{cases} 1 \u0026 \\text { if } \\exists k \\text { s.t } e_{j}=\\lbrace v_{i}, v_{k}\\rbrace \\cr 0 \u0026 \\text { otherwise. } \\end{cases}. $$ ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:3:2","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Convolution on Spectral The key to understand graph convolution: Laplacian matrix Laplacian matrix wikepedia Newton’s law of cooling Heat equation Now, the convolution operation is defined in the Fourier domain by computing the eigendecomposition of the Laplacian Matrix $$ L = U \\Lambda U^{-1} = U \\Lambda U^T $$ Note: $U$ is an orthognal matrix, $U^{-1} = U^T$ Then, given $x \\in R^n$, the fourier transform: $\\hat{x} = U^{T} x$ reverse fourier transform: $x = U \\hat{x}$ Finally, given signal $x$ and kernel $y$, the graph fourier transform ($*_{\\mathcal{g}}$) is $$ x *_{\\mathcal{G}} y=U\\left(\\left(U^{T} x\\right) \\odot\\left(U^{T} y\\right)\\right) $$ $\\odot$: element-wise multiplication As we have a kernel $g_{\\theta}(\\sdot)$, $$ y=g_{\\theta}(L)(x)=g_{\\theta}\\left(U \\Lambda U^{T}\\right) x=U g_{\\theta}(\\Lambda) U^{T} x $$ where $$ g_{\\theta}(\\Lambda)=\\operatorname{diag}(\\theta)=\\left[\\begin{array}{ccc} \\theta_{1} \u0026 \\cdots \u0026 0 \\cr \\vdots \u0026 \\ddots \u0026 \\vdots \\cr 0 \u0026 \\cdots \u0026 \\theta_{n-1} \\end{array}\\right] $$ The learned parameters are in $\\operatorname{diag}(\\theta)$ The problems: lost local connectivity on space (e.g. CNN on images preserve locality) computational complexity $O(n)$, not well generalized on large scale Graphs Need more knowledge of the Chebyshev ploynomials to get deeper. see my next post about GNN. ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:4:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Convolution on Spatial Another way to understand graph convolution: Message Passing. ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:5:0","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Message passing Message passing: node $\\mathcal{S}_1$ and its neigbor $\\mathcal{N}$ (B1, B2, B3), aggregate $\\mathcal{N}$'s message to $\\mathcal{S}_1$. for example, aggreate (sum) each nodes’s features $H^{(l)} \\in R^d$, $$ \\sum_{u \\in \\mathcal{N}(v)} H^{(l)}(u) \\in \\mathbb{R}^{d_{i}} $$ node $v$'s neigbors: $\\mathcal{N(v)}$, layer: $l$ Generally, we add a linear transform matrix $W^{(l)} \\in R^{d_i \\times d_o}$ to change the feature dimension. $$ \\left(\\sum_{u \\in \\mathcal{N}(v)} H^{(l)}(u)\\right) W^{(l)} \\in \\mathbb{R}^{d_{o}} $$ After add activate function, get a more compact equation $$ f(H^{(l)}, A) = \\sigma ( A H^{(l)}W^{(l)}) $$ $A$: Adjacency Matrix ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:5:1","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Example Given graph input feature (10 dim): $f_{in} \\in R^{10}$ output feature (20 dim): $f_{out} \\in R^{20}$ each node’s feature: $H^{(l)} \\in R^{6 \\times 10}$ weight: $W^{(l)} \\in R^{10 \\times 20}$ adjcency matrix: $A \\in R^{6 \\times 6}$ Message passing step: feature dimension change: $HW \\in R^{6 \\times 20}$ select the neigborhood nodes: $AHW$ The problems: Each node have different degree, make the scale of output feature map will completely change (see each row of adjcency matrix). So, we have to normalize laplacian matrix. Each node did not include information from itself. So need to make a self connection. ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:5:2","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Machine Learning with Graphs"],"content":"Definition Adjcency Matrix: $$ \\tilde{A} = A + I_n $$ Degree Matrix: $$ \\tilde D_{ii} = \\sum_{j} \\tilde{A}_{ij} $$ Random Walk Normalization of A: make row sum equal to 1 $$ \\tilde{A} = D^{-1}A $$ Symmetric Normalization: used more in practice, more dynamic. $$ A = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} $$ Laplacian matrix normliaztion: $$ \\begin{aligned} L^{sym} \u0026= D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} \\cr \u0026= D^{-\\frac{1}{2}}(D-A)D^{-\\frac{1}{2}} \\cr \u0026= I_n - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} \\end{aligned} $$ Finally, we have $$ H^{(l+1)} = \\sigma ( \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}) $$ $\\tilde{A} = A+ I_n$ $\\tilde D_ii = \\sum_j \\tilde A_{ij}$ ","date":"2020-07-25","objectID":"/2020-07-25-dl-geometric/:5:3","tags":["Deep Learning","Graph"],"title":"Graph: GNN basics","uri":"/2020-07-25-dl-geometric/"},{"categories":["Coding"],"content":"Get answers for C/C++ within ? s","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"A Cuda/C++ starter cheatsheet ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:0:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"Harward and software Thread block and grid are logical threads, make programming easy. In hardware, each GPU made of lots of streaming multiprocessor(hardware), which have lots of threads. ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:1:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"Concepts kernel: the code (function) run on GPU one kernel, only have one grid, grid have blocks, block has threads. thread, block,grid threadIdx: each thread have a unique id, threadIdx.x, .y,.z blockIdx: each block have a unique id, blockIdx.x, .y,.z dimemnsion size: blockDim.x,gridDim.x, .y,.z ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:2:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"thread management Stream Each GPU made of lots of Streams(hardware). When a kernel grid activate, multi block will assign blocks to avaibable stream to run. Warp For SM(hardware), CUDA run as warp(线程束), SM don’t know where the block, who they are. In hardware, the thread resource are limited, not all logical threads run at the same time. The minimun physical threads run at the same time are called warp. for example: if one block assigned 128 threads, when running on Stream, this block divied into warp0: thread 0,........thread31 warp1: thread 32,........thread63 warp2: thread 64,........thread95 warp3: thread 96,........thread127 ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:3:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"special keywords device: GPU host: CPU compile with nvcc, not gcc keyword execution called by other __global__ device device or host must return void __device__ device device __host__ host host defaut, could omit kernel launch: \u003c\u003c\u003cDg,Db,Ns,S\u003e\u003e\u003e Dg (dim3): specifies the dimension and size of the grid. Db (dim3): specifies the dimension and size of each block Ns (size_t): specifies the number of bytes in shared memory that is dynamically allocated per block for this call in addition to the statically allocated memory. S (cudaStream_t): specifies the associated stream, is an optional parameter which defaults to 0. from docs ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:4:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"Vertors ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:5:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"init 1 dim vector #include \u003cstdio.h\u003e __global__ void initWith(float num, float *a, int N) { int index = threadIdx.x + blockIdx.x * blockDim.x; int stride = blockDim.x * gridDim.x; for(int i = index; i \u003c N; i += stride) { a[i] = num; } } ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:5:1","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"3 dimension index tid=threadIdx.x+threadIdx.y*blockDim.x+threadIdx.z*blockDim.x*blockDim.y ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:5:2","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"vectorized addition __global__ void addVectorsInto(float *result, float *a, float *b, int N) { int index = threadIdx.x + blockIdx.x * blockDim.x; int stride = blockDim.x * gridDim.x; for(int i = index; i \u003c N; i += stride) { result[i] = a[i] + b[i]; } } ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:5:3","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"Common Program Flow ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:0","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"1. Get device int deviceId; int numberOfSMs; // get device cudaGetDevice(\u0026deviceId); cudaDeviceGetAttribute(\u0026numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId); ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:1","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"3. GPU memory allocation const int N = 2\u003c\u003c24; size_t size = N * sizeof(float); float *a; float *b; float *c; // GPU memory allocation cudaMallocManaged(\u0026a, size); cudaMallocManaged(\u0026b, size); cudaMallocManaged(\u0026c, size); // send to GPU cudaMemPrefetchAsync(a, size, deviceId); cudaMemPrefetchAsync(b, size, deviceId); cudaMemPrefetchAsync(c, size, deviceId); size_t threadsPerBlock; size_t numberOfBlocks; // why 32, beacause warp is usually 32 on the hardware design side. // device run more effeciently threadsPerBlock = 256; numberOfBlocks = 32 * numberOfSMs; cudaError_t addVectorsErr; // error handling cudaError_t asyncErr; ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:2","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"4. Create streams /* * Create 3 streams to run initialize the 3 data vectors in parallel. */ cudaStream_t stream1, stream2, stream3; cudaStreamCreate(\u0026stream1); cudaStreamCreate(\u0026stream2); cudaStreamCreate(\u0026stream3); ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:3","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"5. Kernel launch /* * Give each `initWith` launch its own non-standard stream. * note the \u003c\u003c\u003c \u003e\u003e\u003e: also called a “kernel launch” */ initWith\u003c\u003c\u003cnumberOfBlocks, threadsPerBlock, 0, stream1\u003e\u003e\u003e(3, a, N); initWith\u003c\u003c\u003cnumberOfBlocks, threadsPerBlock, 0, stream2\u003e\u003e\u003e(4, b, N); initWith\u003c\u003c\u003cnumberOfBlocks, threadsPerBlock, 0, stream3\u003e\u003e\u003e(0, c, N); // run addVectorsInto\u003c\u003c\u003cnumberOfBlocks, threadsPerBlock\u003e\u003e\u003e(c, a, b, N); addVectorsErr = cudaGetLastError(); if(addVectorsErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(addVectorsErr)); // critical !!! asyncErr = cudaDeviceSynchronize(); if(asyncErr != cudaSuccess) printf(\"Error: %s\\n\", cudaGetErrorString(asyncErr)); ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:4","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"6. fetch data and run on CPU // fetch data to CPU memory cudaMemPrefetchAsync(c, size, cudaCpuDeviceId); // run a func in CPU checkElementsAre(7, c, N); ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:5","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"7. free memory /* * Destroy streams when they are no longer needed. */ cudaStreamDestroy(stream1); cudaStreamDestroy(stream2); cudaStreamDestroy(stream3); // free GPU memory cudaFree(a); cudaFree(b); cudaFree(c); Here is a function run on CPU void checkElementsAre(float target, float *vector, int N) { for(int i = 0; i \u003c N; i++) { if(vector[i] != target) { printf(\"FAIL: vector[%d] - %0.0f does not equal %0.0f\\n\", i, vector[i], target); exit(1); } } printf(\"Success! All values calculated correctly.\\n\"); } ","date":"2020-07-11","objectID":"/2020-07-28-cpp-cuda/:6:6","tags":["C++","CUDA"],"title":"C++ Notes: CUDA","uri":"/2020-07-28-cpp-cuda/"},{"categories":["Coding"],"content":"Get answers for C/C++ within ? s","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"Learn C++11 thread library. Code snippets from Concurrent Programming with C++11 ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:0:0","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"Process vs. Threads ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:1:0","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"Usage Summary A short summary of thread library in STL thread and async /* thread */ std::thread t1(factorial, 6); // create a new thread std::this_thread::sleep_for(chrono::milliseconds(3)); chrono::steady_clock::time_point tp = chrono::steady_clock::now() + chrono::microseconds(4); std::this_thread::sleep_until(tp); /* async() */ std::future\u003cint\u003e fu = async(factorial, 6); // create a new thread mutex /* Mutex */ std::mutex mu; std::lock_guard\u003cmutex\u003e locker(mu); std::unique_lock\u003cmutex\u003e ulocker(mu); ulocker.try_lock(); ulocker.try_lock_for(chrono::nanoseconds(500)); ulocker.try_lock_until(tp); condition variable /* Condition Variable */ std:condition_variable cond; cond.wait_for(ulocker, chrono::microseconds(2)); cond.wait_until(ulocker, tp); future and promise /* Future and Promise */ std::promise\u003cint\u003e p; std::future\u003cint\u003e f = p.get_future(); f.get(); f.wait(); f.wait_for(chrono::milliseconds(2)); f.wait_until(tp); Packaged task /* Packaged Task */ std::packaged_task\u003cint(int)\u003e t(factorial); std::future\u003cint\u003e fu2 = t.get_future(); t(6); ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:2:0","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"Cases ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:0","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"thread two way to create new thread std::thread t1(func); std::async(std::launch::async, func); exmample of thread #incldue \u003cthread\u003e void function1() { std::cout \u003c\u003c\"hello\"\u003c\u003cstd::endl; } std::tread t1(function1); // t1 start running // t1.join(); // main thread wait for t1 to finish t1.detach(); // t1 will freely on its own -- deamon process`` /// once detach, forever detach. if (t1.joinable()) t1.join(); // if detached, this line crashed. ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:1","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"thread managment class Fctor { public: void operator()(std::string \u0026 s) { std::cout\u003c\u003c\"this is thread\"\u003c\u003cstd::endl; } }; std::string = \"string int\" std::thread t1((Fctor()), s); // alway pass by value std::thread t2((Fctor()), std::ref(s)); // pass by ref std::thread t3((Fctor()), std::move(s)); // move s from main to thread std::thread t4 = std::move(t3); // thread could not be copy, only move try { std::cout\u003c\u003c\"this is main\"\u003c\u003cstd::endl; } catch (...) { t1.join(); t2.jion(); throw; } t1.join(); t2.join(); t4.join(); if oversubscription, limit threads with maximum cpu cores std:🧵:hardware_concurrency(); // indication, number of cpu cores ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:2","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"race condition and mutex #include \u003cthread\u003e#include \u003cmutex\u003e std::mutex mu; void shared_print(std::string msg, int id) { std::lock_guard\u003cstd::mutex\u003e guard(mu); // RAII //mu.lock(); // +\u003e safeguard no two threads using cout at the same time, std::cout\u003c\u003cmsg \u003c\u003c id \u003c\u003c std::endl; //mu.unlock(); // if error thrown between .lock() and .unlock(), generate zombie process } void function_1() { for(int i=0; i \u003c 100; i++) shared_print(\"from functino t1\", i); } int main() { std::thread t1(function_1); for (int i=0; i \u003c 100; i++) shared_print(\"from main\", i); t1.join() } more practical example #include \u003cthread\u003e#include \u003cmutex\u003e class LogFile { std::mutex mu; std::ofstream f; public: LogFile() { f.open(\"log.txt\"); } void shared_print(std::string msg, int id) { std::lock_guard\u003cstd::mutex\u003e guard(mu); // RAII f \u003c\u003c msg \u003c\u003c id \u003c\u003c std::endl; } // never return f to outside wworld // never pass f as an argument for user }; void function_1(LogFile\u0026 log) { for(int i=0; i \u003c 100; i++) log.shared_print(\"from functino t1\", i); } int main() { LogFile log; std::thread t1(function_1, std::ref(log)); for (int i=0; i \u003c 100; i++) log.shared_print(\"from main\", i); t1.join() } ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:3","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"Advoid Deadlock prefer locking single mutex Advoid locking a mutex and then calling a user provded function use std::lock() to lock more than one mutex lock the mutexs in same order. ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:4","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"unique_lock and lazy initialization class LogFile { std::mutex mu; std::ofstream f; std::once_flag flag; public: LogFile() { f.open(\"log.txt\"); } void shared_print(std::string msg, int id) { // if you need to check whether a file is open in each call, use once_flag to rescue // std::call_once(flag, [\u0026](){ f.open(\"log.txt\");}) // file only open once std::unique_lock\u003cstd::mutex\u003e locker(mu, std::defer_lock); // note here // do something else locker.lock(); f \u003c\u003c msg \u003c\u003c id \u003c\u003c std::endl; locker.unlock(); // call again locker.lock(); // do something ... locker.unlock(); std::unique_lock\u003cstd::mutex\u003e locker2 = std::move(locker); // could change ownership } }; ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:5","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"condition variable Condition variable is to synchronize the execution order of threads std::condition_variable cond; // usage 1 std::unique_lock\u003cstd::mutex\u003e locker(mu); cond.wait(locker); // spurious wake cond.wait(locker, [](){return !q.empty();}) // cond.notify_one(); // notify one waiting thread cond.notify_all(); // ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:6","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"future and promise Future and promise provide a convenience way to communicate between threads. e.g. return value to main thread int factorial(int n) { int res = 1; return res+ n; } int x; std::future\u003cint\u003e fu = std::async(function, 4); // future, get something in future x = fu.get(); // fu.get(); //crash std::future\u003cint\u003e fu2 = std::async(std::launch::deferred, factorial, 4); // means not excuate unitl call .get() x = fu2.get(); // only excuate fu2 when called get std::future\u003cint\u003e fu3 = std::async(std::launch::async | std::launch::deferred , factorial, 4); // create new thread by calling async or not x = fu3.get(); // only excuate fu2 when called get usage of promise int factorial(std::future\u003cint\u003e \u0026f) { int res = 1; int N = f.get(); // note here return res + N; } int x; std::promise\u003cint\u003e p; std::future\u003cint\u003e f = p.get_future(); std::future\u003cint\u003e fu4 = std::async(std::launch::async, factorial, std::ref(f)); // do something else ... //// if p not set, throw error // p.set_exception(std::make_exception_ptr)(std::runtime_error(\"To err is human\")); // set p p.set_value(4); // get from child x = fu4.get(); shared_future for multi-threads int factorial(std::shared_future\u003cint\u003e \u0026f) { int res = 1; int N = f.get(); // note here return res + N; } int x; std::promise\u003cint\u003e p; std::future\u003cint\u003e f = p.get_future(); std::shared_future\u003cint\u003e sf = f.shared(); std::future\u003cint\u003e fu5 = std::async(std::launch::async, factorial, sf); std::future\u003cint\u003e fu6 = std::async(std::launch::async, factorial, sf); std::future\u003cint\u003e fu7 = std::async(std::launch::async, factorial, sf); p.set_value(4); // get from child x = fu4.get(); ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:7","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"using callable object class A { public: void f(int, char) {} long g(double x) {return 0;} int operator()(int n) {return 0;} }; A a; std::thread t1(a, 6); // copy of a() in a different thread std::thread t2(std::ref(a), 6) // a() in a different thread std::thread t3(A(), 6); // temp A std::thread t4([](int x){return x*x;}, 6); std::thread t5(\u0026A::f, a, 6, 'w'); // copy of a.f(6,'w') in a different thread // these feature could be used in // std::bind, std::async ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:8","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Coding"],"content":"packagee tasks packaged_task provides a way to implement a task pool. It can conveniently convey the returned value from a task to a different thread std::thread t1(factorial, 6); // could pass args std::packaged_task\u003cint(int)\u003e t(factorial); // could not pass additional args std::packaged_task\u003cint()\u003e t2(std::bind(factorial, 6)); // now we could pass args using std::bind // ... t(6); // in a different context, t alwaly return void, so int x = t.get_future().get(); // get value // call t2 by t2(); int factorial(int N) { int res =1; for (int i=N; i \u003e 1; i --) res *= i; return res; } std::deque\u003cstd::packaged_task\u003cint()\u003e\u003e task_q; std::mutex mu; std::condition_variable cond; void thread_1() { std::packaged_task\u003cint()\u003e t; { //std::lock_guard\u003cstd::mutex\u003e locker(mu); // advoid data race std::unique_lock\u003cstd::mutex\u003e locker(mu); cond.wait(locker, [](){return !taks_q.empty();}) t = std::move(task_q.front()); task_q.pop_front(); } t(); } int main() { std::thread t1(thread_1); // so, task_q run in t1; std::packaged_task\u003cint()\u003e t(std::bind(factorical, 6)); std::future\u003cint\u003e fu = t.get_future(); // get returned value to main thread { std::lock_guard\u003cstd::mutex\u003e locker(mu); task_q.push_bask(std::move(t)); } std::cout\u003c\u003cfu.get(); t1.join(); return 0; } Summary: 3 method to get a future promise::get_future() packaged_task::get_future() async() returns a future ","date":"2020-07-10","objectID":"/2020-07-10-cpp-threading/:3:9","tags":["C++"],"title":"C++ Notes: Concurrency","uri":"/2020-07-10-cpp-threading/"},{"categories":["Statistic"],"content":"one-way ANOVA from scratch Calculate the Sum of Squares Total (SST): $$ SS_{total} = \\sum_{j=1}^k \\sum_{i=1}^l (X_{ij} - \\bar{X})^2 $$ Calculate the Sum of Squares Within Groups (SSW): $$ SS_{within} = \\sum_{j=1}^k \\sum_{i=1}^l (X_{ij} - \\bar{X_j})^2 $$ Calculate the Sum of Squares Between Groups (SSB): $$ SS_{between} = \\sum_{j=1}^k n_j ( \\bar X_{j} - \\bar{X}) ^2 $$ $n_j$: numbers of individual point in group j. Verify that $$ SS_{total} = SS_{between} + SS_{within} $$ Calculate the Degrees of Freedom (df) Calculate the Degrees of Freedom Total (DFT) $$ df_{total} = n -1 $$ Calculate the Degrees Between k Groups (DFB) $$ df_{bewteen} = k -1 $$ Calculate the Degrees of Freedom Within Groups (DFW) $$ df_{within} = n - k $$ Verify that $$ df_t = df_w + df_b $$ Calculate the Mean Squares Calculate the Mean Squares Between (MSB) $$ MS_{between} = \\frac{SS_{between}}{df_{between}} $$ Calculate the Mean Squares Within (MSW) $$ MS_{within} = \\frac{SS_{within}}{df_{within}} $$ Calculate the F Statistic $$ F = \\frac{ MS_{between}}{MS_{within}} $$ get pvalue import scipy.stats as stat pvalue = stat.f.sf(F, dfb, dfw) # sf: pvalue = 1 - stat.f.cdf() ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:1:0","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"ANOVA Effect size Omega squared (ω2) is a measure of effect size, or the degree of association for a population. It is an estimate of how much variance in the response variables are accounted for by the explanatory variables. Omega squared is widely viewed as a lesser biased alternative to eta-squared, especially when sample sizes are small. MSerror: mean square error SSE/df(error) Formula $$ \\omega^2 = \\frac {SS_{Effect} - df_{Effect} MS_{error}}{SS_{total} + MS_{error}} $$ for multi-factor, completely randomized design, Formula $$ \\omega^2 = \\frac {SS_{Effect} - df_{Effect} MS_{errors}} {SS_{Effect} + (N-df_{Effect}) MS_{error}} $$ Interpreting Results ω2 can have values between ± 1. Zero indicates no effect. If the observed F is less than one, ω2 will be negative. ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:2:0","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"ANOVA Post-hoc comparison ANOVA does not tell which group are significantly different from each other. To know the pairs of significant different groups, we could perform multiple pairwise comparison (Post-hoc comparison) analysis using Tukey HSD test. from statsmodels.stats.multicomp import pairwise_tukeyhsd # perform multiple pairwise comparison (Tukey HSD) m_comp = pairwise_tukeyhsd(endog=d_melt['value'], groups=d_melt['treatments'], alpha=0.05) ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:3:0","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"Two-way (two factor) ANOVA example # load packages import statsmodels.api as sm from statsmodels.formula.api import ols # Ordinary Least Squares (OLS) model # C(): as categorical # C(Genotype):C(years) represent interaction term model = ols('value ~ C(Genotype) + C(years) + C(Genotype):C(years)', data=d_melt).fit() anova_table = sm.stats.anova_lm(model, typ=2) anova_table see more about ANOVA in python here ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:4:0","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"Advanced ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:5:0","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"One way Anova is a multiple regression model $$ y = \\beta_{0} + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\cdots, H_0 : y = \\beta_0 $$ $x_i$￼ are indicators ( $x = \\lbrace￼ 0,1\\rbrace$), where at most one $x_i = 1$ while all other $x_i = 0$. The Kruskal-wallis test (non-parametric test) is simply a one-way ANOVA on the rank-transformed y (value). $$ rank(y) = \\beta_{0} + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\cdots $$ ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:5:1","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"ANCOVA This is simply ANOVA with a continuous regressor added so that it now contains continuous and (dummy-coded) categorical predictors. $$ y = \\beta_{0} + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n age $$ $\\beta_0$ is now the mean for the first group at age=0. ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:5:2","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"Reference See: Common statistical tests are linear models (or: how to teach stats) R version by Jonas Kristoffer Lindeløv Python port by George Ho ","date":"2020-06-30","objectID":"/2020-06-30-stats-anova/:5:3","tags":null,"title":"ANOVA","uri":"/2020-06-30-stats-anova/"},{"categories":["Statistic"],"content":"Censoring Censoring Surivial without Censoring Surivial with Censoring ","date":"2020-06-22","objectID":"/2020-06-22-stats-survival-analysis/:1:0","tags":null,"title":"Survival Analysis","uri":"/2020-06-22-stats-survival-analysis/"},{"categories":["Statistic"],"content":"Kaplan Meier Curve More individual in each group, better sepration of the group, better p-value Takes censoring into account Estimates probabilitu of “survival” on a given day Conditional probability of surviving on a given day: $$ \\frac {N_{ \\text{“alive” day before}} - N_{ \\text{“dying” nextday}}} { \\text{“alive” day before}} $$ Kaplan-Meier survival curve Survival times $t_1 \\leq t_2 \\leq \\cdots \\leq t_n$ The proportion of subjects, $S(t)$, surviving beyoind any follow up time $t$ is estimated by (conditional probability): $$ S(t) = \\frac {r_1 - d_1}{r_1} \\times \\frac {r_2 - d_2}{r_2} \\times \\cdots \\times \\frac{r_p - d_p}{r_p} $$ where $t_p$ is the largest survival time less han or equal to $t$ $r_i$ is the number of subjects alive just before time $t_i$ $d_i$ = numebr who died at time $t_i$ for censored obeservations $d_i = 0$ ","date":"2020-06-22","objectID":"/2020-06-22-stats-survival-analysis/:2:0","tags":null,"title":"Survival Analysis","uri":"/2020-06-22-stats-survival-analysis/"},{"categories":["Statistic"],"content":"Statistic ","date":"2020-06-22","objectID":"/2020-06-22-stats-survival-analysis/:3:0","tags":null,"title":"Survival Analysis","uri":"/2020-06-22-stats-survival-analysis/"},{"categories":["Statistic"],"content":"Log Rank Test Compares survival times of two independent groups. Assumes that the relative risk of event (e.g. death) between the two groups is constant (proportional hazards) Ranks the survial times combined and compared observed and expected rates Null hypothesis: the rates of events (death) in the two groups are equal under $H_0$, $$ X^2 = \\frac { (O_A - E_A)^2}{E_A} + \\frac { (O_B - E_B)^2}{E_B} \\sim \\chi^2 $$ $O_A$: observed events in group A $E_A$: expected events in gorup A under null hypohesis expect = (proportion in risk set) * (# of failures over both groups) $$ e_{1j} = ( \\frac{ n_{1j}}{ n_{1j} + n_{2j}}) \\times ( m_{1j} + m_{2j}) $$ $$ e_{2j} = ( \\frac{ n_{2j}}{ n_{1j} + n_{2j}}) \\times ( m_{1j} + m_{2j}) $$ ","date":"2020-06-22","objectID":"/2020-06-22-stats-survival-analysis/:3:1","tags":null,"title":"Survival Analysis","uri":"/2020-06-22-stats-survival-analysis/"},{"categories":["Statistic"],"content":"Cox Regression Extends comparison of survial times to allow different predictors (estimate k variable together) Models the hazard: probability of dying at a point in time, given survival to that point in time $$ H(t) = H_0(t) \\times \\exp(b_1X_1 + b_2X_2 + \\cdots + b_kX_k ) $$ Model links to a baseline hazard, $H_0(t)$ Can accomodate many variables, both discrete and continuous measures of event times Proportional hazards assumption: the hazard for any individual is a fixed proportion of the hazard for any other individual Hazard ratio Exp(B) give the hazard ratio (or relative hazard/risk) ","date":"2020-06-22","objectID":"/2020-06-22-stats-survival-analysis/:3:2","tags":null,"title":"Survival Analysis","uri":"/2020-06-22-stats-survival-analysis/"},{"categories":["Nature Language Processing"],"content":"NLP Basics for the newbies like me ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:0:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Languwage model Models that assigns probabilities to sequences of words are called languwage models. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:1:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Count-based Representation ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:2:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"1. one-hot representation ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:2:1","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"2. BoW: Bag of words Blow describes the occurrence of words within a document. including A Vocabulary of known words A measure of the presence of known words, e.g. count ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:2:2","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"3. TF or TF-IDF representation: Term Frequency Inverse Document Frequency TF: the sum of the one-hot representation of a phrase, sentence or document’s constituent words $$ TF (w) = \\frac { \\text{ Number of the term w appears in the document }} { \\text{Number of terms in the document}} $$ IDF: penalizes common tokens and rewards rare tokens $$ IDF(w) = \\log \\frac{\\text{Number of documents}}{\\text{Number of documents with term w}} $$ TF-IDF: $TF(w) \\times IDF(w)$ ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:2:3","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"4. Positive pointwise Mutual Information (PPMI) An alternative weighting function to tf-idf PPMI is a measure of how often two events x and y occur, compared with what we would expect if they were independent: $$ I(x,y) = \\log_2 \\frac{P(x, y)}{{P(x)}{P(y)}} $$ The pointwise mutual information between a target word w and a context word c is then defined as: $$ PMI(w,c) = \\log_2 \\frac{P(w, c)}{{P(w)}{P(c)}} $$ PMI is a useful tool whenever we need to find words that are strongly associated. PPMI replaces all negative PMI values with zeros: $$ \\operatorname{PPMI}(w,c) = \\max (\\log_2 \\frac{P(w, c)}{{P(w)}{P(c)}}, 0 ) $$ However, PMI has the problem: very rare words tend to have very high PMI values. So, use a different function $P_{\\alpha}(c)$ that raise the probability of the context word to the power of $\\alpha$: $$ \\operatorname{PPMI_{\\alpha}}(w,c) = \\max (\\log_2 \\frac{P(w, c)}{{P(w)}{P_{\\alpha}(c)}}, 0 ) $$ ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:2:4","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Word Embedding ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:3:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"word2vec The intuition here is taht we could just use running text as implicitly supervised training data for such a classifer: a word $s$ that occurs near the target word $apricot$ acts as gold ‘correct answer’ to the question “Is word $w$ likely to show up near $apricot$?” This advoids the need for any sort of hand-labeled superivsion signal. Skip-gram Skip-gram with negative sampling, aslo called SGNS Skip-gram trains a probabilistic classifier that given a test targe word $t$ and its context window of $k$ workds $c_{1:k}$, assigns a probability based on how similar this context window is to the target word. $$ \\begin{aligned} P\\left(+\\mid t, c_{1: k}\\right) \u0026=\\prod_{i=1}^{k} \\frac{1}{1+e^{-t \\cdot c_{i}}} \\cr \\log P\\left(+\\mid t, c_{1: k}\\right) \u0026=\\sum_{i=1}^{k} \\log \\frac{1}{1+e^{-t \\cdot c_{i}}} \\end{aligned} $$ Note: similarity between embeddings (Cosine) $$ Similarity(t,c) \\approx t \\cdot c $$ Skip-gram makes the strong assumption that all context words are independent The intuition of skip-gram is: Treat the target word and a neighboring context word as positive examples; Randomly sample other words in the lexicon to get negative samples; Use logistic regression to train a classifer to distinguid those two case; use the regression weights as the embeddings. CBOW Continueous Bag of Words Model (CBOW) ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:3:1","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"GloVe ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:3:2","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Concepts ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Corpora, Tokens, and Types corpus (plural: corpora): a text dataset tokens (English): words and numeric sequences separated by white-spaces characters or punctuation instance or data point: the text along with its metatdata dataset: a collection of instances types: unique tokens present in a corpus. vocabulary or lexicon: the set of all types in a corpus ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:1","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Unigram, Bigrams, Trigrams, … , N-grams N-grams are fixed-length consecutive token sequence occurring in the text ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:2","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Lemmas and Stems Lemmas are the root forms of words. e.g. the root form of the word fly, can be inflected into other words – flow, flew, flies, flown, flowing … Lemmas, also called citation form. Stemming: use handcrafted rules to strip endings of words to reduce them to a common form called stems ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:3","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Word Senses and Semantics Senses: the different meanings of a word ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:4","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Categorizing Words: POS Tagging Part-of-speech (POS): also known as word classes, or syntactic categories POS divided into two broad supercateogries: closed class types: function words like of, it, and, or you open class types: nouns, verbs, adjectives, adverbs POS tagging: labeling individual words or tokens Common algorithms to do tagging HMM: Hidden Markov Models MEMM: maximum Entropy Markov Models ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:5","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Categorizing Spans: Chunking and Named Entity Recognition a span of text: a contiguous multi-token boundary. chunking or shallow parsing: identify the noun phrases (NP) and verb pharses (VP) in a span of text. A named entity is a string mention of a real-world concept like a person, location, organization, drug name, et. al. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:6","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Coreference The task of deciding whether two strings refer to same entity ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:7","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Minimumn Edit distance A way to quantify string similarity. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:8","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Perplexity The perplexity (sometimes called PP) of a language model on a test set is the inverse probability of the test set, normalised by the number of words. $$\\begin{aligned} \\mathrm{PP}(W) \u0026=P(w_{1} w_{2} \\ldots w_{N})^{-\\frac{1}{N}} \\cr \u0026=\\sqrt[N]{\\frac{1}{P(w_{1} w_{2} \\ldots w_{N})}} \\cr \u0026= \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_{i} \\mid w_{1} \\ldots w_{i-1})}} \\end{aligned} $$ Another way to hink about perplexity: as the weighted average branching factor of a language. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:9","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Entropy Entropy is a measure of information. The entropy of the random variable X is: $$ H(X)=-\\sum_{x \\in \\chi} p(x) \\log _{2} p(x) $$ the log can be computed in any base. If we use log base 2, the resulting value of entropy will mesured in bits. One intuitive way to think about entorpy is as a lower bound on the number of bits it would take to encode a certain desision or piece of information in the optimal coding scheme. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:10","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"Cross-entropy The cross-entropy is useful when we don’t know the actual probability distribution p that generated some data. The cross-entropy of m (a model of p) on p is defined by $$ H(p,m) = \\lim_{n \\rightarrow \\infty} - \\frac{1}{n}\\sum_{W \\in L} p (w_1,\\cdots,w_n) \\log m (w_1, cdots, w_n) $$ the cross-entropy $H(p,m)$ is an upper bound on the entropy $H(p)$. For any model m: $$ H(p) \\leq H(p,m) $$ The more accurate m is, the closer the cross-entropy $H(p,m)$ will be to the true entropy $H(p)$. ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:11","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"The relation of perplexity and cross-entropy The approximation to the cross-entropy of a model $M = P(w_i | W_{i-N+1} \\cdots W_{i-1})$ on a sequence of words W is $$ H(W) = - \\frac{1}{N} \\log P(w_1 w_2 \\cdots w_N) $$ The perplexity of a model P on a seqence of words W is defined as exp of this cross-entropy $$ \\begin{aligned} \\operatorname{Perplexity}(W) \u0026=2^{H(W)} \\cr \u0026=P\\left(w_{1} w_{2} \\ldots w_{N}\\right)^{-\\frac{1}{N}} \\cr \u0026=\\sqrt[N]{\\frac{1}{P\\left(w_{1} w_{2} \\ldots w_{N}\\right)}} \\cr \u0026=\\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P\\left(w_{i} \\mid w_{1} \\ldots w_{i-1}\\right)}} \\end{aligned} $$ ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:4:12","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Nature Language Processing"],"content":"statistical testing The approach to computing p-values(x) in NLP is to use non-parametric tests. e.g. bootstrap test approximate randomization bootstrapping refers to repeated drawing large numbers of smaller samples with replacement from an orignial larger sample. the intuition of the bootstrap test is that we can create many virtual test sets from an observed test set by repeated sampling from it. the method only maks the assumption that sample is representative of the population ","date":"2020-06-20","objectID":"/2020-06-20-nlp-basics/:5:0","tags":["Deep Learning","NLP"],"title":"NLP: Start point for biologist","uri":"/2020-06-20-nlp-basics/"},{"categories":["Statistic"],"content":"样本量、效应量、显著水平和统计功效的统计原理和计算 效应量通常用三种方式来衡量：标准均差（standardized mean difference），几率（odd ratio），(3) 相关系数（correlation coefficient）。 ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:0:0","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"统计原理 可视化样本量、效应量、α和统计功效的关系 Significance The probability of a type I error is usually denoted by $\\alpha$ and is commonly referred to as the signiﬁcance level of a test. \\The probability of a type II error is usually denoted by $\\beta$. ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:1:0","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"显著水平 α Type Error 定义 表示 举例 Ⅰ 型错误 拒绝实际上成立的$H_0$ Ⅰ 型错误的概率用显著水平 α 表示, 假阳性、误诊 II 型错误 拒绝（“接受”）实际上不成立的$H_0$ II 型错误概率用 β 表示 假阴性、漏诊 α 常取值0.05、0.01，α可以取单尾、双尾。需假设检验前预先设定。 β 只取单尾 形象化理解 ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:1:1","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"功效（power） 功效（power）：正确拒绝原假设的概率，记作1-β, 即 $$ 1 - \\beta = \\operatorname{Pr} ( \\text{rejecting } H_0 | H_1 true) $$ 假设检验的功效受以下三个因素影响： 样本量 (n)：其他条件保持不变，样本量越大，功效就越大。 显著性水平 (α)： 其他条件保持不变，显著性水平越低，功效就越小。 两总体之间的差异：其他条件保持不变，总体参数的真实值和估计值之间的差异越大，功效就越大。也可以说，效应量（effect size）越大，功效就越大。 ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:1:2","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"效应量（effect size） 效应量： 样本间差异或相关程度的量化指标。效应量越大，表示两个总体重叠的程度越小，效应越明显。 效应量通常用三种方式来衡量：(1) 标准均差（standardized mean difference），(2) 几率（odd ratio），(3) 相关系数（correlation coefficient）。 Difference family: Effect sizes based on differences between means 标准均差（standardized mean difference） Standardized mean difference: 基于总体均值和方差， 效应量为 $$ \\theta = \\frac{\\mu_1 - \\mu_2}{\\sigma} $$ Cohen’s d : 两总体均值之间的标准差异。适用于两组样本的样本量和方差相似的情况。 $$ d = \\frac{ \\bar{x}_1 - \\bar{x}_2}{s} = \\frac{\\mu_1 - \\mu_2}{\\sigma} $$ s是样本方差 $$ s = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2}} $$ $$ s_1 = \\frac{1}{n_1 -1} \\sum_{i=1}^{n_1} (x_{1,i} - \\bar{x}_1)^2 $$ d = 0.01 to 2.0 Effect size d Reference Very small 0.01 Sawilowsky, 2009 Small 0.20 Cohen, 1988 Medium 0.50 Cohen, 1988 Large 0.80 Cohen, 1988 Very large 1.20 Sawilowsky, 2009 Huge 2.0 Sawilowsky, 2009 Hedges’ g: 是cohen的方法的改进，适用于两组样本的样本量不同的情况。 $$ g = \\frac{ \\bar{x}_1 - \\bar{x}_2}{s^*} $$ 而$s^{*}$是 $$ s^* = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 -2 }} $$ Glass’s Δ （delta）: 和cohen的方法类似，但是只除以控制组(control)的标准差。适用于两组样本的方差不同的情况。 $$ \\Delta = \\frac{ \\bar{x}_1 - \\bar{x}_2}{s_2} $$ Categorical family: Effect sizes for associations among categorical variables Odd ratio (OR) The odds ratio is the odds of success in the treatment group relative to the odds of success in the control group. 适用于binary数据。 Relative risk (RR) or risk ratio the risk (probability) of an event relative to some independent variable. Risk difference or absolute risk reduction the difference in risk (probability) of an event between two groups Cramer’s φ (Phi) or Cramer’s V: 用于测算类别型数据 (nominal data) 的效应量。当类别型变量包含2个类别时，使用Cramer’s phi，如果超过2个类别，那么使用Cramer’s V。 Cohen’s w … Correlation family: Effect sizes based on “variance explained” Pearson r correlation Effect size r small ~ 0.1 medium ~ 0.3 large r \u003e 0.5 Cohen’s $f^2$: 用于测算方差分析ANOVA，多元回归之类的效应量。 多元回归的效应量 $$ f^2 = \\frac{R^2}{1-R^2} $$ where $R^2$ is the squared multiple correlation (Coefficient of determination) ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:1:3","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"功效、效应量和样本量计算 ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:2:0","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"计算样本量 determining-sample-size ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:2:1","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"计算效应量 用statsmodels库计算功效，效应量和样本量的函数都是同一个，只要把需要计算的那个值仍然设为None，把其他想要达到的数值填上即可 单样本t检验： statsmodels.stats.power.tt_solve_power(effect_size=None, nobs=None, alpha=None, power=None, alternative='two-sided') 独立样本t检验： statsmodels.stats.power.tt_ind_solve_power(effect_size=None, nobs1=None, alpha=None, power=None, ratio=1.0, alternative='two-sided') 卡方拟合优度检验： statsmodels.stats.power.GofChisquarePower.solve_power(effect_size=None, nobs=None, alpha=None, power=None, n_bins=2) F方差齐性检验： statsmodels.stats.power.FTestPower.solve_power(effect_size=None, df_num=None, df_denom=None, nobs=None, alpha=None, power=None, ncc=1) 方差分析： statsmodels.stats.power.FTestAnovaPower.solve_power(effect_size=None, nobs=None, alpha=None, power=None, k_groups=2) ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:2:2","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"StatQuest Sample size Power Analysis 参考： https://en.wikipedia.org/wiki/Effect_size https://www.cnblogs.com/HuZihu/p/12009535.html ","date":"2020-06-14","objectID":"/2020-06-14-stats-effectsize/:3:0","tags":null,"title":"Power, Effect size, Sample size","uri":"/2020-06-14-stats-effectsize/"},{"categories":["Statistic"],"content":"Quantile normalization is frequently used in microarray data analysis. It was introduced as quantile standardization and then renamed as quantile normalization. ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:0:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"Quantile, quartile, percentile ??? Quantiles are just the lines that divide data into equally sized groups. percentiles are just quantiles that divide the data into 100 equally sized groups Example: 0 quartile = 0 quantile = 0th percentile 1 quartile = 0.25 quantile = 25th percentile 2 quartile = .5 quantile = 50th percentile (median) 3 quartile = .75 quantile = 75th percentile 4 quartile = 1 quantile = 100th percentile ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:1:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"Quantile normalization Quantile normalization transform the statistical distributions across samples to be the same. ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:2:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"Assumptions The roughly same distribution of values across samples Most genes are not differentially expressed Assume global differences in the distribution are induced by only technical variation! ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:2:1","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"How Q-normalization work row: genes column: samples/Arrays Procedure: order values within each sample determine a rank from lowest to highest and record the order within each sample Average across rows and substitute value with average re-order averaged values in the original order recorded in 2. Tied rank entries ? Average the tied rank entries’ mean values and substitute. ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:2:2","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"When NOT to normalize Consider a dilution experiment. In which distributions are supposed to decrease (left plot), Q-normalization does the totally wrong thing (right plot). When you expect a real difference in distributions, Q-normalization will create weird artifacts. ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:2:3","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"Smooth quantile ormalizaiton ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:3:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"Assumptions the statistical distribution of each sample should be the same ( or have the same distributional shape) within biological groups or conditions, but allowing that they may differ between groups ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:3:1","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"How to At each quantile, a weight is computed comparing the variability between groups relative to the total variability between and within groups Let gene(g) denote the $g^{th}$ row after sorting each column in the data. For each row, gene(g), we compute the weight $w(g)$ ∈ [0,1], where a weight of 0 implies quantile normalization within groups is applied and a weight of 1 indicates quantile normalization is applied. The weight at each row depends on the between group sum of squares SSB(g) and total sum of squares SST(g), as follows: $$ w_{(g)} = \\operatorname{median} \\bigg\\lbrace 1- \\frac{SSB_{(i)}}{SST_{(i)}} \\bigg\\rbrace \\text{for } i = g -k, \\cdots, g, \\cdots, g+k $$ where $k$ = floor(Total number of genes * 0.05). The number 0.05 is a flexible parameter that can be altered to change the window of the number of genes considered. ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:3:2","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"StatQuest: Quantile Normalization ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:4:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"reference https://en.wikipedia.org/wiki/Quantile_normalization BIOMEDIN 245: Statistical and Machine Learning Methods for Genomics, Stanford Hicks SC, Okrah K, Paulson JN, Quackenbush J, Irizarry RA, Bravo HC. Smooth quantile normalization. Biostatistics. 2018;19(2):185‐198. doi:10.1093/biostatistics/kxx028 ","date":"2020-06-14","objectID":"/2020-06-14-stats-quantile-normalization/:5:0","tags":null,"title":"Quantile normalization","uri":"/2020-06-14-stats-quantile-normalization/"},{"categories":["Statistic"],"content":"What’s Multilevel models, and how to deal with it ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:0:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Statistic"],"content":"What is multilevel model Multilevel model AKA: multilevel Models random-effects models hierarchical models variance-components models random-coefficient models mixed models Many kinds of data, including observational data collected in the human and biological sciences, have a hierarchical or clustered structure, or non-hierarchical structures.. ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:1:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Statistic"],"content":"A Simple Example Given a set of repeated measures data giving growth patterns for a sample of 26 boys in Oxford, England. The height of each boy is measured on nine different occasions. We could try modelling the growth pattern with a simple linear regression $$ H = \\beta_0 + \\beta_1 A + \\epsilon $$ where H: height A: age $\\epsilon$: the variation in height that cannot be explained by the linear relationship with age. However, If we try to use the model above for the complete set of data, the fit will be very poor (see figure above) To make model more realistic, we allow the intercept in the model above to vary from subject to subject. New multilevel model: $$ H_{ij} = \\beta_{0j} + \\beta_1 A_{ji} + \\epsilon_{ij} $$ Now, assume that the individual intercepts follow a normal distribution with variance $\\tau_{0}$, $$ \\beta_{0j} = \\beta_{0} + \\mu_{0j} $$ where, $\\mu_{0j} \\sim \\mathcal{N} (0, \\tau_0)$, $\\mu_{0j}$ accounts for the variation from one subject to another Fitting the multilevel model to the data, and obtain much better predictions ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:2:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Statistic"],"content":"How do multilevel models differ from regression models? $$ H_{ij} = (\\beta_0 + \\mu_{0j}) + \\beta_1 A_{ij} + \\epsilon_{ij} = \\beta_0 + \\beta_1 A_{ij} + \\mu_{0j} + \\epsilon_{ij} $$ The feature that distinguishes this model from an ordinary regression model is the presence of two random variables the measurement level random variable $\\epsilon_{ij}$ the subject level random variable $\\mu_{0j}$ Because multilevel models contain a mix of fixed effects and random effects, they are sometimes known as mixed-effects models. ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:3:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Statistic"],"content":"Benefits of multilevel modelling Generalize to a wider population Fewer parameters are needed Information can be shared between groups ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:4:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Statistic"],"content":"How to deal with hierachical structures Hierarchical structures : model all levels simultaneously Non- Hierarchical structures cross-classified structure multiple membership with weights … 参考： https://en.wikipedia.org/wiki/Multilevel_model http://www.statstutor.ac.uk/resources/uploaded/multilevelmodelling.pdf https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/hierarchical-models.pdf ","date":"2020-06-13","objectID":"/2020-06-13-stats-hierachial-models/:5:0","tags":null,"title":"Multilevel (Hierachical) Models","uri":"/2020-06-13-stats-hierachial-models/"},{"categories":["Machine Learning"],"content":"蒙特卡罗方法，又称统计模拟方法(statistical simulation method), 通过概率模型的随机抽样进行进行近似数值计算的方法。 马可夫蒙特卡罗法（Markov Chain Monte Carlo, MCMC）则是以马可夫链为概率模型的蒙特卡罗方法。 Metropolis-Hastings算法是最基本的MCMC。 Gibbs sampling是更简单、使用更广泛的MCMC。 Markov Chain Monte Carlo (MCMC) ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:0:0","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"蒙特卡罗法（Monte Carlo） 蒙特卡罗法要解决的问题是，假设概率分布的定义己知，通过抽样获得概率分布的随机样本，并通过得到的随机样本对概率分布的特征进行分析 ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:1:0","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"1. 蒙特卡罗方法的核心 蒙特卡罗方法的核心是随机抽样(random sampling) 直接抽样 接受-拒绝抽样： 适用于概率密度函数复杂，不能直接抽样的情况 重要性抽样： 适用于概率密度函数复杂，不能直接抽样的情况 接受-拒绝抽样思想：找一个可以直接抽样的建议分布（proposal distribution），其概率密度函数为$q(x)$, 并且$q(x)$的$c$倍一定大于$p(x)$， 其中$c \u003e 0$,按照$q(x)$进行抽样，假设得到结果$x^\\ast$， 再按照$\\frac{p(x^\\ast)}{cq(x^\\ast )}$的比例随机决定是否接受$x^\\ast$。落到$p(x)$范围内的就接受，落到$p(x)$范围外的就拒绝❌。 这些抽样方法的缺点： 抽样效率低， 比如 $p(x)$ 占 $cq(x)$ 涵盖体积比例很低 当x为高维数据时，很难寻找合适的建议分布 一个解决办法就是MCMC. ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:1:1","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"2. 数学期望估计(Estimation of mathematical expectation) 按照概率分布 $p(x)$ 独立抽取n个样本后计算函数的样本均值 $$ \\hat f_{n}=\\frac{1}{n} \\sum_{i=1}^{n} f\\left(x_{i}\\right) $$ 作为数学期望的近似值。 根据大数定律可知，当样本容量增大是，样本均值以概率1收敛性于数学期望 $$ \\hat f_{n} \\rightarrow E_{p(x)}[f(x)], \\quad n \\rightarrow \\infty $$ 于是，得到数学期望的近似计算方法 $$ E_{p(x)}[f(x)] \\approx \\frac{1}{n} \\sum_{i=1}^{n} f\\left(x_{i}\\right) $$ ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:1:2","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"3. 蒙特卡罗积分（Monte carlo intergration） 计算函数 $h(x)$ 积分 $$ \\int_{\\mathcal{X}} h(x) \\mathrm{d} x $$ 将 $h(x)$ 分解成 $f(x)$ 和概率密度函数 $p(x)$ 的乘积，即函数 $h(x)$ 的积分可以表示为函数 $f(x)$ 关于概率密度函数 $p(x)$ 的数学期望： $$ \\int_{\\mathcal{X}} h(x) \\mathrm{d} x=\\int_{\\mathcal{X}} f(x) p(x) \\mathrm{d} x=E_{p(x)}[f(x)] $$ 因此，可利用样本均值计算近似积分： $$ \\int_{\\mathcal{X}} h(x) \\mathrm{d} x=E_{p(x)}[f(x)] \\approx \\frac{1}{n} \\sum_{i=1}^{n} f\\left(x_{i}\\right) $$ 更进一步 $$ \\begin{aligned} E_{p(z)}[f(z)] \u0026= \\int f(z) p(z) dz \\cr \u0026= \\int \\underbrace{f(z) \\frac{p(z)}{q(z)}}_{new \\tilde{f} (z)} q(z) dz \\cr \u0026 \\approx \\frac{1}{N} \\sum_{n=1}^{N} f(z^{i}) \\frac{p(z^{i})}{q(z^{i})} \\end{aligned} $$ ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:1:3","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"Markov Chain ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:2:0","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"定义 马可夫性： 随机变量$X_t$只依赖$X_{t-1}$，而不依赖过去的随机变量 $\\lbrace X_{0}, X_{1}, \\cdots, X_{t-2} \\rbrace$。即 $$ P\\left(X_{t} | X_{0}, X_{1}, \\cdots, X_{t-1}\\right)=P\\left(X_{t} | X_{t-1}\\right), \\quad t=1,2, \\cdots $$ 马可夫链或马可夫过程（markov process）指： 具有马可夫性的随机序列 $X=\\lbrace X_{0}, X_{1}, \\cdots, X_{t}, \\cdots \\rbrace$。 马可夫链的转移条件概率分布为 $P(X_t | X_{t-1})$ 。转移概率分布决定马可夫链的特性。 时间齐次马可夫链（time homogenous Markov Chain）是指转移状态分布于t无关的马可夫链 离散状态马可夫链 状态转移矩阵 平稳分布： 马可夫链 $X$， 其状态空间为$\\mathcal{S}$， 转移矩阵为 $P = (p_{ij})$， 如果存在状态空间 $\\mathcal{S}$ 上的一个分布 $$ \\pi = \\left[\\begin{array}{c} \\pi_1 \\cr \\pi_2 \\cr \\vdots \\end{array}\\right] $$ 使得 $\\pi=P\\pi$, 则称$\\pi$为马可夫链$X = {X_0, X_1, \\cdots, X_t, \\cdots }$ 的平稳分布 连续状态马可夫链 定义在连续状态空间，转移概率分布有概率转移核（trainsition kernel）表示 $$ P(x, A) = \\int_{A} p(x, y) dy $$ 转移核$P(x, A)$表示转移概率 $$ P (X_t = A | X_{t-1} = x) = P (x, A) $$ 马可夫链的性质 不可约 (irreducible): 时刻 0 从状态 $j$ 出发，时刻 $t$ 到达状态 $i$ 的概率大于 0 ，则称此马尔可夫链 $X$ 是不可约的 $$ P(X_t = i | X_0 = j) \u003e 0 $$ 非周期：不纯在一个状态，使得再返回到这个状态所经历的时间长呈周期性 正常返(positive recurrent): 任意一个状态$i$，从其他任意状态 $j$ 出发，当时间趋近无穷时，首次转移到这个状态$i$的概率 $p^t_{ij}$ 不为0 $$ \\lim_{t \\rightarrow \\infty} p^t_{ij} \u003e 0 $$ 遍历定理：满足相应条件的马尔可夫链，当时间趋于无穷时，马尔可 夫链的状态分布趋近于平稳分布，随机变量的函数的样本均值以概率 1 收敛于该函数 的数学期望 马可夫链 $X$， 其状态空间为$\\mathcal{S}$， 若马可夫链 $X$ 不可约、非周期且正常返， 则马可夫链有唯一的平稳分布 $\\pi = (\\pi_1, \\pi_2, \\cdots)^T$， 并且转移概率的极限分布是马可夫链的平稳分布 $$ \\lim_{t \\rightarrow \\infty} P(X_t = i | X_0 = j) = \\pi_i, i = 1,2, \\cdots ; j = 1,2,\\cdots $$ 若 $f(X)$是定义在状态空间上的函数 $E_{pi}[ | f(X) | ] \u003c \\infty$, 则 $$ P { \\hat{f_t} \\rightarrow E_{pi}[ f(X) ] } = 1 $$ 这里， $$ \\hat{f_t} = \\frac{1}{t} \\sum^t_{s=1} f(x_s) $$ 关于平稳分布 $\\pi = (\\pi_1, \\pi_2, \\cdots)^T$ 的数学期望 $E_{pi}[f(X)] = \\sum f(i)\\pi_i$, 有 $$ \\hat{f_t} \\rightarrow E_{pi}[ f(X) ], t \\rightarrow \\infty $$ 处处成立或以概率1成立。 ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:2:1","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"Markov Chain Monte Carlo 马可夫蒙特卡罗法更适合随机变量是多元的、密度函数是非标准形式的、随机变量各分量不独立等情况 基本思想： 在随机变量$x$的状态空间$\\mathcal{S}$上定一个满足遍历定理的马可夫链，使其平稳分布就是抽样的目标分布 $p(x)$， 然后在这个马可夫链上进行随机游走，每个时刻得到一个样本。根据遍历定理，当时间趋于无穷是，样本的分布趋近平稳分布，样本函数均值趋近函数的数学期望 $$ \\hat{E}f = \\frac{1}{n-m} \\sum^{n}_{i=m+1} f(x_i) $$ 马尔可夫链蒙特卡罗法的关键是如何构建转移核函数或转移矩阵， 包括： Metropolis-Hastings 和 Gibbs sampling。 马尔可夫链蒙特卡罗法中得到的样本序列，相邻的样本点是相关的，而不是独立的 马尔可夫链蒙特卡罗法的收敛性的判断通常是经验性的 基本步骤： 在随机变量$x$的状态空间$\\mathcal{S}$上构建一个满足遍历定理的马可夫链，使其平稳分布为目标分布 $p(x)$ 从状态空间的某一点 $X_0$ 出发，用构造的马可夫链进行随机游走，产生样本序列 ${x_0, x_1, \\cdots, x_t, \\cdots }$。 应用马可夫链的遍历定理， 确定正整数 $m$ 和 $n$， $m \u003c n$， 得到样本集合 ${x_{m+1}, x_{m+2}， \\cdots, x_n }$ 求得函数f的（遍历）均值 $$ \\hat{E}f = \\frac{1}{n-m} \\sum^{n}_{i=m+1} f(x_i) $$ 几个重要问题需要注意： 如何定义马可夫链，保证MCMC成立 如何确定收敛步数m，保证抽样无偏性 如何确定迭代步数n， 保证遍历均值的计算精度 ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:3:0","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"Metropolis-Hastings Metropolis-Hasting是马尔可夫链蒙特卡罗法的代表算法 可以对多元变量的每一变量的条件分布依次分别进行抽样， 从而实现对整个多元变量的一次抽样，这就是单分量 Metropolis- Hastings (singlecomponent Metropolis- Hastings) 算法。 ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:3:1","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"Gibbs Sampling 吉布斯抽样，可以认为是 Metropolis-Hastings 算法的特殊情况，但是更容易实现，因而被广泛使用。 吉布斯抽样用于多元变量联合分布的抽样和估计。 其基本做法是，从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列。 吉布斯抽样适合于满条件概率分布 容易抽样 的情况，而单分量MetropolisHastings 算法适合于满条件概率分布不容易抽样的情况，这时使用容易抽样的条件分布作建议分布。 参考： 李航《统计学习方法》 ","date":"2020-06-06","objectID":"/2020-01-26-ml-montecarlo/:3:2","tags":["Monte Carlo","Statistical Learning"],"title":"Markov Chain Mento Carlo (MCMC)","uri":"/2020-01-26-ml-montecarlo/"},{"categories":["Machine Learning"],"content":"奇异值分解(SVD)是一种矩阵因子分解方法，在线性代数中，被广泛应用。 奇异值分解也是一种矩阵近似的方法，这个近似是在弗罗贝尼乌斯范数（Frobenius norm) 意义下的近似。 奇异值分解是在平方损失(弗罗贝尼乌斯范数)意义下对矩阵的最优近似，即数据压缩。 ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:0:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"定义 ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:1:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"1. 奇异值分解 将一个 $m \\times n$ 的实矩阵$A$，$A \\in \\mathbf{R}^{m \\times n}$ 表示为以下三个实矩阵乘积形式的运算，即矩阵因子分解： $$ A=U \\Sigma V^{\\mathrm{T}} $$ 其中， $U$是$m$阶正交矩阵: $UU^T = I$ $V$为$n$阶正交矩阵: $VV^T = I$ $\\Sigma$是由降序排列的非负的对角线元素组成的$m \\times n$的对角矩阵: $\\Sigma = diag(\\sigma_1, \\sigma_2, \\cdots, \\sigma_p)$ $\\sigma_{1} \\geqslant \\sigma_{2} \\geqslant \\cdots \\geqslant \\sigma_{p} \\geqslant 0$ $p = \\min(m, n)$ 那么，称 $U \\Sigma V^{\\mathrm{T}}$ : 矩阵A的奇异值分解 $\\sigma_i$ 为A的奇异值(singluar value) $U$ 的列向量为左奇异向量(left singular vector) $V$ 的列向量为右奇异向量(right singular vector) ⚠️注意，矩阵的奇异值分解不唯一。 实际常用的是： ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:1:1","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"2. 紧奇异值分解(compact singular value decomposition)： 无损压缩 设$m \\times n$的实矩阵$A$，其秩为$\\operatorname{rank}(A)=r$, $r \\leqslant \\min (m, n)$, 则紧奇异值分解为： $$ A=U_r \\Sigma_r V^{\\mathrm{T}}_r $$ 其中， $U_r$ 是 $m \\times r$ 矩阵 $V_r$ 是 $n \\times r$ 矩阵 $\\Sigma_r$ 是 $r$ 阶对角阵 $r = \\operatorname{rank}(A)$ ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:1:2","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"3. 截断奇异值分解(truncated singular value decomposition)： 有损压缩 一般讲奇异值分解，实际上多指截断奇异值分解 在奇异值分解中， 只取最大的$k$个奇异值($k \u003c r, r= \\operatorname{rank}(A)$ )对应的部分，就得到截断奇异值分解 设 $m \\times n$ 的实矩阵 $A$，其秩为 $\\operatorname{rank}(A)=r$, 且 $0 \u003c k \u003c r$, 则截断奇异值分解为： $$ A \\approx U_{k} \\Sigma_{k} V_{k}^{\\mathrm{T}} $$ 其中， $U_k$ 是$m \\times k$ 矩阵(前 $k$列) $V_k$ 是$n \\times k$ 矩阵(前 $k$列) $\\Sigma_k$ 是 $k$ 阶对角阵(前 $k$个) $r = \\operatorname{rank}(A)$ ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:1:3","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"几何解释 从线性变换的角度理解奇异值分解： 将 $m \\times n$ 的实矩阵 $A$表示为从 $n$ 维空间 $R_n$ 到 $m$ 维空间 $R_m$的一个线性变换： $$ T: x \\rightarrow A x $$ $x$, $Ax$为各自空间的向量。 那么线性变换可以理解为： 一个坐标系的旋转或反射变换 一个坐标轴的缩放变换 另一个坐标系的旋转或反射变换 对A进行奇异值分解，U和V都是正交矩阵 V的列向量构成Rn空间的一组标准正交基，表示Rn空间中正交坐标系的旋转或反射变换 U的列向量都成Rm空间的一组标准正交基，表示Rm空间中正交坐标系的旋转或反射变换 $\\Sigma$的对角元素是一组非负实数，表示Rn中的原始正交坐标系坐标轴的缩放变换 ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:2:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"奇异值计算 矩阵$A$的奇异值分解可以通过求对阵矩阵$A^TA$的特征值和特征向量得到。 $A^TA$的特征向量构成正交矩阵$V$的列 $A^TA$的特征值$\\lambda_j$的平方根为奇异值$\\sigma_i$，即 $$ \\sigma_{j}=\\sqrt{\\lambda_{j}}, \\quad j=1,2, \\cdots, n $$ 对$\\sigma_i$从大到小排列，得到对角矩阵 $\\Sigma$ 求正奇异值对应的左奇异向量，再扩充的 $A^T$ 的标准正交基，构成正交矩阵 $U$ 的列 ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:3:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"求值过程 求对阵矩阵$A^TA$的特征值和特征向量 计算对称矩阵 $W= A^TA$ 求解特征方程 $(W - \\lambda I)x = 0$ 得到特征值$\\lambda_i$，并将之降序排列 $$ \\lambda_{1} \\geqslant \\lambda_{2} \\geqslant \\cdots \\geqslant \\lambda_{n} \\geqslant 0 $$ 将特征值 $\\lambda_i$ 代入特征方程求的对应特征向量 求 $n$ 阶正交矩阵 $V$ 将特征向量单位化， 得到单位特征向量构成 $n$ 阶正交矩阵V $$ V=\\left[\\begin{array}{llll} v_{1} \u0026 v_{2} \u0026 \\cdots \u0026 v_{n} \\end{array}\\right] $$ 求 $m \\times n$ 对角矩阵 $\\Sigma$ 计算A的奇异值 $$ \\sigma_{j}=\\sqrt{\\lambda_{j}}, \\quad j=1,2, \\cdots, n $$ 构造 $m \\times n$ 矩阵对角矩阵 $\\Sigma$， 主对角线元素是奇异值， 其余元素为 0 $$ \\Sigma=\\operatorname{diag}\\left(\\sigma_{1}, \\sigma_{2}, \\cdots, \\sigma_{n}\\right) $$ 求 $m$ 阶正交矩阵 $U$ 对 $A$ 的前 $r$个正奇异值， 令 $$ u_{j}=\\frac{1}{\\sigma_{j}} A v_{j}, \\quad j=1,2, \\cdots, r $$ 得到 $$ U_{1}=\\left[\\begin{array}{llll} u_{1} \u0026 u_{2} \u0026 \\cdots \u0026 u_{r} \\end{array}\\right] $$ 求 $A^T$ 的零空间的一组标准正交基 $$ \\lbrace u_{r+1}, u_{r+2}, \\cdots, u_{m} \\rbrace $$ 令 $$ U_{2}=\\left[\\begin{array}{llll} u_{r+1} \u0026 u_{r+2} \u0026 \\cdots \u0026 u_{m} \\end{array}\\right] $$ 且令 $$ U=\\left[\\begin{array}{ll} U_{1} \u0026 U_{2} \\end{array}\\right] $$ 得到奇异值分解 $$ A=U \\Sigma V^{\\mathrm{T}} $$ ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:3:1","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"举例 求: 矩阵 $A$ 的奇异值分解 $$ A=\\left[\\begin{array}{ll} 1 \u0026 1 \\cr 2 \u0026 2 \\cr 0 \u0026 0 \\end{array}\\right] $$ 解： 求 $A^TA$ 的特征值和特征向量 $$ A^{\\mathrm{T}} A=\\left[\\begin{array}{lll} 1 \u0026 2 \u0026 0 \\cr 1 \u0026 2 \u0026 0 \\end{array}\\right]\\left[\\begin{array}{ll} 1 \u0026 1 \\cr 2 \u0026 2 \\cr 0 \u0026 0 \\end{array}\\right]=\\left[\\begin{array}{ll} 5 \u0026 5 \\cr 5 \u0026 5 \\end{array}\\right] $$ 满足特征方程 $$ \\left(A^{\\mathrm{T}} A-\\lambda I\\right) x=0 $$ 得到齐次线性方程组 $$ \\begin{cases} (5-\\lambda) x_{1} + \u0026 5 x_{2}=0 \\cr 5 x_{1} + \u0026 (5-\\lambda) x_{2}=0 \\end{cases} $$ 该方程组有非零解的充要条件是 $$ \\left|\\begin{array}{cc} 5-\\lambda \u0026 5 \\cr 5 \u0026 5-\\lambda \\end{array}\\right|=0 $$ 即 $$ \\lambda^{2}-10 \\lambda=0 $$ 得到 $\\lambda_1 = 10 $, $\\lambda_2 = 0$. 特征值代入线性方程组，分别得到对应单位特征向量 $$ v_{1}=\\left[\\begin{array}{c} \\frac{1}{\\sqrt{2}} \\cr \\frac{1}{\\sqrt{2}} \\end{array}\\right], v_{2}=\\left[\\begin{array}{c} \\frac{1}{\\sqrt{2}} \\cr -\\frac{1}{\\sqrt{2}} \\end{array}\\right] $$ 求正交矩阵 $V$ 构造正交矩阵 $$ V=\\left[\\begin{array}{cc} \\frac{1}{\\sqrt{2}} \u0026 \\frac{1}{\\sqrt{2}} \\cr \\frac{1}{\\sqrt{2}} \u0026 -\\frac{1}{\\sqrt{2}} \\end{array}\\right] $$ 求对角矩阵 $\\Sigma$ 奇异值为 $\\sigma_1 = \\sqrt{\\lambda_1} = \\sqrt{10}$, $\\sigma_2 = 0$, 那么 $$ \\Sigma=\\left[\\begin{array}{cc} \\sqrt{10} \u0026 0 \\cr 0 \u0026 0 \\cr 0 \u0026 0 \\end{array}\\right] $$ ⚠️注意： 为了 $\\Sigma$ 能与$U$和$V$进行矩阵乘法， $\\Sigma$要加上零行向量 求正交矩阵 $U$ 基于 $A$ 的奇异值计算得到列向量 $u_1$ $$ u_{1}=\\frac{1}{\\sigma_{1}} A v_{1}=\\frac{1}{\\sqrt{10}}\\left[\\begin{array}{cc} 1 \u0026 1 \\cr 2 \u0026 2 \\cr 0 \u0026 0 \\end{array}\\right]\\left[\\begin{array}{c} \\frac{1}{\\sqrt{2}} \\cr \\frac{1}{\\sqrt{2}} \\end{array}\\right]=\\left[\\begin{array}{c} \\frac{1}{\\sqrt{5}} \\cr \\frac{2}{\\sqrt{5}} \\cr 0 \\end{array}\\right] $$ 列向量$u_2$， $u_3$是 $A^T$的零空间 $N(A^T)$ 的一组标准正交基，故而求解以下线性方程组 $$ A^{\\mathrm{T}} x=\\left[\\begin{array}{lll} 1 \u0026 2 \u0026 0 \\cr 1 \u0026 2 \u0026 0 \\end{array}\\right]\\left[\\begin{array}{l} x_{1} \\cr x_{2} \\cr x_{3} \\end{array}\\right]=\\left[\\begin{array}{l} 0 \\cr 0 \\end{array}\\right] $$ 即 $$ \\begin{array}{c} x_{1}+2 x_{2}+0 x_{3}=0 \\cr x_{1}=-2 x_{2}+0 x_{3} \\end{array} $$ 分别取 $x_2$，$x_3$ 为 $(1,0)$ 和 $(0,1)$ 得到 $N(A^T)$的基 $$ (-2,1,0)^{\\mathrm{T}}, \\quad(0,0,1)^{\\mathrm{T}} $$ 得 $N(A^T)$ 的一组标准正交基是 $$ u_{2}=\\left(-\\frac{2}{\\sqrt{5}}, \\frac{1}{\\sqrt{5}}, 0\\right)^{\\mathrm{T}}, \\quad u_{3}=(0,0,1)^{\\mathrm{T}} $$ 最后，构造正交矩阵 $U$ $$ U=\\left[\\begin{array}{ccc} \\frac{1}{\\sqrt{5}} \u0026 -\\frac{2}{\\sqrt{5}} \u0026 0 \\cr \\frac{2}{\\sqrt{5}} \u0026 \\frac{1}{\\sqrt{5}} \u0026 0 \\cr 0 \u0026 0 \u0026 1 \\end{array}\\right] $$ 矩阵 $A$ 的奇异值分解 $$ A=U \\Sigma V^{\\mathrm{T}}=\\left[\\begin{array}{ccc} \\frac{1}{\\sqrt{5}} \u0026 -\\frac{2}{\\sqrt{5}} \u0026 0 \\cr \\frac{2}{\\sqrt{5}} \u0026 \\frac{1}{\\sqrt{5}} \u0026 0 \\cr 0 \u0026 0 \u0026 1 \\end{array}\\right]\\left[\\begin{array}{cc} \\sqrt{10} \u0026 0 \\cr 0 \u0026 0 \\cr 0 \u0026 0 \\end{array}\\right]\\left[\\begin{array}{cc} \\frac{1}{\\sqrt{2}} \u0026 \\frac{1}{\\sqrt{2}} \\cr \\frac{1}{\\sqrt{2}} \u0026 -\\frac{1}{\\sqrt{2}} \\end{array}\\right] $$ ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:3:2","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"矩阵的外积展开式表示 将A的奇异值分解看成矩阵 $U\\Sigma$ 和 $V^T$ 的乘积， 将 $U\\Sigma$ 按列向量分块， $$ U \\Sigma=\\left[\\begin{array}{llll} \\sigma_{1} u_{1} \u0026 \\sigma_{2} u_{2} \u0026 \\cdots \u0026 \\sigma_{n} u_{n} \\end{array}\\right] $$ $V^T$ 按行向量分块 $$ V^{\\mathrm{T}}=\\left[\\begin{array}{c} v_{1}^{\\mathrm{T}} \\cr v_{2}^{\\mathrm{T}} \\cr \\vdots \\cr v_{n}^{\\mathrm{T}} \\end{array}\\right] $$ 那么外积展开式为 $$ A=\\sigma_{1} u_{1} v_{1}^{\\mathrm{T}}+\\sigma_{2} u_{2} v_{2}^{\\mathrm{T}}+\\cdots+\\sigma_{n} u_{n} v_{n}^{\\mathrm{T}} $$ 或者 $$ A=\\sum_{k=1}^{n} A_{k}=\\sum_{k=1}^{n} \\sigma_{k} u_{k} v_{k}^{\\mathrm{T}} $$ 其中 $A_{k}=\\sigma_{k} u_{k} v_{k}^{\\mathrm{T}}$ 是 $m \\times n$ 矩阵 而 $$ u_{i} v_{j}^{\\mathrm{T}}=\\left[\\begin{array}{c} u_{1 i} \\cr u_{2 i} \\cr \\vdots \\cr u_{m i} \\end{array}\\right]\\left[\\begin{array}{cccc} v_{1 j} \u0026 v_{2 j} \u0026 \\cdots \u0026 v_{n j} \\end{array}\\right] = \\left[\\begin{array}{cccc} u_{1 i} v_{1 j} \u0026 u_{1 i} v_{2 j} \u0026 \\cdots \u0026 u_{1 i} v_{n j} \\cr u_{2 i} v_{1 j} \u0026 u_{2 i} v_{2 j} \u0026 \\cdots \u0026 u_{2 i} v_{n j} \\cr \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\cr u_{m i} v_{1 j} \u0026 u_{m i} v_{2 j} \u0026 \\cdots \u0026 u_{m i} v_{n j} \\end{array}\\right] $$ ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:4:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"补充： ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:5:0","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"Determinant 行列式 Determinant: The determinant of a square matrix is a scalar that provides information about the matrix. e.g. Invertibility Geometrically, it can be viewed as the volume scaling factor of the linear transformation described by the matrix. 一个矩阵的行列式就是一个超平行多面体的（有向的）面积/体积，这个多面体的每条边对应着对应矩阵的列； 矩阵 $A$ 的行列式 $det(A)$ 就是线性变换 $A$ 下的图形面积或体积的伸缩因子。 矩阵的行列式的几何意义是矩阵对应的线性变换前后的面积比 Property: $Det(I) = 1$ Exchanging rows only reverse the sign of det Determinant is “linear” for each row $det(A) \\neq 0$, $A$ is invertible Cramer’s rule: $A^{-1} = \\frac{1}{det(A)}C^T$ $det(A)$: scalar $C$: cofactors of $A$ (C has the same size as $A$) $C^T$ is adjugate of $A$ (伴随矩阵) ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:5:1","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Machine Learning"],"content":"Eigenvalue and Eigenvector Eigen (German word): “unique to” or “belonging to” if $Av = \\lambda v$ ($v$ is a vector , $\\lambda$ is a scalar) $A$ must be square $v$ is an eigenvector of $A$, exluding zero vector $\\lambda$ is an eigenvalue of $A$ that correponds to $v$ $T$ is a linear operator if $T(v) = \\lambda v$ ( $v$ is a vector, $\\lambda$ is a scalar) $v$ is an eigenvector of $T$, exluding zero vector $\\lambda$ is an eigenvalue of $T$ that correponds to $v$ An eigenvector of A corresponds to a unique eigenvalue. An eigenvalue of A has infinitely many eigenvectors. =\u003e how to find eigenvalues t : $$ det(A - tI_n) = 0 $$ 参考： 李航《统计学习方法》 ","date":"2020-06-06","objectID":"/2020-06-06-ml-svd/:5:2","tags":["SVD","Statistical Learning"],"title":"Singular Value Decomposition (SVD)","uri":"/2020-06-06-ml-svd/"},{"categories":["Coding"],"content":"Get answers for Swift within 10s","date":"2020-05-30","objectID":"/2020-06-03-swift-unsafe-pointer/","tags":["Swift"],"title":"Pointer in UnSafe Swift","uri":"/2020-06-03-swift-unsafe-pointer/"},{"categories":["Coding"],"content":"Pointers Unsafe Swift pointers use a predictable naming scheme: Unsafe [Mutable][Raw][Buffer]Pointer[\u003cT\u003e] Explain: Pointers are just memory addresses. Direct memory access is Unsafe. Mutable means you can write to it. Raw means it points to a blob of bytes. Buffer means that is works like a collection. Generic [\u003cT\u003e] pointers are typed. ","date":"2020-05-30","objectID":"/2020-06-03-swift-unsafe-pointer/:1:0","tags":["Swift"],"title":"Pointer in UnSafe Swift","uri":"/2020-06-03-swift-unsafe-pointer/"},{"categories":["Coding"],"content":"Working with Pointers C Pointer Swift Type int * UnsaftMutablePointer const int * UnsafePointer NSDate ** AutoreleasingUnsafeMutablePointer struct UnknowType * OpaquePointer void * UnsafeMutableRawPointer const void * UnsafeRawPointer Explain: see here ","date":"2020-05-30","objectID":"/2020-06-03-swift-unsafe-pointer/:2:0","tags":["Swift"],"title":"Pointer in UnSafe Swift","uri":"/2020-06-03-swift-unsafe-pointer/"},{"categories":["Coding"],"content":"Pointer Safety Safely manage pointers in Swift ","date":"2020-05-30","objectID":"/2020-06-03-swift-unsafe-pointer/:3:0","tags":["Swift"],"title":"Pointer in UnSafe Swift","uri":"/2020-06-03-swift-unsafe-pointer/"},{"categories":["Coding"],"content":"Usage see here and here ","date":"2020-05-30","objectID":"/2020-06-03-swift-unsafe-pointer/:4:0","tags":["Swift"],"title":"Pointer in UnSafe Swift","uri":"/2020-06-03-swift-unsafe-pointer/"},{"categories":["Coding"],"content":"Get answers for Swift within 10s","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Swift Cheat Sheet Stolen from iwasrobbed. I simplify it and add some more. It’s a high level and a quick reference to Swift. The purpose of this cheat sheet is to teach myself and get answers within 10s. ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:0:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Table of Contents Code Document Data Types Operators Operator Overloading Declaring Classes Declarations Lazy Property Property Observer Literals Functions Constants and Variables Naming Conventions Closures Generics Control Statements Extension Protocol Protocol Extension Error Handling Passing Information User Defaults Common Patterns Unicode Support File IO ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:0:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Code Documentation Two ways of commenting: // /* … */ Two ways of documenting with markdown (Reconigzed by xcode): /// /** … */ ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:1:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Markdown a few keywords that xcode can recognized automatically, with the format like - . The most common: Prameters, Throws, Returns /** - Prameters: - argument1: This is arg1 - argument2: This is arg2 - Returns: The results string. - Throws: `Error` if nil */ Other keywords /** - Precondition: - Postcondition: - Requires: All the information in the object should be sorted - Invariant: The object will maintained sorted - Complexity: O(n^2) - Important: - Warning: Very computation consuming - Attention: Same as Warning - Note: something to keep in mind - Remark: Same as note */ Metadata /** - Author: - Authors: - Copyright: - Date: - Since: - Version: */ Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:1:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"MARK Using MARK to organize your code: // MARK:- Use mark to logically organize your code // Declare some functions or variables here // MARK:- They also show up nicely in the properties/functions list in Xcode // Declare some more functions or variables here ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:1:2","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"FIXME Using FIXME to remember to fix your code: // Some broken code might be here // FIXME:Use fixme to create a reminder to fix broken code later FIXME works a lot like MARK because it makes organizing code easier, but it’s used exclusively when you need to remember to fix something. ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:1:3","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"TODO Using TODO to remember to add, delete, or generally refactor your code: // Some incomplete code might be here // TODO:Use todo to create a reminder to finish things up later TODO is very similar to FIXME and MARK, but it’s used exclusively when you need to remember to add, delete, or change your code later. Auto-generating method documentation: In a method’s preceding line, press ⌥ Option + ⌘ Command + / to automatically generate a documentation stub for your method. Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:1:4","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Data Types ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:2:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Size Permissible sizes of data types are determined by how many bytes of memory are allocated for that specific type and whether it’s a 32-bit or 64-bit environment. In a 32-bit environment, long is given 4 bytes, which equates to a total range of 2^(4*8) (with 8 bits in a byte) or 4294967295. In a 64-bit environment, long is given 8 bytes, which equates to 2^(8*8) or 1.84467440737096e19. For a complete guide to 64-bit changes, please see the transition document. ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:2:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"C Primitives Unless you have a good reason to use C primitives, you should just use the Swift types to ensure compability going foward. In fact, Swift just aliases C types to a Swift equivalent: // C char is aliased as an Int8 and unsigned as UInt8 let aChar = CChar() let anUnsignedChar = CUnsignedChar() print(\"C char size: \\(MemoryLayout.size(ofValue: aChar))with min: \\(Int8.min)and max: \\(Int8.max)\") // C char size: 1 with min: -128 and max: 127 print(\"C unsigned char size: \\(MemoryLayout.size(ofValue: anUnsignedChar))with min: \\(UInt8.min)and max: \\(UInt8.max)\") // C unsigned char size: 1 with min: 0 and max: 255 // C short is aliased as an Int16 and unsigned as UInt16 let aShort = CShort() let unsignedShort = CUnsignedShort() print(\"C short size: \\(MemoryLayout.size(ofValue: aShort))with min: \\(Int16.min)and max: \\(Int16.max)\") // C short size: 2 with min: -32768 and max: 32767 print(\"C unsigned short size: \\(MemoryLayout.size(ofValue: unsignedShort))with min: \\(UInt16.min)and max: \\(UInt16.max)\") // C unsigned short size: 2 with min: 0 and max: 65535 // C int is aliased as an Int32 and unsigned as UInt32 let anInt = CInt() let unsignedInt = CUnsignedInt() print(\"C int size: \\(MemoryLayout.size(ofValue: anInt))with min: \\(Int32.min)and max: \\(Int32.max)\") // C int size: 4 with min: -2147483648 and max: 2147483647 print(\"C unsigned int size: \\(MemoryLayout.size(ofValue: unsignedInt))with min: \\(UInt32.min)and max: \\(UInt32.max)\") // C unsigned int size: 4 with min: 0 and max: 4294967295 // C long is aliased as an Int and unsigned as UInt let aLong = CLong() let unsignedLong = CUnsignedLong() print(\"C long size: \\(MemoryLayout.size(ofValue: aLong))with min: \\(Int.min)and max: \\(Int.max)\") // C long size: 8 with min: -9223372036854775808 and max: 9223372036854775807 print(\"C unsigned long size: \\(MemoryLayout.size(ofValue: unsignedLong))with min: \\(UInt.min)and max: \\(UInt.max)\") // C unsigned long size: 8 with min: 0 and max: 18446744073709551615 // C long long is aliased as an Int64 and unsigned as UInt64 let aLongLong = CLongLong() let unsignedLongLong = CUnsignedLongLong() print(\"C long long size: \\(MemoryLayout.size(ofValue: aLongLong))with min: \\(Int64.min)and max: \\(Int64.max)\") // C long long size: 8 with min: -9223372036854775808 and max: 9223372036854775807 print(\"C unsigned long long size: \\(MemoryLayout.size(ofValue: unsignedLongLong))with min: \\(UInt64.min)and max: \\(UInt64.max)\") // C unsigned long long size: 8 with min: 0 and max: 18446744073709551615 From the docs: C Type Swift Type bool CBool char, signed char CChar unsigned char CUnsignedChar short CShort unsigned short CUnsignedShort int CInt unsigned int CUnsignedInt long CLong unsigned long CUnsignedLong long long CLongLong unsigned long long CUnsignedLongLong wchar_t CWideChar char16_t CChar16 char32_t CChar32 float CFloat double CDouble Integers Integers can be signed or unsigned. When signed, they can be either positive or negative and when unsigned, they can only be positive. Apple states: Unless you need to work with a specific size of integer, always use Int for integer values in your code. This aids code consistency and interoperability. Even on 32-bit platforms, Int […] is large enough for many integer ranges. Fixed width integer types with their accompanying byte sizes as the variable names: // Exact integer types let aOneByteInt: Int8 = 127 let aOneByteUnsignedInt: UInt8 = 255 let aTwoByteInt: Int16 = 32767 let aTwoByteUnsignedInt: UInt16 = 65535 let aFourByteInt: Int32 = 2147483647 let aFourByteUnsignedInt: UInt32 = 4294967295 let anEightByteInt: Int64 = 9223372036854775807 let anEightByteUnsignedInt: UInt64 = 18446744073709551615 // Minimum integer types let aTinyInt: Int8 = 127 let aTinyUnsignedInt: UInt8 = 255 let aMediumInt: Int16 = 32767 let aMediumUnsignedInt: UInt16 = 65535 let aNormalInt: Int32 = 2147483647 let aNormalUnsignedInt: UInt32 = 4294967295 let aBigInt: Int64 = 9223372036854775807 let aBigUnsignedInt: UInt64 = 1844674407370955","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:2:2","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Enum \u0026 Bitmask Types Enumeration types can be defined as follows: // Specifying a typed enum with a name (recommended way) enum UITableViewCellStyle: Int { case default, valueOne, valueTwo, subtitle } // Accessing it: let cellStyle: UITableViewCellStyle = .default As of Swift 3, all enum options should be named in lowerCamelCased. Working with Bitmasks Newer Swift versions have a nice substitute for the old NS_OPTIONS macro for creating bitmasks to compare to. An example for posterity: struct Options: OptionSet { let rawValue: Int init(rawValue: Int) { self.rawValue = rawValue } init(number: Int) { self.init(rawValue: 1 \u003c\u003c number) } static let OptionOne = Options(number: 0) static let OptionTwo = Options(number: 1) static let OptionThree = Options(number: 2) } let options: Options = [.OptionOne, .OptionTwo] options.contains(.OptionOne) // true options.contains(.OptionThree) // false ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:2:3","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Type Casting Sometimes it is necessary to cast an object into a specific class or data type. Examples of this would be casting from a Float to an Int or from a UITableViewCell to a subclass such as RPTableViewCell. Checking Types Swift uses is and as both for checking object types as well as conformance to a given protocol. Operator: is Checking object type using is: if item is Movie { movieCount += 1 print(\"It is a movie.\") } else if item is Song { songCount += 1 print(\"It is a song.\") } The is operator returns true if an instance is of that object type, or conforms to the specified protocol, and returns false if it does not. Operators: as? and as! If you want to be able to easily access the data during one of these checks, you can use as? to optionally (or as! to force) unwrap the object when necessary: for item in library { if let movie = item as? Movie { print(\"Director: \\(movie.director)\") } else if let song = item as? Song { print(\"Artist: \\(song.artist)\") } } The as? version of the downcast operator returns an optional value of the object or protocol’s type, and this value is nil if the downcast fails or this instance does not conform to the specified protocol. The as! version of the downcast operator forces the downcast to the specified object or protocol type and triggers a runtime error if the downcast does not succeed. Casting from Generic Types If you’re working with AnyObject objects given from the Cocoa API, you can use: for movie in someObjects as! [Movie] { // do stuff } If given an array with Any objects, you can use a switch statement with the type defined for each case: var things = [Any]() for thing in things { switch thing { case 0 as Int: print(\"Zero as an Int\") case let someString as! String: print(\"S string value of \\\"\\(someString)\\\"\") case let (x, y) as! (Double, Double): print(\"An (x, y) point at \\(x), \\(y)\") case let movie as! Movie: print(\"A movie called '\\(movie.name)' by director \\(movie.director)\") default: print(\"Didn't match any of the cases specified\") } } Basic Casting Swift also offers some simple methods of casting between it’s given data types. // Example 1: let aDifferentDataType: Float = 3.14 let anInt: Int = Int(aDifferentDataType) // Example 2: let aString: String = String(anInt) Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:2:4","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Operators Swift supports most standard C operators and improves several capabilities to eliminate common coding errors. The assignment operator = does not return a value, to prevent it from being mistakenly used when the equal to operator == is intended. Arithmetic operators (+, -, *, /, %) detect and disallow value overflow, to avoid unexpected results when working with numbers that become larger or smaller than the allowed value range of the type that stores them. Arithmetic Operators Operator Purpose + Addition - Subtraction * Multiplication / Division % Remainder Comparative Operators Operator Purpose == Equal to === Identical to != Not equal to !== Not identical to ~= Pattern match \u003e Greater than \u003c Less than \u003e= Greater than or equal to \u003c= Less than or equal to Assignment Operators Operator Purpose = Assign += Addition -= Subtraction *= Multiplication /= Division %= Remainder \u0026= Bitwise AND |= Bitwise Inclusive OR ^= Exclusive OR «= Shift Left »= Shift Right Logical Operators Operator Purpose ! NOT \u0026\u0026 Logical AND || Logical OR Range Operators Operator Purpose ..\u003c Half-open range … Closed range Bitwise Operators Operator Purpose \u0026 Bitwise AND | Bitwise Inclusive OR ^ Exclusive OR ~ Unary complement (bit inversion) « Shift Left » Shift Right Overflow and Underflow Operators Typically, assigning or incrementing an integer, float, or double past it’s range would result in a runtime error. However, if you’d instead prefer to safely truncate the number of available bits, you can opt-in to have the variable overflow or underflow using the following operators: Operator Purpose \u0026+ Addition \u0026- Subtraction \u0026* Multiplication Example for unsigned integers (works similarly for signed): var willOverflow = UInt8.max // willOverflow equals 255, which is the largest value a UInt8 can hold willOverflow = willOverflow \u0026+ 1 // willOverflow is now equal to 0 var willUnderflow = UInt8.min // willUnderflow equals 0, which is the smallest value a UInt8 can hold willUnderflow = willUnderflow \u0026- 1 // willUnderflow is now equal to 255 Other Operators Operator Purpose ?? Nil coalescing ?: Ternary conditional ! Force unwrap object value ? Safely unwrap object value Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:3:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Operator Overloading Swift allows you to overwrite existing operators or define new operators for existing or custom types. For example, this is why in Swift you can join strings using the + operator, even though it is typically used for math. Operator overloading is limited to the following symbols, / = - + * % \u003c \u003e ! \u0026 | ^ . ~, however you cannot overload the = operator by itself (it must be combined with another symbol). Operators can be specified as: prefix: goes before an object such as -negativeNumber infix: goes between two objects, such as a + b postfix: goes after an object, such as unwrapMe! ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:4:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Custom operators associativity: defines how operators of the same precedence are grouped together (left, right) precedence: gives some operators higher priority than others; these operators are applied first. Refer Operator Declarations to see full details about operator associativity and precedence. Example: DefaultPrecedence group // declare first and set rules with a precedence group infix operator ** // use DefaultPrecedence group Custom Precedence group // define a custom precedence group precedencegroup ExponentiationPrecedence { higherThan: MultiplicationPrecedence associativity: right // none, left, right //assignment: false } // now, replace original declaration of ** with infix operator **: ExponentiationPrecedence That’s it. // impelment infix func ** (x: Double, p: Double) -\u003e Double { return pow(x, p) } 2**3 // 8 2**3**2 // 512 1+2**3**2 // 513 5*2**3**2 // 2560 see also docs Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:4:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Declaring Classes Classes are typically declared using separate .swift files, but multiple classes can also be created within the same file if you’d like to organize it that way. Unlike Objective-C, there’s no need for an interface file (.h) in Swift. The implementation file should contain (in this order): Any needed import statements A class declaration which contains any constants or variables necessary for the class All public and private functions Example: MyClass.swift import UIKit class MyClass { // Declare any constants or variables at the top let kRPErrorDomain = \"com.myIncredibleApp.errors\" var x: Int, y: Int // MARK:- Class Methods, e.g. MyClass.functionName() class func alert() { print(\"This is a class function.\") } // MARK:- Instance Methods, e.g. myClass.functionName() init(x: Int, y: Int) { self.x = x self.y = y } // MARK:- Private Methods private func pointLocation() -\u003e String { return \"x: \\(x), y: \\(y)\" } } Instantiation When you want to create a new instance of a class, you use the syntax: let myClass = MyClass(x: 1, y: 2) where x and y are variables that are passed in at the time of instantiation. Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:5:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Declarations More info here in the docs. Preprocessor Swift doesn’t come with a preprocessor so it only supports a limited number of statements for build time. Things like #define have been replaced with global constants defined outside of a class. Directive Purpose #if An if conditional statement #elif An else if conditional statement #else An else conditional statement #endif An end if conditional statement Imports Directive Purpose import Imports a framework Constants \u0026 Variables Directive Purpose let Declares local or global constant var Declares a local or global variable class Declares a class-level constant or variable static Declares a static type Classes, Structure, Functions and Protocols Directive Purpose typealias Introduces a named alias of an existing type enum Introduces a named enumeration struct Introduces a named structure class Begins the declaration of a class init Introduces an initializer for a class, struct or enum init? Produces an optional instance or an implicitly unwrapped optional instance; can return nil deinit Declares a function called automatically when there are no longer any references to a class object, just before the class object is deallocated func Begins the declaration of a function protocol Begins the declaration of a formal protocol static Defines as type-level within struct or enum convenience Delegate the init process to another initializer or to one of the class’s designated initializers extension Extend the behavior of class, struct, or enum subscript Adds subscripting support for objects of a particular type, normally for providing a convenient syntax for accessing elements in a collective, list or sequence override Marks overriden initializers Operators Directive Purpose operator Introduces a new infix, prefix, or postfix operator Declaration Modifiers Directive Purpose dynamic Marks a member declaration so that access is always dynamically dispatched using the Objective-C runtime and never inlined or devirtualized by the compiler final Specifies that a class can’t be subclassed, or that a property, function, or subscript of a class can’t be overridden in any subclass lazy Indicates that the property’s initial value is calculated and stored at most once, when the property is first accessed optional Specifies that a protocol’s property, function, or subscript isn’t required to be implemented by conforming members required Marks the initializer so that every subclass must implement it weak Indicates that the variable or property has a weak reference to the object stored as its value Access Control Directive Purpose open Can be subclassed outside of its own module and its methods overridden as well; truly open to modification by others and useful for framework builders public Can only be subclassed by its own module or have its methods overridden by others within the same module internal (Default) Indicates the entities are only available to the entire module that includes the definition, e.g. an app or framework target fileprivate Indicates the entities are available only from within the source file where they are defined private Indicates the entities are available only from within the declaring scope within the file where they are defined (e.g. within the { } brackets only) public class AccessLevelsShowCase { // Property accessible for other modules public var somePublicProperty = 0 // Property accessible from the module var someInternelProperty = 1 // Property accessible from its own defining source file fileprivate func someFilePrivateMethod() {} // Property accessible fro its enclosing declaration private func somePrivateMethod() {} } Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:6:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Literals Literals are compiler directives which provide a shorthand notation for creating common objects. Syntax What it does \"string\" Returns a String object 28 Returns an Int 3.14, 0xFp2, 1.25e2 Returns a Double object true, false Returns a Bool object [] Returns an Array object [keyName:value] Returns a Dictionary object 0b Returns a binary digit 0o Returns an octal digit 0x Returns a hexadecimal digit Strings Special characters can be included: Null Character: \\0 Backslash: \\\\ (can be used to escape a double quote) Horizontal Tab: \\t Line Feed: \\n Carriage Return: \\r Double Quote: \\\" Single Quote: \\' Unicode scalar: \\u{n} where n is between one and eight hexadecimal digits Multiline string literal let json = \"\"\" { \"username\": \"David\", \"loginCount\": 2} \"\"\" Array Access Syntax let example = [ \"hi\", \"there\", 23, true ] print(\"item at index 0: \\(example[0])\") Dictionary Access Syntax let example = [ \"hi\" : \"there\", \"iOS\" : \"people\" ] if let value = example[\"hi\"] { print(\"hi \\(value)\") } Mutability For mutable literals, declare it with var; immutable with let. Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:7:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Functions Declaration Syntax Functions without a return type use this format: // Does not return anything or take any arguments func doWork() { // Code } class precedes declarations of class functions: // Call on a class, e.g. MyClass.someClassFunction() class func someClassFunction() { // Code } static is similar to class functions where you don’t need an instance of the class or struct in order to call a method on it: // Call on a class/struct, e.g. MyStruct.someStaticFunction() static func someStaticFunction() { // Code } Declare instance functions: // Called on an instance of a class, e.g. myClass.someInstanceFunction() func doMoreWork() { // Code } Function arguments are declared within the parentheses: // Draws a point func draw(point: CGPoint) Return types are declared as follows: // Returns a String object for the given String argument func sayHelloToMyLilFriend(lilFriendsName: String) -\u003e String { return \"Oh hello, \\(lilFriendsName). Cup of tea?\" } You can have multiple return values, referred to as a tuple: // Returns multiple objects func sayHelloToMyLilFriend(lilFriendsName: String) -\u003e (msg: String, nameLength: Int) { return (\"Oh hello, \\(lilFriendsName). Cup of tea?\", countElements(lilFriendsName)) } var hello = sayHelloToMyLilFriend(\"Rob\") print(hello.msg) // \"Oh hello, Rob. Cup of tea?\" print(hello.nameLength) // 3 And those multiple return values can be optional: func sayHelloToMyLilFriend(lilFriendsName: String) -\u003e (msg: String, nameLength: Int)? By default, external parameter names are given when you call the function, but you can specify that one or more are not shown in the method signature by putting a _ symbol in front of the parameter name: func sayHelloToMyLilFriend(_ lilFriendsName: String) { // Code } sayHelloToMyLilFriend(\"Rob\") or you can rename the variable once within the method scope: func sayHelloToMyLilFriend(friendsName lilFriendsName: String) { // Code } sayHelloToMyLilFriend(friendsName: \"Rob\") // and local variable is `lilFriendsName` You can also specify default values for the parameters: func sayHelloToMyLilFriend(_ lilFriendsName: String = \"Rob\") { // Code } sayHelloToMyLilFriend() // \"Oh hello, Rob. Cup of tea?\" sayHelloToMyLilFriend(\"Jimbob\") // \"Oh hello, Jimbob. Cup of tea?\" Swift also supports variadic parameters so you can have an open-ended number of parameters passed in: func sayHelloToMyLilFriends(_ lilFriendsName: String...) { // Code } sayHelloToMyLilFriends(\"Rob\", \"Jimbob\", \"Cletus\") // \"Oh hello, Rob, Jimbob and Cletus. Cup of tea?\" And lastly, you can also use a prefix to declare input parameters as inout. An in-out parameter has a value that is passed in to the function, is modified by the function, and is passed back out of the function to replace the original value. You may remember inout parameters from Objective-C where you had to sometimes pass in an \u0026error parameter to certain methods, where the \u0026 symbol specifies that you’re actually passing in a pointer to the object instead of the object itself. The same applies to Swift’s inout parameters now as well. Calling Functions Functions are called using dot syntax: myClass.doWork() or self.sayHelloToMyLilFriend(\"Rob Phillips\") self is a reference to the function’s containing class. At times, it is necessary to call a function in the superclass using super.someMethod(). Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:8:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Constants and Variables Declaring a constant or variable allows you to maintain a reference to an object within a class or to pass objects between classes. Constants are defined with let and variables with var. By nature, constants are obviously immutable (i.e. cannot be changed once they are instantiated) and variables are mutable. class MyClass { let text = \"Hello\" // Constant var isComplete: Bool // Variable } There are many ways to declare properties in Swift, so here are a few examples: var myInt = 1 // inferred type var myExplicitInt: Int = 1 // explicit type var x = 1, y = 2, z = 3 // declare multiple variables let (a,b) = (1,2) // declare multiple constants Getters and Setters In Objective-C, variables were backed by getters, setters, and private instance variables created at build time. However, in Swift getters and setters are only used for computed properties and constants actually don’t have a getter or setter at all. The getter is used to read the value, and the setter is used to write the value. The setter clause is optional, and when only a getter is needed, you can omit both clauses and simply return the requested value directly. However, if you provide a setter clause, you must also provide a getter clause. You can overrride the getter and setter of a property to create the illusion of the Objective-C property behavior, but you’d need to store them as a private property with a different name (not recommended for most scenarios): private var _x: Int = 0 var x: Int { get { print(\"Accessing x...\") return _x } set { print(\"Setting x...\") _x = newValue } } Property Observer Swift also has callbacks for when a property will be or was set using willSet and didSet shown below: willset: before assignment didSet: after assignment class LightBulb { static let maxCurrent = 30 var current = 0 { willSet(newCurrent) { // do something before value assignment // newValue -\u003e newCurrent print(\"Current value changed, the change is \\(abs(current- newCurrent))\") } didSet { // do somthing afther value assignment if current == LightBulb.maxCurrent { print(\"current get to maximum point\") } // oldValue } } } let bulb = LightBulb() bulb.current = 20 bulb.current = 30 bulb.current = 40 Back to top Lazy Property lazy: only compute once and remember the value, won’t re-compute if called again. class ClosedRange { let start: Int let end: Int var width: Int { return end - start +1 } // note the = lazy var sum: Int = { var res = 0 print(\"run\") for i in self.start...self.end{ res += 1 } return }() // don't forget () init?(start: Int, end: Int){ if start \u003e end { return nil } self.start = start self.end = end } } // example if let range = ClosedRange(start: 0, end: 10_000) { range.width //1001 range.sum // will print out \"run\" range.sum // range.sum // } Back to top Accessing Local Variables Local variables and constants only exist within the scope of a function. func doWork() { let localStringVariable = \"Some local string variable.\" self.doSomething(string: localStringVariable) } Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:9:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Naming Conventions The general rule of thumb: Clarity and brevity are both important, but clarity should never be sacrificed for brevity. Functions and Properties These both use camelCase where the first letter of the first word is lowercase and the first letter of each additional word is capitalized. Class names and Protocols These both use CapitalCase where the first letter of every word is capitalized. ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:10:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Enums The options in an enum should be lowerCamelCased Functions These should use verbs if they perform some action (e.g. performInBackground). You should be able to infer what is happening, what arguments a function takes, or what is being returned just by reading a function signature. Example: // Correct func move(from start: Point, to end: Point) {} // Incorrect (likely too expressive, but arguable) func moveBetweenPoints(from start: Point, to end: Point) {} // Incorrect (not expressive enough and lacking argument clarity) func move(x: Point, y: Point) {} Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:10:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Closures Closures in Swift are similar to blocks in Objective-C and are essentially chunks of code, typically organized within a {} clause, that are passed between functions or to execute code as a callback within a function. Swift’s func functions are actually just a special case of a closure in use. Syntax { (params) -\u003e returnType in statements } Examples // Map just iterates over the array and performs whatever is in the closure on each item let people = [\"Rob\", \"Jimbob\", \"Cletus\"] people.map({ (person: String) -\u003e String in \"Oh hai, \\(person)...\" }) // Oh hai, Rob // Oh hai, Jimbob // Oh hai, Cletus // Closure for alphabetically reversing an array of names, where sorted is a Swift library function let names = [\"Francesca\", \"Joe\", \"Bill\", \"Sally\", ] var reversed = names.sorted { (s1: String, s2: String) -\u003e Bool in return s1 \u003e s2 } // Or on a single line: reversed = names.sorted{ (s1: String, s2: String) -\u003e Bool in return s1 \u003e s2 } // Or because Swift can infer the Bool type: reversed = names.sorted { s1, s2 in return s1 \u003e s2 } // Or because the return statement is implied: reversed = names.sorted { s1, s2 in s1 \u003e s2 } // Or even shorter using shorthand argument names, such as $0, $1, $2, etc.: reversed = names.sorted { $0 \u003e $1 } // Or just ridiculously short because Swift's String greater-than operator implementation exactly matches this function definition: reversed = names.sorted(by: \u003e) If the closure is the last parameter to the function, you can also use the trailing closure pattern. This is especially useful when the closure code is especially long and you’d like some extra space to organize it: func someFunctionThatTakesAClosure(closure: () -\u003e ()) { // function body goes here } // Instead of calling like this: someFunctionThatTakesAClosure({ // closure's body goes here }) // You can use trailing closure like this: someFunctionThatTakesAClosure() { // trailing closure's body goes here } Capturing Values A closure can capture constants and variables from the surrounding context in which it is defined. The closure can then refer to and modify the values of those constants and variables from within its body, even if the original scope that defined the constants and variables no longer exists. In Swift, the simplest form of a closure that can capture values is a nested function, written within the body of another function. A nested function can capture any of its outer function’s arguments and can also capture any constants and variables defined within the outer function. func makeIncrementor(forIncrement amount: Int) -\u003e () -\u003e Int { var runningTotal = 0 func incrementor() -\u003e Int { runningTotal += amount return runningTotal } return incrementor } Swift determines what should be captured by reference and what should be copied by value. You don’t need to annotate a variable to say that they can be used within the nested function. Swift also handles all memory management involved in disposing of variables when they are no longer needed by the function. Capturing Self If you create a closure that references self.* it will capture self and retain a strong reference to it. This is sometimes the intended behavior, but often could lead to retain cycles where both objects won’t get deallocated at the end of their lifecycles. The two best options are to use unowned or weak. This might look a bit messy, but saves a lot of headache. Use unowned when you know the closure will only be called if self still exists, but you don’t want to create a strong (retain) reference. Use weak if there is a chance that self will not exist, or if the closure is not dependent upon self and will run without it. If you do use weak also remember that self will be an optional variable and should be checked for existence. typealias SomeClosureType = (_ value: String) -\u003e () class SomeClass { fileprivate var currentValue = \"\" init() { someMethod { (value) in // Retained self self.currentValue = value } someMethod { [unowned self] (value) in // Not retained, but ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:11:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Generics Coming soon… Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:12:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Control Statements Swift uses all of the same control statements that other languages have: If-Else If-Else if someTestCondition { // Code to execute if the condition is true } else if someOtherTestCondition { // Code to execute if the other test condition is true } else { // Code to execute if the prior conditions are false } As you can see, parentheses are optional. Ternary Operators The shorthand notation for an if-else statement is a ternary operator of the form: someTestCondition ? doIfTrue : doIfFalse Example: func stringForTrueOrFalse(trueOrFalse: Bool) -\u003e String { return trueOrFalse ? \"True\" : \"False\" } Nil Coalescing Operators In Swift, we need to consider the use of optional values. One very basic way to handle nil cases is with an if-else statement: func stringForOptionalExistence(optionalValue: String?) -\u003e String { if optionalValue != nil { return optionalValue } else { return \"Empty\" } } In this particular case, we are returning optionalValue if it is not nil, and \"Empty\" if optionalValue is nil. The shorthand notation for this type of if(!=nil)-else statement is a nil coalescing operator of the form: optionalValue ?? nonOptionalValue Example: func stringForOptionalExistence(optionalValue: String?) -\u003e String { return optionalValue ?? \"Empty\" } For Loops Swift enables you to use ranges inside of for loops now: for index in 1...5 { print(\"\\(index)times 5 is \\(index * 5)\") } // Or if you don't need the value of the index let base = 3, power = 10 var answer = 1 for _ in 1...power { answer *= base } print(\"\\(base)to the power of \\(power)is \\(answer)\") // prints \"3 to the power of 10 is 59049\" Enumerating arrays \u0026 dictionaries // We explicitly cast to the Movie class from AnyObject class for movie in someObjects as [Movie] { // Code to execute each time } // Enumerating simple array let names = [\"Anna\", \"Alex\", \"Brian\", \"Jack\"] for name in names { print(\"Hello, \\(name)!\") } // Enumerating simple dictionary let numberOfLegs = [\"spider\": 8, \"ant\": 6, \"cat\": 4] for (animalName, legCount) in numberOfLegs { print(\"\\(animalName)s have \\(legCount)legs\") } If you need to cast to a certain object type, see the earlier discussion about the as! and as? keywords. While Loop while someTestCondition { // Code to execute while the condition is true } Repeat While Loop repeat { // Code to execute while the condition is true } while someTestCondition Switch Switch statements are often used in place of if statements if there is a need to test if a certain variable matches the value of another constant or variable. For example, you may want to test if an error code integer you received matches an existing constant value or if it’s a new error code. switch errorStatusCode { case .network: // Code to execute if it matches case .wifi: // Code to execute if it matches default: // Code to execute if nothing else matched } Switch statements in Swift do not fall through the bottom of each case and into the next one by default. Instead, the entire switch statement finishes its execution as soon as the first matching switch case is completed, without requiring an explicit break statement. This makes the switch statement safer and easier to use than in C, and avoids executing more than one switch case by mistake. Exiting Loops Although break is not required in Swift, you can still use a break statement to match and ignore a particular case, or to break out of a matched case before that case has completed its execution. return : Stops execution and returns to the calling function. It can also be used to return a value from a function. break : Used to stop the execution of a loop. Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:13:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Extension Extensions add new functionality to an existing class, structure, enumeration or protocol type extension String { // Extending String type to calculate if a String instance is truthy of falsy var boolValue:Bool { if self == \"1\" return true } return false } let isTrue = \"0\".boolValue Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:14:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Protocol Define protocol Codable { // definitions var description: String var mustBeSettable: Int { get set } var doesNotNeedToBeSettable: Int { get } func dance () -\u003e Double static func someTypeMethod() mutating func toggle() // modify (or mutate) the instance it belongs to init(someParameter: Int) // require specific initializers } Usage import Foundation struct UserInfo: Codable { let username: String let loginCount: Int } extension UserInfo: CustomStringConvertible { var description: String { return \"\\(username)has tried to login \\(loginCount)time(s)\" } } ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:15:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Protocol Extension Protocols can be extended to provide method, initializer, subscript, and computed property implementations to conforming types. Very Important and Useful: Implementation to any method or computed property requirement of that protocol can only be in extension extension RandomNumberGenerator { func randomBool() -\u003e Bool { return random() \u003e 0.5 } } By creating an extension on the protocol, all conforming types automatically gain this method implementation without any additional modification. You can use protocol extensions to provide a default implementation to any method or computed property requirement of that protocol. extension PrettyTextRepresentable { var prettyTextualDescription: String { return textualDescription } } Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:15:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Error Handling Representing an Error enum BeverageMachineError: Error { case invalidSelection case insufficientFunds case outOfStock } func selectBeverage (_ selection: Int) throws -\u003e String { // do something return \"Waiting for beverage...\" } // us do...catch to handle error throwed by func let message:String do { message = try selectBeverage(20) } catch BeverageMachineError.invalidSelection { print(\"Invalid selection\") } catch BeverageMachineError.insufficientFunds { print(\"Insufficient Funds\") } catch BeverageMachineError.outOfStock { print(\"Out of Stock\") } catch { print (\"Generic error\") } // if throw error, return nil let message = try? selectBeverage(10) // if throw error, get a runtime error let message = try! selectBeverage(10) Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:16:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Passing Information Coming soon… Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:17:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"User Defaults User defaults are basically a way of storing simple preference values which can be saved and restored across app launches. It is not meant to be used as a data storage layer, like Core Data or sqlite. ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:18:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Storing Values let userDefaults = UserDefaults.standard userDefaults.setValue(\"Some Value\", forKey: \"RPSomeUserPreference\") ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:18:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Retrieving Values let userDefaults = UserDefaults.standard let someValue = userDefaults.value(forKey: \"RPSomeUserPreference\") as AnyObject? There are also other convenience functions on UserDefaults instances such as bool(forKey:...), string(forKey:...), etc. Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:18:2","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Common Patterns For a comprehensive list of design patterns, as established by the Gang of Four, look here: Design Patterns in Swift ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:19:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Singletons Singleton’s are a special kind of class where only one instance of the class exists for the current process. They are a convenient way to share data between different parts of an app without creating global variables or having to pass the data around manually, but they should be used sparingly since they often create tighter coupling between classes. To turn a class into a singleton, you use the following implementation where the function name is prefixed with shared plus another word which best describes your class. For example, if the class is a network or location manager, you would name the function sharedManager instead of sharedInstance. class MyClass { // MARK:- Instantiation // Naming convention: // sharedInstance, sharedManager, sharedController, etc. // depending on the class type static let sharedInstance = MyClass() // This prevents others from using the default '()' initializer for this class. private init() {} var isReady = true // More class code here } Explanation: The static constant sharedInstance is run as dispatch_once the first time that variable is accessed to make sure the initialization is atomic. This ensures it is thread safe, fast, lazy, and also bridged to ObjC for free. More from here. Usage: You would get a reference to that singleton class in another class with the following code: // Now you could do let myClass = MyClass.sharedInstance let answer = myClass.isReady ? \"Yep!\" : \"Nope!\" print(\"Are you ready to rock and roll? \\(answer)\") Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:19:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Unicode Support Although I don’t recommend this, Swift will compile even if you use emoji’s in your code since it offers Unicode support. More info from Apple here Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:20:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"FileIO ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:21:0","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"C style FileIO let fd = fopen(\"aFile.txt\", \"w\") fwrite(\"Hello Swift!\", 12, 1, fd) let res = fclose(file) if res != 0 { print(strerror(errno)) } let fd = fopen(\"aFile.txt\", \"r\") var array = [Int8](count: 13, repeatedValue: 0) fread(\u0026array, 12, 1, fd) fclose(fd) let str = String.fromCString(array) print(str) // Hello Swift! ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:21:1","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Coding"],"content":"Swift Style FileIO let path = Bundle.main.path(forResource:\"test\", ofType: \"txt\") // read let lines = try? String(contentsOfFile: path!) .split{$0 == \"\\n\"} .map(String.init) // write do { let lines = self._outlines.joined(separator: \"\\n\") try lines.write(to: url, atomically: false, encoding: .utf8) } catch{} Back to top ","date":"2020-05-30","objectID":"/2020-05-30-swift-cheat-sheet/:21:2","tags":["Swift"],"title":"Swift Cheat Sheet","uri":"/2020-05-30-swift-cheat-sheet/"},{"categories":["Machine Learning"],"content":"提升（Boosting）方法： 通过改变训练样本的权重（概率分布），学习n个分类器，并将这些分类器线性组合，提高分类性能。 ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:0:0","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"1. AdaBoost AdaBoost通过提高被前一轮弱分类器错误分类样本的权值，从而降低被正确分类样本的权值，并采取加权多数表决的方法达到分类目的。 输入：训练数据集$T={(x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N)}$, $\\mathcal{Y} = {-1,+1}$; 输出：分类器$G(x)$ 1). 初始化训练数据权值分布 $$D_1 = (w_{11}, \\cdots, w_{1i}, \\cdots, w_{1N}), w_{1i} = \\frac{1}{N}, i = 1,2,\\cdots,N$$ 2). 对 $m = 1，2，\\cdots, M$ a.对权值分布$D_m$的训练数据集学习，得到基本分类器 $$ G_{m}(x): \\mathcal{X} \\rightarrow{-1,+1} $$ b.计算$G(x)$在训练数据集上的分类误差率 $$ e_{m}=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right) $$ c. 计算$G(x)$的系数 $$ \\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}} $$ d. 更新训练数据的权值分布 $$ D_{m+1}=\\left(w_{m+1,1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N}\\right) $$ $$ w_{m+1, i} = \\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, N $$ 其中， $$ Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right) $$ 3）构建基本线性分类器组合 $$ f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x) $$ 得到最终分类器 $$ \\begin{aligned} G(x) \u0026=\\operatorname{sign}(f(x)) \\cr \u0026=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\\right) \\end{aligned} $$ ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:1:0","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"1.1 AdaBoost算法误差 AdaBoost算法最终分类器训练误差界为 $$ \\frac{1}{N} \\sum_{i=1}^{N} I\\left(G\\left(x_{i}\\right) \\neq y_{i}\\right) \\leqslant \\frac{1}{N} \\sum_{i} \\exp \\left(-y_{i} f\\left(x_{i}\\right)\\right)=\\prod_{m} Z_{m} $$ 这一定理说明，每一轮选取适当的$G_m$使$Z_m$最小，从而使训练误差下降最快。 对于二分类问题： $$ \\begin{aligned} \\prod_{m=1}^{M} Z_{m} \u0026=\\prod_{m=1}^{M}[2 \\sqrt{e_{m}\\left(1-e_{m}\\right)}] \\cr \u0026=\\prod_{m=1}^{M} \\sqrt{\\left(1-4 \\gamma_{m}^{2}\\right)} \\cr \u0026 \\leqslant \\exp \\left(-2 \\sum_{m=1}^{M} \\gamma_{m}^{2}\\right) \\end{aligned} $$ 其中， $\\gamma_{m}=\\frac{1}{2}-e_{m}$ ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:1:1","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"1.2 AdaBoost算法解释 AdaBooost可以认为：模型为加法模型，损失函数为指数函数，学习算法为前向分布算法的二分类学习方法 1.2.1 前向分步算法 考虑加法模型（additive model） $$ f(x)=\\sum_{m=1}^{M} \\beta_{m} b\\left(x ; \\gamma_{m}\\right) $$ 其中，$b(x; \\gamma_m)$为基函数，$gamma_m$为参数， $\\beta_m$为系数。 在给定训练集和损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$成为经验风险极小化（损失函数极小化）问题： $$ \\min_{\\beta_{m}, \\gamma_{m}} \\sum_{i=1}^{N} L\\left(y_{i}, \\sum_{m=1}^{M} \\beta_{m} b\\left(x_{i} ; \\gamma_{m}\\right)\\right) $$ 前向分布算法思想是： 从前向后，每一步只学一个基函数及其系数，逐步逼近优化目标函数，达到优化步骤简化的目的。 因此，每一步只需优化如下损失函数： $$ \\min_{\\beta, \\gamma} \\sum_{i=1}^{N} L\\left(y_{i}, \\beta b\\left(x_{i} ; \\gamma\\right)\\right) $$ 算法步骤 输入：训练数据集$T=\\lbrace (x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N)\\rbrace$, 损失函数$L(y,f(x))$;基函数集$\\lbrace b(x;\\gamma) \\rbrace$; 输出：加法模型$f(x)$ 1）初始化$f_0(x) = 0$ 2) 对$m = 1,2,\\cdots, M$ a.极小化损失函数 $$ \\left(\\beta_{m}, \\gamma_{m}\\right)=\\arg \\min _{\\beta, \\gamma} \\sum_{i=1}^{N} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+\\beta b\\left(x_{i} ; \\gamma\\right)\\right) $$ 得到参数$\\beta_m$, $\\gamma_m$。 b.更新 $$ f_{m}(x)=f_{m-1}(x)+\\beta_{m} b\\left(x ; \\gamma_{m}\\right) $$ 3）得到加法模型 $$ f(x)=f_{M}(x)=\\sum_{m=1}^{M} \\beta_{m} b\\left(x ; \\gamma_{m}\\right) $$ ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:1:2","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"2. Boosting Tree 提升树🌲是以决策树为基本分类器的提升方法 ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:2:0","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"2.1 提升树模型 采用加法模型（基函数的线性组合）与前向分布算法： $$ f_{M}(x)=\\sum_{m=1}^{M} T\\left(x ; \\Theta_{m}\\right) $$ 其中 $T\\left(x ; \\Theta_{m}\\right)$表示决策树，$\\Theta_{m}$决策树参数， $M$为树的个数 ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:2:1","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"2.2 提升树算法 采用加法模型和前向分布算法实现学习优化的过程。 首先确定提升树$f_{0}(x)=0$， 第$m$步的模型是 $$ f_{m}(x)=f_{m-1}(x)+T\\left(x ; \\Theta_{m}\\right) $$ 其中， $f_{m-1}(x)$为当前模型，通过经验风险极小化确定下一刻决策树的参数$\\Theta_{m}$： $$ \\hat \\Theta_m = \\arg \\min_{\\Theta_{m}} \\sum_{i=1}^{N} L(y_{i}, f_{m-1} (x_{i})+T (x_{i} ; \\Theta_{m} )) $$ 2.2.1 回归问题提升树 训练数据集: $T=\\lbrace (x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N)\\rbrace$, $x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}$, $\\mathcal{X}$为输入空间， $\\mathcal{Y} \\subseteq \\mathbf{R}$; 将输入空间划分为$J$个互不相交的区域$R1，R2, \\cdots, R_J$， 并且每个区域上确定输出的常量$c_j$，那么树可以表示为： $$ T(x ; \\Theta)=\\sum_{j=1}^{J} c_{j} I\\left(x \\in R_{j}\\right) $$ 其中， $$ \\Theta=\\lbrace \\left(R_{1}, c_{1}\\right),\\left(R_{2}, c_{2}\\right), \\cdots,\\left(R_{J}, c_{J}\\right)\\rbrace $$ 表示树的却与划分和各个取悦是那个的常数。 采用一下前向分布算法 $$ \\begin{aligned} \u0026f_{0}(x)=0\\cr \u0026\\begin{array}{l} f_{m}(x)=f_{m-1}(x)+T\\left(x ; \\Theta_{m}\\right), \\quad m=1,2, \\cdots, M \\cr f_{M}(x)=\\sum_{m=1}^{M} T\\left(x ; \\Theta_{m}\\right) \\end{array} \\end{aligned} $$ 求解$\\hat \\Theta_{m}$， 若用平方误差损失函数： $$ L(y, f(x))=(y-f(x))^{2} $$ 则损失函数为： $$ \\begin{aligned} L\\left(y, f_{m-1}(x)+T\\left(x ; \\Theta_{m}\\right)\\right) \u0026=\\left[y-f_{m-1}(x)-T\\left(x ; \\Theta_{m}\\right)\\right]^{2} \\cr \u0026=\\left[r-T\\left(x ; \\Theta_{m}\\right)\\right]^{2} \\end{aligned} $$ 这里， $$ r=y-f_{m-1}(x) $$ 是当前模型拟合数据的残差（residual）。因此对于回归问题提升树，只需拟合当前模型残差。得到$T\\left(x ; \\Theta_{m}\\right)$，更新模型，得到$f_m(x)$。 ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:2:2","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"3. 梯度提升 当损失函数不是简单的平方损失、指数损失时，提升树的优化就很难。梯度提升算法利用最速下降法的近似方法，计算损失函数的负梯度在当前模型的值 $$ -\\left[\\frac{\\partial L\\left(y, f\\left(x_{i}\\right)\\right)}{\\partial f\\left(x_{i}\\right)}\\right]_{f(x)=f_{m-1}(x)} $$ 并将其作为回归问题提升树算法中的残差近似值，拟合一个回归树。 输入： 训练数据集$T=\\lbrace (x_1, y_1), (x_2, y_2), \\cdots, (x_N, y_N)\\rbrace$, $x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}$,$\\mathcal{X}$为输入空间， $\\mathcal{Y} \\subseteq \\mathbf{R}$; 损失函数$L(y,f(x))$ 输出： 回归树$\\hat f(x)$ 初始化 $$ f_{0}(x)=\\arg \\min _{c} \\sum_{i=1}^{N} L\\left(y_{i}, c\\right) $$ 对 $m=1，2，\\cdots, M$ (1) 对 $i=1，2，\\cdots, N$计算 $$ r_{m i}=-\\left[\\frac{\\partial L\\left(y_{i}, f\\left(x_{i}\\right)\\right)}{\\partial f\\left(x_{i}\\right)}\\right]_{f(x)=f_{m-1}(x)} $$ (2) 对$r_{mi}$拟合一个回归树，得到第$m$颗树的节点区域$R_{mj}$ (3) 对$j=1,2,\\cdots, J$, 计算 $$ c_{m j}=\\arg \\min _{c} \\sum_{x_{i} \\in R_{m j}} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+c\\right) $$ (4)更新 $$ f_{m}(x)=f_{m-1}(x)+\\sum_{j=1}^{J} c_{m j} I\\left(x \\in R_{m j}\\right) $$ 得到回归树 $$ \\hat{f}(x)=f_{M}(x)=\\sum_{m=1}^{M} \\sum_{j=1}^{J} c_{m j} I\\left(x \\in R_{m j}\\right) $$ 参考： 李航《统计学习方法》 ","date":"2020-05-05","objectID":"/2020-05-05-ml-boosting/:3:0","tags":["Boosting","Statistical Learning"],"title":"Boosting","uri":"/2020-05-05-ml-boosting/"},{"categories":["Machine Learning"],"content":"隐马可夫模型（HMM）描述隐藏的马可夫链随机生成观测序列的过程，属于生成模型。 HMM在语音识别、自然语言处理、生物信息、模式识别等领域由广泛应用。 ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:0:0","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"1. HMM的定义 隐马可夫模型是关于时序的概率模型， 描述由一个隐藏的马可夫链随机生成不可观测的状态，再由各个状态生成一个观测，从而产生观测随机序列的过程。 简而言之，隐马可夫链随机成状态序列（state sequence），而每个状态生成观测，产生观测序列（observation sequence）。序列的一个位置可以看作一个时刻。 令$Q$ 表示所有可能状态的集合：$Q = { q_1, q_2, \\cdots, q_N }$; 令$V$ 表示所有可能的观测集合：$V = {v_1, v_2, \\cdots, v_M }$; 令$I$ 表示长度为T的状态序列： $I = (i_1, i_2, \\cdots, i_T)$; 令$O$ 表示对应的是观测序列： $O = (o_1, o_2, \\cdots, o_T)$. 令$A$是转移概率矩阵： $$A = [a_{ij}]_{N \\times N}$$ 其中， $$a_{ij} = P(i_{t+1} = q_j | i_t = q_j), i=1,2, \\cdots, N; j = 1,2, \\cdots, N$$ 是在时刻$t$处于状态$q_i$的条件下生成观测$t +1$转移到状态$q_j$的概率。 令$B$是观测概率矩阵： $$B = [b_j(k)]_{N \\times M}$$ 其中， $$b_j(k) = P(o_t = v_k | i_t = q_j), k=1,2,\\cdots, M; j=1,2,\\cdots, N$$ 是在时刻$t$处于状态$q_j$的条件下生成观测$v_k$ 的概率。 令$\\pi$是初始状态概率向量： $$\\pi = (\\pi_i)$$ 其中， $$\\pi_{i} = P(i_1 = q_i),i=1,2,\\cdots, N$$ 是时刻t=1处于状态$q_i$的概率. 隐马可夫模型$\\lambda$由$\\pi$， $A$，$B$决定。 $$\\lambda = (A, B, \\pi)$$ 其中，$\\pi$和$A$决定状态序列，$B$决定观测序列。 隐马可夫模型的两个基本假设 齐次马可夫性 隐马可夫链在任意时刻t的状态前一时刻状态，与其他时刻的隐状态和观测无关， 也与时刻t无关： $$P(i_t | i_{t-1}, O_{t-1}, \\cdots, i_1, o_1) = P(i_t | i_{t-1}), t = 1,2,\\cdots,T$$ 观测独立性 任意时刻的观测只依赖改时刻的马可夫链状态，与其他观测和状态无关: $$P(o_t | i_{T}, O_{T}, i_{T-1}, o_{T-1}\\cdots, i_{t+1}, O_{t+1}, i_{t-1}, O_{t-1}, i_1, o_1) = P(o_t | i_{t})$$ ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:1:0","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"2. HMM的3个基本问题 概率计算：给定模型$\\lambda = (A, B, \\pi)$和观测序列 $O = (o_1, o_2, \\cdots, o_T)$， 求概率$P(O | \\lambda)$ 学习: 已知观测序列$O = (o_1, o_2, \\cdots, o_T)$，估计模型参数$\\lambda = (A, B, \\pi)$， 使概率$P(O \\vert \\lambda)$最大（用极大似然估计）。 预测：给定模型$\\lambda = (A, B, \\pi)$和观测序列 $O = (o_1, o_2, \\cdots, o_T)$，求条件概率$P(I | O)$最大的状态序列 $I = (i_1, i_2, \\cdots, i_T)$. ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:2:0","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"2.1 概率计算前向（forward）和后向（backward）算法 2.1.1 前向算法 给定模型$\\lambda$，当时刻$t$时，状态为$q_i$，部分观测序列为$o_1, o_2, \\cdots, o_t$，记： $$\\alpha_{t}(i) = P(o_1, o_2, \\cdots, o_t, i_t = q_i | \\lambda)$$ 输入： 隐马可夫模型 $\\lambda$， 观测序列$O$; 输出： 观测序列概率$P(O | \\lambda)$ （1）初值 $$ \\alpha_{1}(i)=\\pi_{i} b_{i}\\left(o_{1}\\right), \\quad i=1,2, \\cdots, N $$ （2）递推 对 $t = 1,2, \\cdots, T-1,$ $$ \\alpha_{t+1}(i)=\\left[\\sum_{j=1}^{N} \\alpha_{t}(j) a_{j i}\\right] b_{i}\\left(o_{t+1}\\right), \\quad i=1,2, \\cdots, N $$ （3）终止 $$ P(O | \\lambda)=\\sum_{i=1}^{N} \\alpha_{T}(i) $$ 2.1.2 后向算法 给定模型$\\lambda$，当时刻$t$时，状态为$q_i$，部分观测序列为$o_1, o_2, \\cdots, o_t$，记： $$\\beta_{t}(i) = P(o_{t+1}, o_{t+2}, \\cdots, o_T | i_t = q_i, \\lambda)$$ 输入： 隐马可夫模型 $\\lambda$， 观测序列$O$; 输出： 观测序列概率$P(O | \\lambda)$ （1）初始 令最终时刻所有状态$q_i$ $$\\beta_T(i) = 1, i=1,2,\\cdots, N$$ （2）递推 对$t=T-1, T-2, \\cdots, 1$ $$ \\beta_{t}(i)=\\sum_{j=1}^{N} a_{i j} b_{j}\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad i=1,2, \\cdots, N $$ （3）终止 $$ P(O | \\lambda)=\\sum_{i=1}^{N} \\pi_{i} b_{i}\\left(o_{1}\\right) \\beta_{1}(i) $$ 利用前后向概率定义，可以将观测序列概率$P(O \\vert \\lambda)$统一写成 $$ P(O | \\lambda)=\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_{t}(i) a_{i j} b_{j}\\left(o_{t+1}\\right) \\beta_{t+1}(j), \\quad t=1,2, \\cdots, T-1 $$ ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:2:1","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"2.2 学习问题的EM算法 实质上求一个隐变量的概率模型的参数估计： $$ P(O | \\lambda)=\\sum_{I} P(O | I, \\lambda) P(I | \\lambda) $$ 参数估计由EM算法实现: (待续) 输入：观测数据$O = (o_1, o_2, \\cdots, o_T)$; 输出：隐马可夫模型参数 （1）初始化 对 n=0， 选取$a_{ij}^{(0)}$, $b_{j}(k)^{(0)}$, $\\pi_{i}^{(0)}$, 得到模型$\\lambda = (A^{(0)}, B^{(0)}, \\pi^{(0)})$. （2）递推 对$n=1,2, \\cdots,$, 有 $$ a_{i j}^{(n+1)}=\\frac{\\sum_{t=1}^{T-1} \\xi_{t}(i, j)}{\\sum_{t=1}^{T-1} \\gamma_{t}(i)} $$ 另， $$ b_{j}(k)^{(n+1)}=\\frac{\\sum_{t=1, o_{t}=v_{k}}^{T} \\gamma_{t}(j)}{\\sum_{t=1}^{T} \\gamma_{t}(j)} $$ $$ \\pi_{i}^{(n+1)}=\\gamma_{1}(i) $$ 其中，时刻$t$处于$q_i$，且时刻$t+1$处于状态$q_j$的概率, 记 $$ \\xi_{t}(i, j)=P\\left(i_{t}=q_{i}, i_{t+1}=q_{j} | O, \\lambda\\right) $$ 那么 $$ \\xi_{t}(i, j)=\\frac{P\\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \\lambda\\right)}{P(O | \\lambda)}=\\frac{P\\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \\lambda\\right)}{\\sum_{i=1}^{N} \\sum_{j=1}^{N} P\\left(i_{t}=q_{i}, i_{t+1}=q_{j}, O | \\lambda\\right)} $$ 和时刻$t$处于$q_i$的概率， 有 $$ \\gamma_{t}(i)=P\\left(i_{t}=q_{i} | O, \\lambda\\right)=\\frac{P\\left(i_{t}=q_{i}, O | \\lambda\\right)}{P(O | \\lambda)} $$ （3）终止 得到模型参数$\\lambda^{(n+1)} = (A^{(n+1)}, B^{(n+1)}, \\pi^{(n+1)})$ ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:2:2","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"2.3 预测算法 包括近似算法和维特比算法（Viterbi algorithm） 2.3.1 近似算法 在每个时刻$t$， 选择在该时刻最可能出现的状态 $i^*_t$从而得到一个状态序列 $I^* = (i^*_i, i^*_i, \\cdots, i^*_T)$，将它最为预测结果。 给定模型$\\lambda$和观测序列$O$， 在时刻$t$处于状态$q_i$的概率$\\gamma_t(i)$是 $$ \\gamma_{t}(i)=\\frac{\\alpha_{t}(i) \\beta_{t}(i)}{P(O | \\lambda)}=\\frac{\\alpha_{t}(i) \\beta_{t}(i)}{\\sum_{j=1}^{N} \\alpha_{t}(j) \\beta_{t}(j)} $$ 而每一时刻$t$最有可能的状态$i_{t}^{*}$是 $$ i_{t}^{*}=\\arg \\max _{1 \\leqslant i \\leqslant N}\\left[\\gamma_{t}(i)\\right], \\quad t=1,2, \\cdots, T $$ 从而得到状态序列 $$I^* = (i^*_i, i^*_i, \\cdots, i^*_T)$$ 缺点： 不能保证预测状态序列整体是最有可能的状态序列，因为预测的状态序列实际可能由不发生的部分。 2.3.2 维特比算法 实质是运用动态规划求概率最大路径，从而解决HMM的预测问题 维特比算法: 只需从时刻$t=1$开始，递推地计算在时刻$t$状态为$q_i$的各条部分路径的最大概率，直至得到时刻$t = T$状态为$i$的各条路径的最大概率。时刻 $t = T$ 的最大概率即为最优路径的概率 $P^\\ast$, 最优路径的终结点$i^*_T$ 也同时得到。之后，为了找出最优路径的各个结点，从终结点$i^*_T$开始，由后向前逐步求得结点 $i^*_{T-1}, \\cdots, i^*_1$，得到最优路径$I^* = (i^*_i, i^*_i, \\cdots, i^*_T)$。 定义在时刻$t$状态$i$的所有单个路径中概率最大值为 $$ \\delta_{t}(i)=\\max_{i_{1}, i_{2}, \\cdots, i_{t-1}} P\\left(i_{t}=i, i_{t-1}, \\cdots, i_{1}, o_{t}, \\cdots, o_{1} | \\lambda\\right), \\quad i=1,2, \\cdots, N $$ 因此 $$ \\begin{aligned} \\delta_{t+1}(i) \u0026=\\max _{i_{1}, i_{2}, \\cdots, i_{t}} P\\left(i_{t+1}=i, i_{t}, \\cdots, i_{1}, o_{t+1}, \\cdots, o_{1} | \\lambda\\right) \\cr \u0026= \\max _{1 \\leqslant j \\leqslant N}\\left[\\delta_{t}(j) a_{j i}\\right] b_{i}\\left(o_{t+1}\\right), \\quad i=1,2, \\cdots, N ; \\quad t=1,2, \\cdots, T-1 \\end{aligned} $$ 定义在时刻t状态i的所有单个路径中概率最大路径的第$t-1$个节点为 $$ \\Psi_{t}(i)=\\arg \\max _{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right], \\quad i=1,2, \\cdots, N $$ 输入： 隐马可夫模型 $\\lambda$， 观测序列$O$; 输出： 最优路径$$I^* = (i^*_i, i^*_i, \\cdots, i^*_T)$$ (1) 初始化: $$ \\begin{array}{c} \\delta_{1}(i)=\\pi_{i} b_{i}\\left(o_{1}\\right), \\quad i=1,2, \\cdots, N \\cr \\Psi_{1}(i)=0, \\quad i=1,2, \\cdots, N \\end{array} $$ (2) 递推: $$ \\begin{array}{c} \\delta_{t}(i)=\\max _{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right] b_{i}\\left(o_{t}\\right), \\quad i=1,2, \\cdots, N \\cr \\Psi_{t}(i)=\\arg \\max _{1 \\leqslant j \\leqslant N}\\left[\\delta_{t-1}(j) a_{j i}\\right], \\quad i=1,2, \\cdots, N \\end{array} $$ (3) 终止 $$ \\begin{array}{c} P^* = \\max _{1 \\leqslant i \\leqslant N} \\delta_T(i) \\cr i^*_T = \\arg \\max _{1 \\leqslant i \\leqslant N} [ \\delta_T(i)] \\end{array} $$ (4) 最优路径回溯 对$t=T-1, T-2, \\cdots, 1$, $$i^*_t = \\Psi_{t+1}(i^*_{t+1})$$ 参考： 李航《统计学习方法》 ","date":"2020-05-03","objectID":"/2020-05-03-ml-hmm/:2:3","tags":["Hidden Markov Model","Expectation Maximization","Probabilistic Graphical Model","Statistical Learning"],"title":"Hidden Markov Model (HMM)","uri":"/2020-05-03-ml-hmm/"},{"categories":["Machine Learning"],"content":"潜在语义分析（LSA）是一种非监督学习方法，用于文本话题分析。其特点是通过矩阵分解发现文本于单词之间的基于话题的语义关系。 潜在语义分析是一种非概率话题分析模型。步骤为： 先将文本集合表示为单词-文本矩阵 对单词-文本矩阵进行奇异值分解（SVD）或非负矩阵分解（NMF），从而得到话题向量空间，以及文本在话题向量空间的表示 ","date":"2020-04-30","objectID":"/2020-04-30-ml-lsa/:0:0","tags":["TF-IDF","Latent Semantic Analysis","Statistical Learning"],"title":"Latent semantic analysis (LSA)","uri":"/2020-04-30-ml-lsa/"},{"categories":["Machine Learning"],"content":"1. 单词向量空间 给定由n个文本的集合 $D = \\lbrace d_1, d_2, \\cdots, d_n \\rbrace$ ,以及所有文本中单词集 $W = \\lbrace w_1, w_2, \\cdots, w_m \\rbrace$, 则单词在文本中出现的数据用单词-文本矩阵(word-document matrix)表示, 记为： $$ X=\\left[\\begin{array}{cccc} x_{11} \u0026 x_{12} \u0026 \\cdots \u0026 x_{1 n} \\cr x_{21} \u0026 x_{22} \u0026 \\cdots \u0026 x_{2 n} \\cr \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\cr x_{m 1} \u0026 x_{m 2} \u0026 \\cdots \u0026 x_{m n} \\end{array}\\right] $$ 其中， $x_{ij}$表示单词$w_i$在文本$d_j$中出现的频数或权值。由于单词种类多，而每个文本中单词种类通常少，所以为单词-文本矩阵是稀疏矩阵。 权值常用单词频率-逆文本频率(term frequeny-inverse document frequency, TF-IDF)表示: $$ \\mathrm{TFIDF_{ij}}=\\frac{\\mathrm {tf_{ij}}}{\\mathrm {tf_{\\cdot j}}} \\log \\frac{\\mathrm{df}}{\\mathrm {df_i}}, \\quad i=1,2, \\cdots, m ; \\quad j=1,2, \\cdots, n $$ 其中， $\\mathrm{tf}_{ij}$ 是单词 $w_i$ 在文本 $d_j$ 中的频数; $\\mathrm{tf}_{\\cdot j}$ 是 $d_j$ 中出现的所有单词频数之和; $\\mathrm{df}_{i}$ 是含有单词$w_i$的文本数; $\\mathrm{df}$ 是文本集合$D$的全部文本数。 单词-文本矩阵的第j列向量$x_j$表示文本$d_j$： $$ x_{j}=\\left[\\begin{array}{c} x_{1 j} \\cr x_{2 j} \\cr \\vdots \\cr x_{m j} \\end{array}\\right], \\quad j=1,2, \\cdots, n $$ 两个单词向量内积或者标准化内积表示对应文本之间的语义相似度， 因此文本$d_i$与$d_j$的之间的相似度： $$ x_{i} \\cdot x_{j}, \\quad \\frac{x_{i} \\cdot x_{j}}{\\left|x_{i}\\right|\\left|x_{j}\\right|} $$ 单词向量空间模型的优缺点 优点： 简单，计算高效 缺点： 一词多义(polysemy)和多词一义(synonymy)不能很好处理， 存在相似度计算不准确的问题 ","date":"2020-04-30","objectID":"/2020-04-30-ml-lsa/:0:1","tags":["TF-IDF","Latent Semantic Analysis","Statistical Learning"],"title":"Latent semantic analysis (LSA)","uri":"/2020-04-30-ml-lsa/"},{"categories":["Machine Learning"],"content":"2. 话题（topic）向量空间 话题没有严格的定义，是指文本讨论的内容或主题。而基于话题的模型是为了解决单词向量不能很好处理一词多义(polysemy)和多词一义(synonymy)的问题。 给定由n个文本的集合 $D = \\lbrace d_1, d_2, \\cdots, d_n \\rbrace$, 以及所有文本中单词集 $W = \\lbrace w_1, w_2, \\cdots, w_m \\rbrace$, 则单词在文本中出现的数据用单词-文本矩阵(word-document matrix)表示, 记为： $$ X=\\left[\\begin{array}{cccc} x_{11} \u0026 x_{12} \u0026 \\cdots \u0026 x_{1 n} \\cr x_{21} \u0026 x_{22} \u0026 \\cdots \u0026 x_{2 n} \\cr \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\cr x_{m 1} \u0026 x_{m 2} \u0026 \\cdots \u0026 x_{m n} \\end{array}\\right] $$ 假设所有文本含有k个话题， 每个话题l由一个定义在单词集合W傻姑娘的m维向量： $$ t_{l}=\\left[\\begin{array}{c} t_{1 l} \\cr t_{2 l} \\cr \\vdots \\cr t_{m l} \\end{array}\\right], \\quad l=1,2, \\cdots, k $$ 则有话题向量矩阵T： $$ T=\\left[\\begin{array}{cccc} t_{11} \u0026 t_{12} \u0026 \\cdots \u0026 t_{1 k} \\cr t_{21} \u0026 t_{22} \u0026 \\cdots \u0026 t_{2 k} \\cr \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\cr t_{m 1} \u0026 t_{m 2} \u0026 \\cdots \u0026 t_{m k} \\end{array}\\right] $$ ","date":"2020-04-30","objectID":"/2020-04-30-ml-lsa/:0:2","tags":["TF-IDF","Latent Semantic Analysis","Statistical Learning"],"title":"Latent semantic analysis (LSA)","uri":"/2020-04-30-ml-lsa/"},{"categories":["Machine Learning"],"content":"3. 文本在话题向量空间的表示 文本$d_j$在单词向量空间用$x_j$表示，将$x_j$投影到话题向量空间$T$，得到话题向量空间$y_j$，$y_j$是个k维向量: $$ y_{j}=\\left[\\begin{array}{c} y_{1 j} \\cr y_{2 j} \\cr \\vdots \\cr y_{k j} \\end{array}\\right], \\quad j=1,2, \\cdots, n $$ 因此，话题-文本矩阵$Y$： $$ Y=\\left[\\begin{array}{cccc} y_{11} \u0026 y_{12} \u0026 \\cdots \u0026 y_{1 n} \\cr y_{21} \u0026 y_{22} \u0026 \\cdots \u0026 y_{2 n} \\cr \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\cr y_{k 1} \u0026 y_{k 2} \u0026 \\cdots \u0026 y_{k n} \\end{array}\\right] $$ ","date":"2020-04-30","objectID":"/2020-04-30-ml-lsa/:0:3","tags":["TF-IDF","Latent Semantic Analysis","Statistical Learning"],"title":"Latent semantic analysis (LSA)","uri":"/2020-04-30-ml-lsa/"},{"categories":["Machine Learning"],"content":"4. 单词向量空间到话题向量空间转换 因此，单词向量空间的文本向量$x_j$，可以用话题向量空间$y_j$近似表示，即以k个话题向量以$y_j$为系数的线性组合： $$ x_{j} \\approx y_{1 j} t_{1}+y_{2 j} t_{2}+\\cdots+y_{k j} t_{k}, \\quad j=1,2, \\cdots, n $$ 矩阵形式： $$ X \\approx TY $$ 这就是潜在语义分析。 参考： 李航《统计学习方法》 ","date":"2020-04-30","objectID":"/2020-04-30-ml-lsa/:0:4","tags":["TF-IDF","Latent Semantic Analysis","Statistical Learning"],"title":"Latent semantic analysis (LSA)","uri":"/2020-04-30-ml-lsa/"},{"categories":["Machine Learning"],"content":"CRF条件随机场，可应用于标注问题 概率无向图模型Probabilistic undirected graphical model(Markov random field) 是一个可以由无向图表示的联合概率分布 ","date":"2020-04-29","objectID":"/2020-04-29-ml-crf/:0:0","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Conditional random field (CRF)","uri":"/2020-04-29-ml-crf/"},{"categories":["Machine Learning"],"content":"1. 模型定义 概率图模型：由图（Graph）表示的概率分布。 令无向图 G = (V, E) 表示联合概率分布P(Y)，即G中， 节点$v \\in V$ 表示随机变量$Y_{v}, Y=\\left(Y_{v}\\right)_{v \\in V}$； 边$e \\in E$表示随机变量之间的概率依赖关系 无向图表示的随机变量的独立性假设: 成对马可夫性 pariwise Markov property 指任意两个没有边连接的节点，在给定随机变量组（其他所有节点）条件下，该两节点是条件独立 局部马可夫性 local Markov property 马科夫毯（Markov blanket）:节点 v 的所有相邻节点， 指任意一个节点 v，在给定其所有相邻节点 W 条件下， v于除v，W以外的节点条件独立 全局马可夫性 global Markov property 节点集合A、C被集合B所分开，在给定B条件下，A与C条件独立。 概率无向图模型：无向图 $G = (V, E)$ 表示联合概率分布 $P(Y)$，如果联合概率分布 $P(Y)$ 满足成对、局部或全局马可夫性，就称此联合概率分布 $P(Y)$ 为概率无向图模型，或马可夫随机场 团（clique）：图G中任何两个节点均有边连接的节点子集 最大团（maximal clique）：团C中不能再加任何一个节点使它成为更大的团，则称最大团 ","date":"2020-04-29","objectID":"/2020-04-29-ml-crf/:0:1","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Conditional random field (CRF)","uri":"/2020-04-29-ml-crf/"},{"categories":["Machine Learning"],"content":"2. 条件随机场 条件随机场指给定随机变量X条件下， 随机变量Y的马可夫随机场。 2.1 条件随机场： 若随机变量$Y$构成一个由无向图$G = (V, E)$表示的马可夫随机场，即 $$ P\\left(Y_{v} | X, Y_{w}, w \\neq v\\right)=P\\left(Y_{v} | X, Y_{w}, w \\sim v\\right) $$ 对于任意节点$v$成立， 则称条件概率分布$P(Y\\vert X)$为条件随机场。其中$w \\sim v$表示在图$G = (V, E)$中与节点$v$有边连接的所有节点$w$， $w \\neq v$表示节点v以外的所有节点。 2.2 线性链条件随机场（ linear chain conditional random field） 线性链条件随机场也是对数线性模型(log linear model)，定义为： $$ P\\left(Y_{i} | X, Y_{1}, \\cdots, Y_{i-1}, Y_{i+1}, \\cdots, Y_{n}\\right)=P\\left(Y_{i} | X, Y_{i-1}, Y_{i+1}\\right) $$ 在条件概率模型$P(Y | X)$中， $Y$是输出变量，表示标记序列（状态序列，参见HMM）；$X$使输入变量，表示需要标注的观测序列。利用训练集，通过极大似然估计或正则化的极大似然估计得到条件概率模型$\\hat{P}(Y | X)$;预测时，对于给定输入序列$x$，求条件概率$\\hat{P}(Y | X)$最大的输出序列$\\hat{y}$。 2.3 条件随机场的参数化形式 设$P(Y\\vert X)$为线性链条件随机场，X取值为x， Y取值为y的条件概率具有如下形式： $$ P(y | x)=\\frac{1}{Z(x)} \\exp \\left(\\sum_{i, k} \\lambda_{k} t_{k}\\left(y_{i-1}, y_{i}, x, i\\right)+\\sum_{i, l} \\mu_{l} s_{l}\\left(y_{i}, x, i\\right)\\right) $$ 其中， $$ Z(x)=\\sum_{y} \\exp \\left(\\sum_{i, k} \\lambda_{k} t_{k}\\left(y_{i-1}, y_{i}, x, i\\right)+\\sum_{i, l} \\mu_{l} s_{l}\\left(y_{i}, x, i\\right)\\right) $$ 式中，$t_{k}$和$s_{l}$是特征函数, $\\lambda_{k}$和$\\mu_{l}$是对应的权值。 $Z(x)$是规范化因子。在所有可能输出的序列上进行求和操作。 关于特征函数： 令$t_{k}$是定义在边上的特征函数，称为转移特征，依赖当前和前一个位置 令$s_{l}$是定义在节点上的特征函数，称为状态特征，依赖当前位置 特征函数$t_{k}$和$s_{l}$取值0或1；满足条件取1，反之0 条件随机长完全由特征函数$t_{k}$和$s_{l}$， 和对应的权值$\\lambda_{k}$和$\\mu_{l}$确定。 2.4 条件随机场的矩阵形式 对于观测序列x的每个位置，y在m个标记中取值，可以定义一个m阶的矩阵随机变量： $$ M_{i}(x) = [ M_{i}(y_{i-1}, y_{i}|x) ] $$ 矩阵随机变量元素为 $$ \\begin{aligned} \u0026M_{i}\\left(y_{i-1}, y_{i} | x\\right)=\\exp \\left(W_{i}\\left(y_{i-1}, y_{i} | x\\right)\\right)\\cr \u0026W_{i}\\left(y_{i-1}, y_{i} | x\\right)=\\sum_{k=1}^{K} w_{k} f_{k}\\left(y_{i-1}, y_{i}, x, i\\right) \\end{aligned} $$ 这里$w_k$为 $$ w_{k}=\\begin{cases} \\lambda_{k}, \u0026 k=1,2, \\cdots, K_{1} \\cr \\mu_{l}, \u0026 k=K_{1}+l ; l=1,2, \\cdots, K_{2} \\end{cases} $$ 和$f_k$为 $$ f_{k}\\left(y_{i-1}, y_{i}, x, i\\right)=\\begin{cases} t_{k}\\left(y_{i-1}, y_{i}, x, i\\right), \u0026 k=1,2, \\cdots, K_{1} \\cr s_{l}\\left(y_{i}, x, i\\right), \u0026 k=K_{1}+l ; l=1,2, \\cdots, K_{2} \\end{cases} $$ 于是，条件概率$P_{w}(y \\vert x)$: $$ P_{w}(y | x)=\\frac{1}{Z_{w}(x)} \\prod_{i=1}^{n+1} M_{i}\\left(y_{i-1}, y_{i} | x\\right) $$ 其中， $$ Z_{w}(x)=\\left[M_{1}(x) M_{2}(x) \\cdots M_{n+1}(x)\\right]_{\\mathrm{start}, \\mathrm{stop}} $$ 注， $y_{0} = \\mathrm{start}$，表示开始状态； $y_{n+1} = \\mathrm{stop}$， 表示终止状态 参考： 李航《统计学习方法》 ","date":"2020-04-29","objectID":"/2020-04-29-ml-crf/:0:2","tags":["Probabilistic Graphical Model","Statistical Learning"],"title":"Conditional random field (CRF)","uri":"/2020-04-29-ml-crf/"},{"categories":["Statistic"],"content":"Probability, P-value, Likelihood ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:0:0","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Probability and likelihood likehood \u0026 maximum likehood 在非正式场合似然（likelihood）和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。 概率: 在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性。 比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的； 似然: 刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数）。 假设随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上，那么两面朝上的概率均为50%。运用出现的结果来判断这个事情本身的性质（参数），也就是似然。 当结果和参数相互对应，似然和概率在数值上相等。 用 θ 表示环境对应的参数，x 表示结果，那么概率可以表示为： $$P(x | \\theta )$$ $p(x \\vert θ)$ 是条件概率的表示方法。θ 是前置条件，理解为在 θ 的前提下，事件 x 发生的概率，相对应的似然可以表示为: $$\\mathcal{L}(\\theta | x)$$ 可以理解为已知结果为 x ，参数为 θ (似然函数里 θ 是变量，这里说的参数和变量是相对与概率而言的)对应的概率，即： $$\\mathcal{L}(\\theta | x)=P(x | \\theta)$$ 两者在数值上相等，但是意义并不相同, $\\mathcal{L}$ 是关于 θ 的函数，而 P 则是关于 x 的函数。 ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:1:0","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Probability and P-value A p-value is the probability that random chance generated the data, or something else that is equal or rarer. A p-value is composed of three parts: The probability random chance would result in the observation. The probability of observing something else that is equally rare. The probability of observing something rarer or more extreme. But probability $$ \\text{Probalibility} = \\frac{ \\text{Number of outcomes of interest}} { \\text{The total number of outcomes}}$$ In hypothesis testing, p-values are numbers, between 0 and 1, that, how small does a p-value have to be before we are confident that interested A is different from B. Statquest: P Values, clearly explained ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:0","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"PDF (probability density function) PDF：概率密度函数（probability density function）, 连续型随机变量的概率密度函数是一个描述某个确定的取值点附近的可能性的函数。 数学表示：用PDF在某一区间上的积分来刻画随机变量落在这个区间中的概率 $$ \\operatorname{Pr}(a \\leq X \\leq b)=\\int_{a}^{b} f_{X}(x) d x $$ ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:1","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"PMF (probability mass function) PMF : 概率质量函数（probability mass function), 在概率论中，概率质量函数是离散随机变量在各特定取值上的概率。 数学表示： PMF其实就是高中所学的离散型随机变量的分布律。 $$ f_{X}(x)=\\operatorname{Pr}(X=x) $$ ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:2","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"CDF (cumulative distribution function) CDF : 累积分布函数 (cumulative distribution function)，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布。 CDF是PDF的（从负无穷$-\\infty$到当前值的）积分，PDF是CDF的导数．（为了便于概率的计算，引入CDF的概念） CDF相当于其左侧的面积，也相当于小于该值的概率，负无穷的CDF值为０，正无穷的CDF值总为１． 对于连续变量，有 $$ F_{X}(x)=\\operatorname{Pr}(X \\leq x)=\\int_{-\\infty}^{x} f_{X}(t) dt $$ 对于离散型变量，有如 $$ F_{X}(x)=\\operatorname{Pr}(X \\leq x)= \\begin{cases} 0 \\text { if } x\u003c0 \\cr \\frac{1}{2} \\text { if } 0 \\leq x\u003c1 \\cr 1 \\text { if } x \\geq 1 \\end{cases} $$ ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:3","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Central Limit Theorem 中心极限定理（Central Limit Theorem） 给定一个任意分布的总体， 每次从这些总体中随机抽取 n 个抽样，一共抽 m 次， 然后把这 m 组抽样分别求出平均值， 当m足够大时，这m次的平均值的分布（称为抽样分布）接近正态分布。 独立同分布的中心极限定理 $$ \\lim_{n \\rightarrow \\infty} F_{\\mathcal{X}}(x) = \\lim_{n \\rightarrow \\infty} P \\Bigg\\lbrace \\frac{\\sum_{k=1}^{n}X_k - n\\mu}{\\sqrt{n}\\sigma} \\leq x \\Bigg\\rbrace = \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{t^2}{2}}dt $$ 德莫佛－拉普拉斯定理: 设随机变量序列$\\lbrace \\eta_1, \\eta_2,\\cdots, \\eta_n \\rbrace$ 服从参数为$n, p (0 \u003c p \u003c 1)$ 的二项分布 $$ \\lim_{n \\rightarrow +\\infty} P \\Bigg\\lbrace \\frac{\\eta_n - np }{\\sqrt{np(1-p)}} \\leq x \\Bigg\\rbrace = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{t^2}{2}}dt $$ ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:4","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Law of Large Numbers 当样本数据无限大时，样本均值趋于总体均值 $$ \\bar{X} = \\frac{1}{n} \\sum_{k=1}^n X_k \\xrightarrow{p} \\mu $$ 大数定律告诉我们能用频率近似代替概率；能用样本均值近似代替总体均值。 辛钦大数定律: 设$X_1, X_2, \\cdots, X_n$是相互独立且服从同分布的随机变量序列， 具有数学期望$E(X_k) = \\mu$, $k=1,2,3,\\cdots$。对于任意 $\\epsilon \u003e 0$, 有 $$ \\lim_{n \\rightarrow +\\infty} P \\bigg\\lbrace | \\frac{1}{n} \\sum_{k=1}^n X_k - \\mu | \u003c \\epsilon \\bigg\\rbrace = 1 $$ 切比雪夫大数定律: 随机变量序列$X$具有相同期望和方差, 样本均值依概率$p$收敛于 $\\mu$ $$ \\frac{1}{n} \\sum_{k=1}^n X_k \\xrightarrow{p} \\mu $$ 伯努利大数定律: $n_A$是n次独立重复试验中事件A发生的次数， p是事件A在每次试验中发生的概率，任意$\\epsilon \u003e 0$ $$ \\lim_{n \\rightarrow +\\infty} P \\bigg\\lbrace | \\frac{n_A}{n} - p | \u003c \\epsilon \\bigg\\rbrace = 1 $$ 比较 定律 分布 期望 方差 结论 辛钦大数定律 相互独立且同分布 存在 估算期望 切比雪夫大数定律 相互独立 相同 相同 估算期望 伯努利大数定律 二项分布 相同 相同 频率=概率 相同点：$n \\rightarrow +\\infty$, 依概率趋近 条件组件变得严格 ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:5","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Confidence interval 置信区间（confidence interval） 置信区间是指由样本统计量所构造的总体参数的估计区间。 置信区间展现的是这个参数的真实值落在测量值（推测值）的周围的可信程度。 ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:2:6","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Statistic"],"content":"Additional: StatQuest How to calculate P-value ","date":"2020-04-29","objectID":"/2020-04-29-stats-proba-pvalue/:3:0","tags":["P-Value"],"title":"Probability, P-value, Likelihood","uri":"/2020-04-29-stats-proba-pvalue/"},{"categories":["Make bioinfo uncool again"],"content":"The correct way to convert seurat to Scanpy h5ad","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"IMPORTANT UPDDATE: 2023-02-21 Refer to MuDataSeurat # single modality MuDataSeurat::WriteH5AD(srt, \"srt.h5ad\") # multi modality MuDataSeurat::WriteH5MU(srt, \"srt.h5mu\") ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:1:0","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"IMPORTANT UPDATE: 2021-04-15 ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:2:0","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"SeuratDisk Please see SeuratDisk to convert seurat to scanpy. library(Seurat) library(SeuratDisk) # step 1: Slim down a Seurat object. So you get raw counts, lognorm counts seu = DietSeurat( srt, counts = TRUE, # so, raw counts save to adata.raw.X data = TRUE, # so, log1p counts save to adata.X scale.data = FALSE, # set to false, or else will save to adata.X features = rownames(srt), # export all genes, not just top highly variable genes assays = \"RNA\", dimreducs = c(\"pca\",\"umap\"), graphs = c(\"RNA_nn\", \"RNA_snn\"), # to RNA_nn -\u003e distances, RNA_snn -\u003e connectivities misc = TRUE ) # step 2: factor to character, or else your factor will be number in adata i \u003c- sapply(seu@meta.data, is.factor) seu@meta.data[i] \u003c- lapply(seu@meta.data[i], as.character) # step 3: convert SaveH5Seurat(seu, filename = \"srt.h5seurat\", overwrite = TRUE) Convert(\"srt.h5seurat\", \"srt.h5ad\", assay=\"RNA\", overwrite = TRUE) # load h5ad import scanpy as sc adata = sc.read_h5ad(\"srt.h5ad\") # save counts to layers adata.layers['counts'] = adata.raw.X.copy() adata.layers['log1p'] = data.X.copy() # you need to scale data for downsream tasks if needed. ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:3:0","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"Seurat -\u003e loom -\u003e scanpy You actually neeed additional steps when seurat -\u003e loom -\u003e scanpy see here save to loom format. pbmc.loom \u003c- as.loom(seurat_object, filename = \"../output/pbmc.loom\", verbose = FALSE) pbmc.loom$close_all() # alway close when done write.csv(Cells(seurat_object), file = \"cellID_obs.csv\", row.names = FALSE) write.csv(Embeddings(seurat_object, reduction = \"umap\"), file = \"cell_embeddings.csv\") write.csv(seurat_object@meta.data$seurat_clusters, file = \"clusters.csv\") read into scanpy import scanpy as sc adata = sc.read_loom(\"../output/pbmc.loom\") sample_obs = pd.read_csv(\"cellID_obs.csv\") umap_cord = pd.read_csv(\"cell_embeddings.csv\") cell_clusters = pd.read_csv(\"clusters_obs.csv\") # now add metadata to the adata # e.g. adata.obsm['X_umap'] = umap_ordered.values # cellID should be matched first adata.uns['Cluster_colors'] = ... ... open loom in R immune \u003c- Connect(filename = \"../data/mmune_cells.loom\", mode = \"r\") seurat \u003c- as.Seurat(immune) immune$close_all() # alway close when done ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:4:0","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"rpy2 This is the old way. Very hard to make it work. Not recommended! Convert Seurat to Scanpy costed me a lot of time to convert seurat objects to scanpy. It’s not a pleasant experience. ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:5:0","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"1. Install Seurat v3.0.2, or python kernel will always died!!! Don’t know why latest seurat not work. ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:5:1","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"2. Set the R version for rpy2 # user defined R installation import os # path to your libR.so, only Seurat v3.0.2 works! # create a conda R env for seurat 3.0.2 first os.environ['R_HOME'] = '/home/fangzq/miniconda/envs/seurat/lib/R' # path depends on where you installed Python. os.environ['R_USER'] = '/home/fangzq/miniconda/lib/python3.7/site-packages/rpy2' ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:5:2","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"3. Now, you’er good to go import scanpy as sc import glob Install anndata2ri first import anndata2ri from rpy2.robjects import r from rpy2.robjects.conversion import localconverter # activate rpy2 env anndata2ri.activate() robjs = glob.glob(\"data/*Robj\") Convert to h5ad r('library(Seurat)') for robj in robjs: r(f'x\u003c-load(\"{robj}\")') r('y=get(x)') r('rm(x)') r('DefaultAssay(y) \u003c- \"RNA\"') # get raw count matrix to save # seurat2 object # adata = r('as.SingleCellExperiment(UpdateSeuratObject(y))') adata = r('as.SingleCellExperiment(y)') adata.write_h5ad(filename=robj.replace(\"Robj\",\"h5ad\")) ","date":"2020-04-28","objectID":"/2020-04-28-seurat2scanpy/:5:3","tags":["scRNA-seq","Scanpy","Seurat","Bioinformatics"],"title":"Convert Seurat to Scanpy h5ad","uri":"/2020-04-28-seurat2scanpy/"},{"categories":["Make bioinfo uncool again"],"content":"GATK is design for human genetics, but it also work well for inbred mice. However, one of my colleague who studies mouse genetics, said, I tried the haplotype caller from GATK. But it seems that the haplotype caller is designed for heterogeneous genome like human than for mice. Therefore, the result coming out of HC is worse than samtools, as I manually inspected a few regions that HC calls didn’t make sense. In addition, in one of their mouse genomic paper that we reviewed, they even skipped the second recalibration step. We asked them why and they said it was because of the same reason: good for human but not that good for the homogeneous inbred mouse. With my own experience with GATK4, I found that: SNP: at least 97% of the time, they both have the same call for inbred mice. Indels: GATK is a preferable alogrithm for calling Indels (higher accuary and lower FDR), benefits from a assemble-based caller While BCFtools is as good as GATK for calling SNPs (position-based caller). ","date":"2020-03-10","objectID":"/2020-03-10-gatk4-mm10-bundle/:0:0","tags":["GATK","Genetics","Bioinformatics"],"title":"GATK for inbred mouse","uri":"/2020-03-10-gatk4-mm10-bundle/"},{"categories":["Make bioinfo uncool again"],"content":"GATK resource bundle for inbred mouse. I found a workflow here. However, the script is out of date. Also, see discussion here For GATK4, we have ","date":"2020-03-10","objectID":"/2020-03-10-gatk4-mm10-bundle/:1:0","tags":["GATK","Genetics","Bioinformatics"],"title":"GATK for inbred mouse","uri":"/2020-03-10-gatk4-mm10-bundle/"},{"categories":["Make bioinfo uncool again"],"content":"1. Genome Download from NCBI (mm10) or Sanger Mouse Genetics Programme # NCBI wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/635/GCF_000001635.26_GRCm38.p6/GCF_000001635.26_GRCm38.p6_genomic.fna.gz -O GRCm38_68.fa.gz # or Sanger MGP wget ftp://ftp-mouse.sanger.ac.uk/ref/GRCm38_68.fa -O GRCm38_68.fa ","date":"2020-03-10","objectID":"/2020-03-10-gatk4-mm10-bundle/:1:1","tags":["GATK","Genetics","Bioinformatics"],"title":"GATK for inbred mouse","uri":"/2020-03-10-gatk4-mm10-bundle/"},{"categories":["Make bioinfo uncool again"],"content":"2. dbSNP Depends on your study design. Download All in one vcf file from NCBI wget ftp://ftp.ncbi.nih.gov/snp/organisms/archive/mouse_10090/VCF/00-All.vcf.gz \\ -O mouse.dbsnp.vcf.gz Download from the Sanger Mouse Genetics Programme (Sanger MGP) wget ftp://ftp-mouse.sanger.ac.uk/REL-1505-SNPs_Indels/mgp.v5.merged.snps_all.dbSNP142.vcf.gz ","date":"2020-03-10","objectID":"/2020-03-10-gatk4-mm10-bundle/:1:2","tags":["GATK","Genetics","Bioinformatics"],"title":"GATK for inbred mouse","uri":"/2020-03-10-gatk4-mm10-bundle/"},{"categories":["Make bioinfo uncool again"],"content":"3. Known Indels For mouse indels, the Sanger Mouse Genetics Programme (Sanger MGP) is probably the best resource. Download all MGP indels (5/2015 release): wget ftp://ftp-mouse.sanger.ac.uk/REL-1505-SNPs_Indels/mgp.v5.merged.indels.dbSNP142.normed.vcf.gz \\ -O mgp.v5.indels.vcf.gz Filter for passing variants # take header first zcat mgp.v5.indels.vcf.gz | head -1000 | grep \"^#\" | cut -f 1-8 \\ \u003e mgp.v5.indels.pass.chr.vcf # keep only passing and append zcat mgp.v5.indels.vcf.gz | grep -v \"^#\" | cut -f 1-8 \\ | grep -w \"PASS\" \u003e\u003e mgp.v5.indels.pass.chr.vcf Sort VCF (automatically generated index has to be deleted due to a known bug -\u003e No anymore): gatk SortVcf -SD GRCm38_68.dict -I mgp.v5.indels.pass.chr.vcf -O mgp.v5.indels.pass.chr.sort.vcf # rm .idx # rm mgp.v5.indels.pass.chr.sort.vcf.idx ","date":"2020-03-10","objectID":"/2020-03-10-gatk4-mm10-bundle/:1:3","tags":["GATK","Genetics","Bioinformatics"],"title":"GATK for inbred mouse","uri":"/2020-03-10-gatk4-mm10-bundle/"},{"categories":["Coding"],"content":"Get answers for C/C++ within ? s","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Just some advanced C/C++ code snippets to keep in mind. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:0:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Header naming Never used some header file name with std. Sometimes, compiler could not find the std headers.!!! ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:1:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"FileIO The simplest example #include \u003ciostream\u003e#include \u003cfstream\u003e // output file std::ofstream output; output.open(\"test.compact.txt\"); // read input file string line; std::ifstream input(\"test.chrX.vcf\"); if (input.is_open()) { while (getline(input, line)) output \u003c\u003c line \u003c\u003c'\\n'; } input.close(); output.close(); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:2:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Strings: split and strip split string by delimiter std::vector\u003cstd::string\u003e split(const std::string\u0026 s, char delimiter) { std::vector\u003cstd::string\u003e tokens; std::string token; std::istringstream tokenStream(s); while (std::getline(tokenStream, token, delimiter)) { tokens.push_back(token); } return tokens; } strip strings std::string trim(const std::string\u0026 str, const std::string delimiter = \" \\n\\r\\t\") { // std::string s; // s.erase(s.find_last_not_of(\" \\n\\r\\t\")+1); size_t first = str.find_first_not_of(delimiter); if (std::string::npos == first) { return str; } size_t last = str.find_last_not_of(delimiter); return str.substr(first, (last - first + 1)); } ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:3:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Containor ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:4:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"remove duplicated elements: O(nlogn) sort(nums.begin(),nums.end()); // inplace // unique do not change vector size, only put dup elements to end of containor // and return a iter which points to the first non-uniqdup element vector\u003cint\u003e::iterator iter = unique(nums.begin(), nums.end()); nums.erase(iter, nums.end()); //remove duplciates inplace // nums.resize( std::distance(nums.begin(),iter) ); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:4:1","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Remove elements Vector or Deque: algorithm remove() followed by erase() vector\u003cint\u003e vec = {1,1,2,3,4,4,6}; auto itr = remove(vec.begin(), vec.end(), 4); vec.erase(iter, vec.end()); vec.shrink_to_fit(); // reduce capacity List: member function .remove() Associative Container or Unordered Container: .erase() ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:4:2","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Lambda Syntax auto basicLambda = [] { cout \u003c\u003c \"Hello, world!\" \u003c\u003c endl; }; basicLambda(); // Hello, world! // return type auto add = [](int a, int b) -\u003e int { return a + b; }; // inference return type auto multiply = [](int a, int b) { return a * b; }; Capture parameters int x = 10; auto add_x = [x](int a) { return a + x; }; // copy capture x auto multiply_x = [\u0026x](int a) { return a * x; }; // ref capture x []：默认不捕获任何变量； [=]：默认以值捕获所有变量； [\u0026]：默认以引用捕获所有变量； [ x ]：仅以值捕获x，其它变量不捕获； [\u0026x]：仅以引用捕获x，其它变量不捕获； [=, \u0026x]：默认以值捕获所有变量，但是x是例外，通过引用捕获； [\u0026, x]：默认以引用捕获所有变量，但是x是例外，通过值捕获； [this]：通过引用捕获当前对象（其实是复制指针）； [*this]：通过传值方式捕获当前对象； capture expression // capture by expression int x = 4; auto y = [\u0026r = x, x = x + 1] { r += 2; return x * x; }(); // x = 6，y = 25 // initialize directly auto z = [str = \"string\"]{ return str; }(); // z: const char * generic: auto auto add = [](auto x, auto y) { return x + y; }; int x = add(2, 3); // 5 double y = add(2.5, 3.5); // 6.0 ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:5:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Design Pattern ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:6:0","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Singleton Define class Singleton { private: /* Here will be the instance stored. */ static Singleton* instance; /* Private constructor to prevent instancing. */ Singleton() {}; public: /* Static access method. */ static Singleton* getInstance() { if (instance == 0) instance = new Singleton(); return instance; } }; /* NULL, because instance will be initialized on demand. */ Singleton* Singleton::instance = 0; Usage #include \u003ciostream\u003eint main() { //new Singleton(); // Won't work Singleton* s = Singleton::getInstance(); // Ok Singleton* r = Singleton::getInstance(); /* The addresses will be the same. */ std::cout \u003c\u003c s \u003c\u003c std::endl; std::cout \u003c\u003c r \u003c\u003c std::endl; } ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:6:1","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Delegate Don’t confuse with delegate constructor!!! A delegate is a class that wraps a pointer or reference to an object instance, a member method of that object’s class to be called on that object instance, and provides a method to trigger that call. Example 1 #include \u003ciostream\u003eusing namespace std; class RealPrinter { public: void print() { std::cout \u003c\u003c \"real-printer\" \u003c\u003c std::endl; } }; class Printer { public: Printer() : p(RealPrinter()) {} void print() { p.print(); } private: RealPrinter p; }; int main() { Printer* printer = new Printer(); printer-\u003eprint(); } Example 2: #include \u003ciostream\u003eclass I //interface { public: virtual void f() = 0; virtual void g() = 0; }; class A : public I { public: void f(){std::cout \u003c\u003c \"A::f()\" \u003c\u003c std::endl;} void g(){std::cout \u003c\u003c \"A::g()\" \u003c\u003c std::endl;} }; class B : public I { public: void f(){std::cout \u003c\u003c \"B::f()\" \u003c\u003c std::endl;} void g(){std::cout \u003c\u003c \"B::g()\" \u003c\u003c std::endl;} }; class C : public I { public: C() { m_i = new A();/*delegation*/ } void f(){ m_i-\u003ef(); } void g(){ m_i-\u003eg(); } // normal attributes void toA(){ m_i = new A(); } void toB(){ m_i = new B(); } private: I* m_i; } int main() { C cc = C(); cc.f(); // output: A::f() cc.g(); // output: A::g() cc.toB(); cc.f(); // output: B::f() cc.g(); // output: B::g() } ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:6:2","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Composite Composite is a structural design pattern that allows composing objects into a tree-like structure and work with the it as if it was a singular object. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-stl/:6:3","tags":["C++"],"title":"C++ Notes:  STL","uri":"/2020-02-10-cpp-stl/"},{"categories":["Coding"],"content":"Get answers for C/C++ within ? s","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"C++ Notes Just some C/C++ code snippets to keep in mind. C/C++ is tremendous complicated, but it’s still the most powerful programming language. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:0:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Table of Contents char to Int Pointer Pointer and Smart Pointer Array as Argument Operator that can’t be overloaded Object Instantization Object Relationship Virtual Function and Ploymorphism Friend Const Constexpr Extern and static ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:1:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Char to Int ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:2:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"1. Char sotred as ASCII C store Char as ASCII (Int) by default. So, Char is equal to ASCII code. char a = 'A'; // 65 int c = a; //c = 65 ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:2:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"2. Char to Int, to String, and vice versa char and int char c='5' int res = c -'0' ; // 5 int i=5; char res = I + '0'; // '5' char*,int and string // char * to string const char * str_c = \"hello\"; std::string str = str_c; // string to char* str.c_str(); // return const char* // int to string std::to_string() // string to int std::stoi() ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:2:2","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"3. Char as subscript of array: legal! This is useful when create hashmap. e.g. counting chars int test[200] = {0}; test['A'] = 1; // legal test['b'] = 2; // legal ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:2:3","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Operator Could not be Overloaded operator memo . Member access or dot operator .* Pointer-to-member Operator :: Scope Resolution operator ? : conditional operator, ternary operator sizeof object size operator, built-in operations typeid object type operator, built-in operations OK, What’s .* ? //we have a class struct X { void f() {} void g() {} }; typedef void (X::*pointer)(); //ok, let's take a pointer and assign f to it. pointer somePointer = \u0026X::f; //now I want to call somePointer. But for that, I need an object X x; //now I call the member function on x like this (x.*somePointer)(); //will call x.f() //now, suppose x is not an object but a pointer to object X* px = new X; //I want to call the memfun pointer on px. I use -\u003e* (px -\u003e* somePointer)(); //will call px-\u003ef(); Now, you can’t use x.somePointer(), or px-\u003esomePointer() because there is no such member in class X. see here ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:3:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Pointer Pointer syntax Rule: read from right to left int a; // an int int *a; // a pointer point to int int **a; // secondary int pointer, point to another int pointer int a[10]; // int array int *a[10]; // a poiter array, point to int int (*a)[10]; // a int pointer point to an int array int (*a)(int); // a pointer point to a function, will return an int int (*a[10])(int); // a poiter array, point to a function，will return an int Declare two pointers int* a, b; // equal to int* a; int b; int *a, *b; // correct way ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:4:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Pointer and Smart Pointer #include \u003cmemory\u003e // smart pointer header // [pomter to smart pointer struct Base {}; struct Derived: Base {}; // pointer to smart Base *p1 = new Derived(); // upcast std::shared_ptr\u003cBase\u003e sp(p1); // a polymorphic type Base *p = new Derived(); // upcast, dynamic_cast is unnecessary Derived* dp = dynamic_cast\u003cDerived*\u003e (p); // downcast // smart pointer convert to pointer std::shared_ptr\u003cBase\u003e smart = std::make_shared\u003cDerived\u003e(); Base* p2 = smart.get(); // .get() // smart pointer cast // downcast std::shared_ptr\u003cDerived\u003e dsmart = std::dynamic_pointer_cast\u003cDerived\u003e(smart); // upcast // case 1 std::shared_ptr\u003cBase\u003e foo(new Derived()); // case 2 std::shared_ptr\u003cDerived\u003e bar = std::make_shared\u003cBase\u003e(); std::shared_ptr\u003cBase\u003e foo = std::dynamic_pointer_cast\u003cA\u003e(bar); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:5:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Array ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:6:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Array as formal arguments An Array could not copy to anther Array (Copy pointer is not allowed!), so call-by-value is not allowed. So, use array pointer: //these are same void print(const int*); void print(const int[]); void print(const int[5]); multi-dimension array void print(const int(*p)[3], int rowsize); void print(const int p[][5], int rowsize); When use pointer to an Array, the dimension is unknown. So, need an extra argument to specify it explicitly. Example: void print1(int (*p)[3]) { cout\u003c\u003cp[1][1]\u003c\u003cendl; } void print2(int p[][3]) { cout\u003c\u003cp[0][0]\u003c\u003cendl; } int a[2][3]={ {1,2},{3,4} }; print1(a); // 4 print2(a); // 1 int b[2][4]={ {1,2,5,6},{3,4,7,8} }; print1(b); // error ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:6:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Object Instantization ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:7:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"1. without new stack ClassName object(param); // A a(1); ClassName object2 = ClassName(param); // A b = A(1); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:7:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"2. with new heap ClassName *object = new ClassName(param);//A *a = new A(); delete object; ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:7:2","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"3. copy constructor // ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:7:3","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"4. Smart Pointer std::unique_ptr\u003cClassName\u003e object (new ClassName(param)); // recommend this way of instantization std::unique_ptr\u003cClassName\u003e object = std::make_unique\u003cClassName\u003e(param); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:7:4","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Friend The friend declaration appears in a class body and grants a function or another class access to private and protected members of the class where the friend declaration appears. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:8:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"1. friend function Declare anywhere inside a class, but define outside // function friend \u003ctype\u003e \u003cName\u003e(\u003carguments\u003e); Example: class A { public: A(int _a):a(_a){}; // non-member function friend int getA_a(A \u0026_classA); private: int a; }; // without the friend keyword int getA_a(A \u0026_classA) { //access member by formal arguments return _classA.a; } A _classA(3); std::cout\u003c\u003cgetA_a(_classA); // 3 ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:8:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"2. friend class Delare inside class, define outside // class friend class \u003cName\u003e; Note: friend class X {}; is an error Example: class B { public: B(int _b):b(_b){}; friend class C; // friend class private: int b; }; class C { public: int getB_b(B _classB){ //access member by formal arguments return _classB.b; }; }; B _classB(3); C _classC; // an instance of a friend class _classC.getB_b(_classB); ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:8:2","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"3. Others: friend ostream, friend template … class Y { int data; // the non-member function operator\u003c\u003c will have access to Y's private members friend std::ostream\u0026 operator\u003c\u003c(std::ostream\u0026 out, const Y\u0026 o); friend char* X::foo(int); // members of other classes can be friends too friend X::X(char), X::~X(); // constructors and destructors can be friends }; // this operator\u003c\u003c still needs to be defined, as a non-member std::ostream\u0026 operator\u003c\u003c(std::ostream\u0026 out, const Y\u0026 y) { // can access private member Y::data return out \u003c\u003c y.data; } Back to top ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:8:3","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Object Relationships relation types “is-a” “has-a” “uses-a” “depends-on” Property Composition Aggregation Association Relationship type Whole/part Whole/part Otherwise unrelated Members can belong to multiple classes No Yes Yes Members existence managed by class Yes No No Directionality Unidirectional Unidirectional Unidirectional or bidirectional Relationship verb Part-of Has-a Uses-a ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Composition: has a data member Building complex objects from simpler ones is called object composition . object composition models a “has-a” relationship between two objects. In C++, It means structs and classes can have data members of various types. class A； class B { public: B(){} ~B(){} private: A a; int b; }； Summary: Typically use normal member variables Can use pointer members if the class handles object allocation/deallocation itself Responsible for creation/destruction of parts ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Aggregation: “has a” Unlike a composition, parts can belong to more than one object at a time, and the whole object is not responsible for the existence and lifespan of the parts. Summary: Typically use pointer or reference members that point to or reference objects that live outside the scope of the aggregate class Not responsible for creating/destroying parts ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:2","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Association: “uses a” Association models as “uses-a” relationship. The doctor “uses” the patient (to earn income). The patient uses the doctor (for whatever health purposes they need). ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:3","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Delegate: “has a” or called pImpl(Pointer to IMPLementation) Delegate: Composition by reference has a pointer of another object class A； class B { public: B(){} ~B(){} private: A *a; int b; }； ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:4","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Inheritance: “is a” public, protected, private class A { public: A(){} virtual ~A(){} } class B : public A { }; ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:9:5","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Virtual Functions and Runtime Polymorphism Declare: vitrual keyword class TestA { public: virtual void func() { cout \u003c\u003c \"virtual function\" \u003c\u003c endl; } }; class Test : public TestA { public: virtual void func() { // virtual could be omited cout \u003c\u003c \"Test virtual function\" \u003c\u003c endl; } ~Test() { } }; TestA* t = new Test; // parent pointer point to child (Ploymorphism) t-\u003efunc(); // Results：Test virtual function delete t; Member Could not be virtual inline function constructor non-member function static function: only one copy of all objects. friend function: it’s non-member function member function template ! Pure virtual function declare virtual void fun() = 0; class with pure virtual functoin could not be instantized! a derived class of virtual class has to define pure virtual function. then the derived class could be instantized. abstract class: class with pure virtual function virtual deconstrutor A parent pointer point to it’s child. When delete the parent pointer, only parent constuctor is called. if declared a virtual deconstuctor, child’s deconstuctor is called first, then the parent deconsturctor. virtural keyword could be omited if a parent deconstructor is declared. delete a pointer will only called object’s deconstructor where the pointer point to. see also Pointer and smart pointer cast ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:10:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Const ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:11:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"1. const before or behind type/class, the syntax semantic are same // they are same const int x; // (int x) is const/inmutable int const x; // (const x) has type int ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:11:1","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"2. Pointer with const: const int* p, int const* p and int *const p Dirty trick: use * as a separator, const restrict the type according to the side where it belong to point to const: These two expression are same // -\u003e (const int) | p; p : a mutable pointer points to a const/immutable int const int * p; // -\u003e (int const) | p; p2: a mutable pointer points a const which has type int int const * p2; const pointer: But these two not the same // -\u003e int | (const p); p3: a const pointer, point to an mutable int int * const p3; // -\u003e (const int) | const p; p4: a const pointer, pointing to an immutable/const int const int * const p4; ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:11:2","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"3. class member func with const: () const a. const object could not change class variable could not call non-const function class Number { public: void set(int num) { number = num; } int get() { return number; } int get2() const {return number;} int number = 0; }; // Example const Number n; n.number = 1; // Error, n is const n.set(1); // Error, n is const, non-const `set()` n.get(); // Error, non-const `get()` n.get2(); // OK b. () const could not change class variable, except static could get variable class Number { private: int a; static int b; const int c = 20; public: void set() { a = 10; // error when `this` argument has type 'const' void set2() const { b = 20; // OK } int get() const { // OK return a; // did not change a } }; const Number n; n.set(); // Error n.set2(); // OK n.get(); // OK Easy to understand, when pointer this is const void Number::set(const Number *const this, int num) { number = num; } // illegal -\u003e const this c. () const overloading ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:11:3","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"constexpr The constexpr specifier declares that it is possible to evaluate the value of the function or variable at compile time. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:12:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"default and delete in class special class member: default constructor deconstructor copy constructor operater = when use default and delete default class X { public: X()=default; // with this, you could declare like this: X x; X(int){}; }; X x; // works delete: prohibit func call marked by delete class X { public: X(); X(const X\u0026) = delete; X\u0026 operator = (const X \u0026) = delete; }; // example X x1; X x2=x1; // Error, copy constructor is prohibited ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:13:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"extern, static global variable defined outside all functions and available to all functions. unaffected by scopes and are always available (exists until the program ends) extern declare a global variable (exists on the whole project): variable could be used in multi- .cpp files extern \"C\" {/* c code */}: compile c code. static declare a local global variable (file scope): only be accessed in its translation unit or .o file, that’s, in the file where it is created. declare a static class member (class scope): initialization should be outside class body static data member static function: no this pointer: only access to other static member/function could declare as private ","date":"2020-02-10","objectID":"/2020-02-10-cpp-basics/:14:0","tags":["C++"],"title":"C++ Notes: Basics","uri":"/2020-02-10-cpp-basics/"},{"categories":["Coding"],"content":"Get answers for C/C++ within ? s","date":"2020-02-10","objectID":"/2020-02-10-cpp-pointer/","tags":["C++"],"title":"C++ Notes: Return Pointer or Reference","uri":"/2020-02-10-cpp-pointer/"},{"categories":["Coding"],"content":"Explaination A pointer or reference could not be return if they point/refer to a local variable stored in stack inside a function (local variable stored in stack will be destoried automatically when return, and the pointer become wild) Situations when a function could return pointer or reference variable defined outside a function scope global variable local static variable local variable stored in heap ( new opterator, malloc()) Other process could not access the memory of variable stored in heap until it is released. That’s why. ","date":"2020-02-10","objectID":"/2020-02-10-cpp-pointer/:1:0","tags":["C++"],"title":"C++ Notes: Return Pointer or Reference","uri":"/2020-02-10-cpp-pointer/"},{"categories":["Coding"],"content":"Example #include \u003ciostream\u003e#include \u003cstring.h\u003e#include \u003cstdlib.h\u003e using namespace std; string\u0026 f1(const string \u0026s) { static string result = s; return result; } string \u0026f2(const string \u0026s) { string *p = new string; *p = s; return *p; } int *f3() { int *a = (int *)malloc(sizeof(int) * 10); *a = 10; *(a + 1) = 11; return a; } int \u0026f4() { int *a = (int *)malloc(sizeof(int) * 10); *a = 10; *(a + 1) = 11; return *a; } int main() { int *a = \u0026f7(); cout\u003c\u003c(*(a + 1))\u003c\u003cendl; free(a); // free the memory when done. return 0; } Return *this, or alrealy exist objets // ref A\u0026 A::operator++() { count++; return *this; // already existed object, created outside } ","date":"2020-02-10","objectID":"/2020-02-10-cpp-pointer/:2:0","tags":["C++"],"title":"C++ Notes: Return Pointer or Reference","uri":"/2020-02-10-cpp-pointer/"},{"categories":["Coding"],"content":"What’s the defference between new and malloc() malloc() is a function that takes a number (of bytes) as its argument; it __returns a void*__ pointing to unitialized storage. new is an operator that **takes a type** and (optionally) a set of initializers for that type as its arguments; it **returns a pointer to an** (optionally) initialized **object of its type**. The difference is most obvious when you want to allocate an object of a user-defined type with non-trivial initialization semantics ","date":"2020-02-10","objectID":"/2020-02-10-cpp-pointer/:3:0","tags":["C++"],"title":"C++ Notes: Return Pointer or Reference","uri":"/2020-02-10-cpp-pointer/"},{"categories":["Machine Learning"],"content":"A recipe for interactive computing using custom Jupyter kernels on Stanford's Sherlock.","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"A recipe for interactive computing using custom Jupyter kernels on Stanford’s Sherlock. ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:0:0","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"Setting up custom conda environment on Sherlock’s login node ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:0","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"1. Download and install Miniconda wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh # install bash Miniconda3-latest-Linux-x86_64.sh conda config --set always_yes yes ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:1","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"2. Install jupyter notebook/lab and secure your notebooks with a password # install the default py3 kernel for jupyter notebook conda install ipython jupyter notebook jupyterlab # add password jupyter notebook password ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:2","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"3. (Optional) Add custom conda environment. i.e. fastai conda create -n fastai ipython ipykernel # add the custom to Jupyter notebook conda activate fastai python -m ipykernel install --user --name fastai --display-name FastAI you could also add R, Julia etc kernel. ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:3","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"4. Install pytorch/tensorflow You should select the existed cuda version which installed in Sherlock conda install -c pytorch pytorch torchvision cudatoolkit=10.1 tensorflow conda install tensorflow-gpu cudatoolkit=10.1 ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:4","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"5. Load gpu modules. Select the corresponding cuda version you’ve just installed # this is my version module load cuda/10.1.168 module load cudnn/7.6.4 module load nccl ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:5","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"6. now, open ipython, run import torch print(torch.cuda.is_avilable()) if print out is True, then you’er OK to use GPUs. Follow these steps on your local machine see details here. ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:6","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"7. Download the forward repo git clone https://github.com/vsoch/forward cd forward ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:7","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"8. Generate your parameters bash setup.sh Select Sherlock partition: gpu ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:8","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"9. SSH Credentials bash hosts/sherlock_ssh.sh \u003e\u003e ~/.ssh/config ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:9","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"10. create a sbatch script in forward/sbatches/sherlock and save as jupyter-gpu.sbatch #!/bin/bash PORT=$1 NOTEBOOK_DIR=$2 if [ -z \"$NOTEBOOK_DIR\" ]; then cd $SCRATCH else cd $NOTEBOOK_DIR fi ## to compile libtorch C++ code, load these modules # module load gcc/7.3.0 # module load gdb # module load cmake # export CC=$(which gcc) # export CXX=$(which g++) # select cuda version you need module load cuda/10.1.168 module load cudnn/7.6.4 module load nccl # activate fastai env source activate fastai jupyter lab --no-browser --port=$PORT ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:10","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"11. Start a session The default working directory is $SCRATCH bash start.sh jupyter-gpu change the working directory bash start.sh jupyter /path/to/dir ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:11","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"12. open your browser in local machine and type if your port is 51888, then http://localhost:51888/ here is my jupyter lab computing environment. Have fun! fastai kernel Test GPUs ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:12","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"13. Resume a session bash resume.sh jupyter-gpu # or bash resume.sh jupyter-gpu /path/to/dir ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:13","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Machine Learning"],"content":"14. Stop a session bash end.sh jupyter-gpu # or bash end.sh jupyter-gpu /path/to/dir ","date":"2020-02-10","objectID":"/2020-02-10-ml-sherlock/:1:14","tags":["Jupyter","Sherlock"],"title":"How to do deep learning using custom Jupyter kernels on Sherlock","uri":"/2020-02-10-ml-sherlock/"},{"categories":["Algorithm and data structure"],"content":"Graphs ","date":"2020-02-09","objectID":"/2020-02-09-cs-graph/:0:0","tags":["C++"],"title":"Graph","uri":"/2020-02-09-cs-graph/"},{"categories":["Algorithm and data structure"],"content":"Some data structures to keep in my mind. BinaryHeap: Complete binary tree MaxHeap: Parent \u003e Both Children IndexMaxHeap MinHeap: Parent \u003c Both Children IndexMinHeap Priority queue (MaxHeap) BinarySearchTree Not always complete binary tree Value: leftChild \u003c Parent \u003c rightChild DenseGraph SparseGraph Code snippets are taken from Play with Algorithm ","date":"2020-02-09","objectID":"/2020-02-09-cs-graph/:0:1","tags":["C++"],"title":"Graph","uri":"/2020-02-09-cs-graph/"},{"categories":["Algorithm and data structure"],"content":"1. Dense Graph #include \u003ciostream\u003e#include \u003cvector\u003e#include \u003ccassert\u003e using namespace std; // 稠密图 - 邻接矩阵 class DenseGraph{ private: int n, m; bool directed; vector\u003cvector\u003cbool\u003e\u003e g; public: DenseGraph( int n , bool directed ){ this-\u003en = n; this-\u003em = 0; this-\u003edirected = directed; for( int i = 0 ; i \u003c n ; i ++ ) g.push_back( vector\u003cbool\u003e(n, false) ); } ~DenseGraph(){ } int V(){ return n;} int E(){ return m;} void addEdge( int v , int w ){ assert( v \u003e= 0 \u0026\u0026 v \u003c n ); assert( w \u003e= 0 \u0026\u0026 w \u003c n ); if( hasEdge( v , w ) ) return; g[v][w] = true; if( !directed ) g[w][v] = true; m ++; } bool hasEdge( int v , int w ){ assert( v \u003e= 0 \u0026\u0026 v \u003c n ); assert( w \u003e= 0 \u0026\u0026 w \u003c n ); return g[v][w]; } void show(){ for( int i = 0 ; i \u003c n ; i ++ ){ for( int j = 0 ; j \u003c n ; j ++ ) cout\u003c\u003cg[i][j]\u003c\u003c\"\\t\"; cout\u003c\u003cendl; } } class adjIterator{ private: DenseGraph \u0026G; int v; int index; public: adjIterator(DenseGraph \u0026graph, int v): G(graph){ this-\u003ev = v; this-\u003eindex = -1; } int begin(){ index = -1; return next(); } int next(){ for( index += 1 ; index \u003c G.V() ; index ++ ) if( G.g[v][index] ) return index; return -1; } bool end(){ return index \u003e= G.V(); } }; }; ","date":"2020-02-09","objectID":"/2020-02-09-cs-graph/:0:2","tags":["C++"],"title":"Graph","uri":"/2020-02-09-cs-graph/"},{"categories":["Algorithm and data structure"],"content":"2. Sparse Graph #include \u003ciostream\u003e#include \u003cvector\u003e#include \u003ccassert\u003e using namespace std; // 稀疏图 - 邻接表 class SparseGraph{ private: int n, m; bool directed; vector\u003cvector\u003cint\u003e\u003e g; public: SparseGraph( int n , bool directed ){ this-\u003en = n; this-\u003em = 0; this-\u003edirected = directed; for( int i = 0 ; i \u003c n ; i ++ ) g.push_back( vector\u003cint\u003e() ); } ~SparseGraph(){ } int V(){ return n;} int E(){ return m;} void addEdge( int v, int w ){ assert( v \u003e= 0 \u0026\u0026 v \u003c n ); assert( w \u003e= 0 \u0026\u0026 w \u003c n ); g[v].push_back(w); if( v != w \u0026\u0026 !directed ) g[w].push_back(v); m ++; } bool hasEdge( int v , int w ){ assert( v \u003e= 0 \u0026\u0026 v \u003c n ); assert( w \u003e= 0 \u0026\u0026 w \u003c n ); for( int i = 0 ; i \u003c g[v].size() ; i ++ ) if( g[v][i] == w ) return true; return false; } void show(){ for( int i = 0 ; i \u003c n ; i ++ ){ cout\u003c\u003c\"vertex \"\u003c\u003ci\u003c\u003c\":\\t\"; for( int j = 0 ; j \u003c g[i].size() ; j ++ ) cout\u003c\u003cg[i][j]\u003c\u003c\"\\t\"; cout\u003c\u003cendl; } } class adjIterator{ private: SparseGraph \u0026G; int v; int index; public: adjIterator(SparseGraph \u0026graph, int v): G(graph){ this-\u003ev = v; this-\u003eindex = 0; } int begin(){ index = 0; if( G.g[v].size() ) return G.g[v][index]; return -1; } int next(){ index ++; if( index \u003c G.g[v].size() ) return G.g[v][index]; return -1; } bool end(){ return index \u003e= G.g[v].size(); } }; }; ","date":"2020-02-09","objectID":"/2020-02-09-cs-graph/:0:3","tags":["C++"],"title":"Graph","uri":"/2020-02-09-cs-graph/"},{"categories":["Algorithm and data structure"],"content":"Binary trees Difference ","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:0:0","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"Some data structures to keep in my mind. BinaryHeap: Complete binary tree MaxHeap: Parent \u003e Both Children IndexMaxHeap MinHeap: Parent \u003c Both Children IndexMinHeap Priority queue (MaxHeap) BinarySearchTree Not always complete binary tree Value: leftChild \u003c Parent \u003c rightChild DenseGraph SparseGraph Code snippets are taken from Play with Algorithm ","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:1:0","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"Heap The min-max heap property is: each node at an even level in the tree is less than all of its descendants, while each node at an odd level in the tree is greater than all of its descendants ","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:2:0","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"1. MaxHeap A-Max Heap is a Complete Binary Tree. A-Max heap is typically represented as an array. if the root element index starts from Array[1] Arr[i/2] Returns the parent node. Arr[2*i] Returns the left child node. Arr[2*i+1] Returns the right child node. if the root element index starts from Array[0] Arr[(i-1)/2] Returns the parent node. Arr[2*i + 1] Returns the left child node. Arr[2*i + 2] Returns the right child node. How to construct MaxHeap: store values into an Array find the last node’s parent shiftDown (see code) Example Code: #include \u003ciostream\u003e#include \u003calgorithm\u003e#include \u003cstring\u003e#include \u003cctime\u003e#include \u003ccmath\u003e#include \u003ccassert\u003e using namespace std; template\u003ctypename Item\u003e class MaxHeap { private: Item *data; int count; int capacity; /// helper func: construct max-heap, shift the last item up void shiftUp(int k) { // k: index of the data array Item e = data[k]; // parent: k/2, child: k // if k \u003e=2 ( count \u003e 2 ), then swap while( k \u003e 1 \u0026\u0026 data[k/2] \u003c data[k] ) { // swap( data[k/2], data[k] ); data[k] = data[k/2]; k /= 2; } data[k] = e; } /// helper func: shift the root item down void shiftDown(int k) { Item e = data[k]; while( 2*k \u003c= count ) { int j = 2*k; // which child is larger. left: j, right: j+1 if( j+1 \u003c= count \u0026\u0026 data[j+1] \u003e data[j] ) j ++; // select right child if( data[k] \u003e= data[j] ) break; // swap( data[k] , data[j] ); // swap parent and child data[k] = data[j]; // shift down to child k = j; // data[j] 是 data[2*k]和data[2*k+1]中的最大值 } data[k] = e; } public: MaxHeap(int capacity){ data = new Item[capacity+1]; count = 0; this-\u003ecapacity = capacity; } MaxHeap(Item arr[], int n) { data = new Item[n+1]; capacity = n; // init a new array, store values data[1...] for( int i = 0 ; i \u003c n ; i ++ ) // note: heap index start position 1 data[i+1] = arr[i]; count = n; // construct maxheap for( int i = count/2 ; i \u003e= 1 ; i -- ) // note: heap index start position 1 shiftDown(i); } ~MaxHeap(){ delete[] data; } int size(){ return count; } bool isEmpty(){ return count == 0; } void insert(Item item) { assert( count + 1 \u003c= capacity ); // note: we init count == 0 data[count+1] = item; // append the new item to array. shiftUp(count+1); // the last item count ++; } /// heap sort Item extractMax() { assert( count \u003e 0 ); Item ret = data[1]; // put the max element to last node, then heapify again swap( data[1] , data[count] ); count --; shiftDown(1); // note: update maxheap, start from root node return ret; } Item getMax() { assert( count \u003e 0 ); return data[1]; } }; // 测试最大堆 int main() { MaxHeap\u003cint\u003e maxheap = MaxHeap\u003cint\u003e(100); srand(time(NULL)); int n = 100; // 随机生成n个元素放入最大堆中 // heapify for( int i = 0 ; i \u003c n ; i ++ ){ maxheap.insert( rand()%100 ); } int* arr = new int[n]; // heap sort // 将maxheap中的数据逐渐使用extractMax取出来 // 取出来的顺序应该是按照从大到小的顺序取出来的 for( int i = 0 ; i \u003c n ; i ++ ){ arr[i] = maxheap.extractMax(); cout\u003c\u003carr[i]\u003c\u003c\" \"; } cout\u003c\u003cendl; return 0; } ","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:2:1","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"2. IndexMaxHeap Need 3 vector: data, indexes, reverse Code #include \u003calgorithm\u003e#include \u003ccassert\u003e using namespace std; template\u003ctypename Item\u003e class IndexMaxHeap { private: Item *data; int *indexes; int *reverse; int count; int capacity; void shiftUp( int k ){ while( k \u003e 1 \u0026\u0026 data[indexes[k/2]] \u003c data[indexes[k]] ){ swap( indexes[k/2] , indexes[k] ); reverse[indexes[k/2]] = k/2; reverse[indexes[k]] = k; k /= 2; } } void shiftDown( int k ) { while( 2*k \u003c= count ) { int j = 2*k; if( j + 1 \u003c= count \u0026\u0026 data[indexes[j+1]] \u003e data[indexes[j]] ) j += 1; if( data[indexes[k]] \u003e= data[indexes[j]] ) break; swap( indexes[k] , indexes[j] ); reverse[indexes[k]] = k; reverse[indexes[j]] = j; k = j; } } public: IndexMaxHeap(int capacity){ data = new Item[capacity+1]; indexes = new int[capacity+1]; reverse = new int[capacity+1]; for( int i = 0 ; i \u003c= capacity ; i ++ ) reverse[i] = 0; count = 0; this-\u003ecapacity = capacity; } ~IndexMaxHeap(){ delete[] data; delete[] indexes; delete[] reverse; } int size() { return count; } bool isEmpty() { return count == 0; } // 传入的i对用户而言,是从0索引的 void insert(int i, Item item) { assert( count + 1 \u003c= capacity ); assert( i + 1 \u003e= 1 \u0026\u0026 i + 1 \u003c= capacity ); i += 1; data[i] = item; indexes[count+1] = i; reverse[i] = count+1; count++; shiftUp(count); } Item extractMax() { assert( count \u003e 0 ); Item ret = data[indexes[1]]; swap( indexes[1] , indexes[count] ); reverse[indexes[count]] = 0; reverse[indexes[1]] = 1; count--; shiftDown(1); return ret; } int extractMaxIndex() { assert( count \u003e 0 ); int ret = indexes[1] - 1; swap( indexes[1] , indexes[count] ); reverse[indexes[count]] = 0; reverse[indexes[1]] = 1; count--; shiftDown(1); return ret; } Item getMax(){ assert( count \u003e 0 ); return data[indexes[1]]; } int getMaxIndex(){ assert( count \u003e 0 ); return indexes[1]-1; } bool contain( int i ){ assert( i + 1 \u003e= 1 \u0026\u0026 i + 1 \u003c= capacity ); return reverse[i+1] != 0; } Item getItem( int i ){ assert( contain(i) ); return data[i+1]; } void change( int i , Item newItem ){ assert( contain(i) ); i += 1; data[i] = newItem; // 找到indexes[j] = i, j表示data[i]在堆中的位置 // 之后shiftUp(j), 再shiftDown(j) // for( int j = 1 ; j \u003c= count ; j ++ ) // if( indexes[j] == i ){ // shiftUp(j); // shiftDown(j); // return; // } int j = reverse[i]; shiftUp( j ); shiftDown( j ); } }; ","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:2:2","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"BinarySearchTree All property see the code. preorder inorder postorder BFS DFS Example Code: #include \u003ciostream\u003e#include \u003cqueue\u003e#include \u003ccassert\u003e using namespace std; template \u003ctypename Key, typename Value\u003e class BST{ private: struct Node{ Key key; Value value; Node *left; Node *right; Node(Key key, Value value) { this-\u003ekey = key; this-\u003evalue = value; this-\u003eleft = this-\u003eright = NULL; } Node(Node *node) { this-\u003ekey = node-\u003ekey; this-\u003evalue = node-\u003evalue; this-\u003eleft = node-\u003eleft; this-\u003eright = node-\u003eright; } }; Node *root; int count; public: BST(){ root = NULL; count = 0; } ~BST(){ destroy( root ); } int size() { return count; } bool isEmpty() { return count == 0; } void insert(Key key, Value value) { root = insert(root, key, value); } bool contain(Key key) { return contain(root, key); } Value* search(Key key){ return search( root , key ); } // 前序遍历 void preOrder() { preOrder(root); } // 中序遍历 void inOrder() { inOrder(root); } // 后序遍历 void postOrder() { postOrder(root); } // 层序遍历 void levelOrder() { queue\u003cNode*\u003e q; q.push(root); while( !q.empty() ) { Node *node = q.front(); q.pop(); cout\u003c\u003cnode-\u003ekey\u003c\u003cendl; if( node-\u003eleft ) q.push( node-\u003eleft ); if( node-\u003eright ) q.push( node-\u003eright ); } } // 寻找最小的键值 Key minimum() { assert( count != 0 ); Node* minNode = minimum( root ); return minNode-\u003ekey; } // 寻找最大的键值 Key maximum() { assert( count != 0 ); Node* maxNode = maximum(root); return maxNode-\u003ekey; } // 从二叉树中删除最小值所在节点 void removeMin() { if( root ) root = removeMin( root ); } // 从二叉树中删除最大值所在节点 void removeMax(){ if( root ) root = removeMax( root ); } // 从二叉树中删除键值为key的节点 void remove(Key key) { root = remove(root, key); } private: // 向以node为根的二叉搜索树中,插入节点(key, value) // 返回插入新节点后的二叉搜索树的根 Node* insert(Node *node, Key key, Value value) { if( node == NULL ) { count ++; return new Node(key, value); } if( key == node-\u003ekey ) node-\u003evalue = value; else if( key \u003c node-\u003ekey ) node-\u003eleft = insert( node-\u003eleft , key, value); else // key \u003e node-\u003ekey node-\u003eright = insert( node-\u003eright, key, value); return node; } // 查看以node为根的二叉搜索树中是否包含键值为key的节点 bool contain(Node* node, Key key) { if( node == NULL ) return false; if( key == node-\u003ekey ) return true; else if( key \u003c node-\u003ekey ) return contain( node-\u003eleft , key ); else // key \u003e node-\u003ekey return contain( node-\u003eright , key ); } // 在以node为根的二叉搜索树中查找key所对应的value Value* search(Node* node, Key key) { if( node == NULL ) return NULL; if( key == node-\u003ekey ) return \u0026(node-\u003evalue); else if( key \u003c node-\u003ekey ) return search( node-\u003eleft , key ); else // key \u003e node-\u003ekey return search( node-\u003eright, key ); } // 对以node为根的二叉搜索树进行前序遍历 void preOrder(Node* node) { if( node != NULL ) { cout\u003c\u003cnode-\u003ekey\u003c\u003cendl; preOrder(node-\u003eleft); preOrder(node-\u003eright); } } // 对以node为根的二叉搜索树进行中序遍历 void inOrder(Node* node) { if( node != NULL ) { inOrder(node-\u003eleft); cout\u003c\u003cnode-\u003ekey\u003c\u003cendl; inOrder(node-\u003eright); } } // 对以node为根的二叉搜索树进行后序遍历 void postOrder(Node* node) { if( node != NULL ) { postOrder(node-\u003eleft); postOrder(node-\u003eright); cout\u003c\u003cnode-\u003ekey\u003c\u003cendl; } } void destroy(Node* node) { if( node != NULL ) { destroy( node-\u003eleft ); destroy( node-\u003eright ); delete node; count --; } } // 在以node为根的二叉搜索树中,返回最小键值的节点 Node* minimum(Node* node) { if( node-\u003eleft == NULL ) return node; return minimum(node-\u003eleft); } // 在以node为根的二叉搜索树中,返回最大键值的节点 Node* maximum(Node* node) { if( node-\u003eright == NULL ) return node; return maximum(node-\u003eright); } // 删除掉以node为根的二分搜索树中的最小节点 // 返回删除节点后新的二分搜索树的根 Node* removeMin(Node* node) { if ( node-\u003eleft == NULL ) { Node* rightNode = node-\u003eright; delete node; count --; return rightNode; } node-\u003eleft = removeMin(node-\u003eleft); return node; } // 删除掉以node为根的二分搜索树中的最大节点 // 返回删除节点后新的二分搜索树的根 Node* removeMax(Node* node) { if ( node-\u003eright == NULL ) { Node* leftNode = node-\u003eleft; delete node; count --; return leftNode; } node-\u003eright = removeMax(node-\u003eright); return node; } // 删除掉以node为根的二分搜索树中键值为key的节点 // 返回删除节点后新的二分搜索树的根 Node* remove(Node* node, Key key) { if ( node == NULL ) return NULL; if ( key \u003c node-\u003ekey ){ node-\u003eleft = remove( node-\u003eleft , key )","date":"2020-02-08","objectID":"/2020-02-08-cs-binarytree/:3:0","tags":["C++"],"title":"Binary tree","uri":"/2020-02-08-cs-binarytree/"},{"categories":["Algorithm and data structure"],"content":"Sort algorithms Code snippets are taken from Play with Algorithm ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:0","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"Some algorithm to keep in my mind. selectionSort insertionSort mergeSort quickSort two way three way heapSort ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:1","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"1. insertionSort #include \u003ciostream\u003e#include \u003calgorithm\u003e using namespace std; // 对arr[l...r]范围的数组进行插入排序 template\u003ctypename T\u003e void insertionSort(T arr[], int l, int r){ for( int i = l+1 ; i \u003c= r ; i ++ ) { T e = arr[i]; int j; for (j = i; j \u003e l \u0026\u0026 arr[j-1] \u003e e; j--) arr[j] = arr[j-1]; arr[j] = e; } return; } ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:2","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"2. mergeSort #include \u003ciostream\u003e#include \u003calgorithm\u003e#include \"InsertionSort.h\" using namespace std; template\u003ctypename T\u003e void __merge(T arr[], int l, int mid, int r){ T aux[r-l+1]; for( int i = l ; i \u003c= r; i ++ ) aux[i-l] = arr[i]; int i = l, j = mid+1; for( int k = l ; k \u003c= r; k ++ ){ if( i \u003e mid ) { arr[k] = aux[j-l]; j ++;} else if( j \u003e r ){ arr[k] = aux[i-l]; i ++;} else if( aux[i-l] \u003c aux[j-l] ){ arr[k] = aux[i-l]; i ++;} else { arr[k] = aux[j-l]; j ++;} } } template\u003ctypename T\u003e void __mergeSort(T arr[], int l, int r){ if( r - l \u003c= 15 ){ insertionSort(arr, l, r); return; } int mid = (l+r)/2; __mergeSort(arr, l, mid); __mergeSort(arr, mid+1, r); if( arr[mid] \u003e arr[mid+1] ) __merge(arr, l, mid, r); } template\u003ctypename T\u003e void mergeSort(T arr[], int n){ __mergeSort( arr , 0 , n-1 ); } template \u003ctypename T\u003e void mergeSortBU(T arr[], int n){ for( int i = 0 ; i \u003c n ; i += 16 ) insertionSort(arr,i,min(i+15,n-1)); for( int sz = 16; sz \u003c= n ; sz += sz ) for( int i = 0 ; i \u003c n - sz ; i += sz+sz ) if( arr[i+sz-1] \u003e arr[i+sz] ) __merge(arr, i, i+sz-1, min(i+sz+sz-1,n-1) ); } ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:3","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"3. qucikSort 3 Way QuickSort #include \u003ciostream\u003e#include \u003cctime\u003e#include \u003calgorithm\u003e#include \"InsertionSort.h\" using namespace std; template \u003ctypename T\u003e int _partition(T arr[], int l, int r){ // select a rand index in arr, and swap swap( arr[l] , arr[rand()%(r-l+1)+l] ); T v = arr[l]; int i = l+1, j = r; while( true ){ while( i \u003c= r \u0026\u0026 arr[i] \u003c v ) i ++; while( j \u003e= l+1 \u0026\u0026 arr[j] \u003e v ) j --; if( i \u003e j ) break; swap( arr[i] , arr[j] ); i ++; j --; } swap( arr[l] , arr[j]); return j; } template \u003ctypename T\u003e void _quickSort(T arr[], int l, int r){ if( r - l \u003c= 15 ){ insertionSort(arr,l,r); return; } int p = _partition(arr, l, r); _quickSort(arr, l, p-1 ); _quickSort(arr, p+1, r); } template \u003ctypename T\u003e void quickSort(T arr[], int n){ srand(time(NULL)); _quickSort(arr, 0, n-1); } template \u003ctypename T\u003e void __quickSort3Ways(T arr[], int l, int r){ if( r - l \u003c= 15 ){ insertionSort(arr,l,r); return; } swap( arr[l], arr[rand()%(r-l+1)+l ] ); T v = arr[l]; int lt = l; // arr[l+1...lt] \u003c v int gt = r + 1; // arr[gt...r] \u003e v int i = l+1; // arr[lt+1...i) == v while( i \u003c gt ){ if( arr[i] \u003c v ){ swap( arr[i], arr[lt+1]); i ++; lt ++; } else if( arr[i] \u003e v ){ swap( arr[i], arr[gt-1]); gt --; } else{ // arr[i] == v i ++; } } swap( arr[l] , arr[lt] ); __quickSort3Ways(arr, l, lt-1); __quickSort3Ways(arr, gt, r); } template \u003ctypename T\u003e void quickSort3Ways(T arr[], int n){ srand(time(NULL)); __quickSort3Ways( arr, 0, n-1); } ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:4","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"4. heapSort #include \"Heap.h\"using namespace std; template\u003ctypename T\u003e void heapSort1(T arr[], int n){ MaxHeap\u003cT\u003e maxheap = MaxHeap\u003cT\u003e(n); for( int i = 0 ; i \u003c n ; i ++ ) maxheap.insert(arr[i]); // heapify for( int i = n-1 ; i \u003e= 0 ; i-- ) arr[i] = maxheap.extractMax(); // get root node value } ","date":"2020-02-08","objectID":"/2020-02-08-cs-sort/:0:5","tags":["C++"],"title":"Sort","uri":"/2020-02-08-cs-sort/"},{"categories":["Algorithm and data structure"],"content":"What on earth is Big O? Time complexity and space complexity ","date":"2020-02-01","objectID":"/2020-02-01-cs-algo/:0:1","tags":["C++"],"title":"What is Big O","uri":"/2020-02-01-cs-algo/"},{"categories":["Algorithm and data structure"],"content":"Time complexity O(f(n)): number of commands need to execute. proportional to f(n). 表示运行算法所需要执行的指令数，和f(n)成正。 严格来讲，O(f(n))表示算法执行的上界。业界默认为算法执行的最低上界(最坏情况）。 n represents the data scale 数据规模 when n is a large number, the constant is usually ignored. algorithm n of cmd Binary reserach $O(logn)$ $a*logn$ Max/min in an array $O(n)$ b*n merge sort $O(nlogn)$ $c*nlogn$ select sort $O(n^2)$ $d*n^2$ quick sort $O(nlogn)$ e*nlogn adjacent graph $O(V+E)$ Lazy Prim $O(ElogE)$ Prim $O(ElogV)$ Kruskal $O(ElogE)$ Dijkstra $O(ElogV)$ Bellman-Ford $O(EV)$ minimum span tree Shortest path tree (Single source shortest path) ","date":"2020-02-01","objectID":"/2020-02-01-cs-algo/:0:2","tags":["C++"],"title":"What is Big O","uri":"/2020-02-01-cs-algo/"},{"categories":["Algorithm and data structure"],"content":"Space complexity cmd complexity new an array $O(n)$ new 2d array $O(n^2)$ new an constant space $O(1)$ recursive function: the depth (n) of a recursive function, the extra space need $O(n)$. ","date":"2020-02-01","objectID":"/2020-02-01-cs-algo/:0:3","tags":["C++"],"title":"What is Big O","uri":"/2020-02-01-cs-algo/"},{"categories":["Algorithm and data structure"],"content":"Make sense of n If you want to solve the problem in 1 second, then an algorithm of complexity cmds n $O(n^2)$ could exec cmd n = $10^4$ $O(n)$ could exec cmd n = $10^8$ $O(nlogn)$ could exec cmd n = $10^7$ ","date":"2020-02-01","objectID":"/2020-02-01-cs-algo/:0:4","tags":["C++"],"title":"What is Big O","uri":"/2020-02-01-cs-algo/"},{"categories":["Algorithm and data structure"],"content":"Example binarySearch find from n element find from $n/2$ element find from $n/4$ element ... find from 1 That’s, need how many steps of search when n = 1? $log_{2}n = O(logn)$. int2string. Set num \u003e 0 string int2string(int num) { string s=\"\"; while(num) { s += '0' + num%10; num /= 10; } reverse(s); // O(n) return s; } That is, how many “/10” steps when num = 0? $log_{10}n = O(logn)$. Case: two nested for loop, not always $O(n^2)$ void hello(int n){ for (int sz =1; sz \u003c n; sz ++ sz) // logn here for( int i=1; i \u003c n;; i++) //n cout\u003c\u003c\"hello, complex\" \u003c\u003cendl; } So, should be $O(nlogn)$ isPrime: $O(\\sqrt{n})$ // set n \u003e 1 bool isPrime(int n){ for( int x =2; x*x \u003c= n; x++){ if( n%x == 0) return false; return true; } } recursive function single recursive function call int binarySearch(int arr[], int l, int r, int target) { if (l\u003er) return -1; int mid = l +(r-l)/2; if (arr[mid] == target) return mid; else if (arr[mid] \u003e target) return binarySearch(arr, ;, mid-1, target); else return binarySearch(arr, mid+1, r, target); } each step need O(1), so overall complexity depend on recursive exec depth. That is, if each function call needs time T, then time complexity: O(T*depth) -\u003e O(n). Another example: recursion depth logn, them time complexity O(logn). double pow( double x, int n){ assert(n \u003e=0); if (n==0) return 1.0; double t = pow(x, n/2); if( n%2) return x*t*t; return t*t; } multi recursive exec how many exec step? int f(int n) { assert(n \u003e=0); if(n == 0) return 1; return f(n-1) + f(n); } that’s, count how many nodes on a full binary tree. $2^{n+1} -1 = O(2^n)$ how to think about this? void mergeSort(int arr[]. int l. int r){ if (l \u003e=r) return; int mid = (l+r) /2; mergeSort(arr, l, mid); mergeSort(arr, mid+1, r); merge(arr, l, mid, r); } For binary tree, complexity for each level O(n), while tree depth O(logn). Overall, O(nlogn) Amortized time i.e. dynamic vector/stack/deque template\u003cT\u003e class MyVector{ private: T* data; int capacity; int size; //O(n) void resize(int newCapacity){ assert(newCapacity \u003e= size); T* newData = new T[newCapacity]; for(int i = 0; i \u003c size; i++ ){ newData[i] = data[i]; } delete[] data; data = newData; capacity = newCapacity; } public: MyVector() { data = new T[10]; capacity = 10; size = 0; } ~MyVector() { delete[] data; } // Average: O(1) void push_back(T e){ //assert(size \u003c capacity) if (size == capacity) resize (2 *capacity); data[size++] = e; } // Average O(1) T pop_back(){ assert (size \u003e0); T ret = data[size-1]; size --; // note the denominator here. To advoid ossilation of space complexity if(size == capacity / 4) resize(capacity /2); return ret; } }; ","date":"2020-02-01","objectID":"/2020-02-01-cs-algo/:0:5","tags":["C++"],"title":"What is Big O","uri":"/2020-02-01-cs-algo/"},{"categories":["Machine Learning"],"content":"A breif review over the foundations of statistical inference ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:0:0","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"Statistical Models and Inference statistical inference: a formal approach to characterizing a random phenomenon using observations, either by providing a description of a past phenomenon or by giving some predictions about future phenomenon of similar nature. ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:1:0","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"1. Statistical Models The first step in statistical inference is to specify a statistical model, under some simplifying assumptions (i.e. independence assumptions). Hierarchical models: the probability distribution of one parameter is dependent on the values of other hierachical paramters (i.e. conditional independent). Steps: Set assumptions (i.e. independent), parameter and model. Make explicit assumptions on the probability distributions. focus on parametric modeling, because of limited data nonparametric not consider here, used for hypothesis testing or when sample size is very large. Once the model is specified, then choose a method of inference, as well as an algorithm to obtain estimates. Most commonly use: Maximum likelihood inference Bayesian inference ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:1:1","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"2. Maximum likelihood inference Quantifying confidence: the Fisher Information Matrix Newton’s algorithm Approximate Techniques Monte Carlo Sampling for intractable likelihoods Composite likelihood ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:1:2","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"3. Bayesian Inference A statistical model describes the uncertainty about how the data was produced. The ultimate aim for statistical inference is to obtain information about the unknown parameter $\\theta$ given the data $\\mathcal{D}$. Frequentist: $\\theta$ is fixed but unknown quantity. Bayesian: use a fully probabilistic model and treat $\\theta$ as a random quantity. To do so, chose an appropriate prior distribution $\\mathbb{P}(\\theta)$, which reflects the knowledge (i.e. uncertainty) about $\\theta$ prior to the experiment the goal is to update the knowledge given the information contained in the data $\\mathcal{D}$. the updated knowledge (i.e. reduced uncertainty) is encapsulated in the posterior distribution $\\mathbb{P}(\\theta \\vert \\mathcal{D})$, which is calculated via Bayes’theorem. $$ \\mathbb{P}(\\boldsymbol{\\theta} | \\mathcal{D})=\\frac{\\mathbb{P}(\\mathcal{D} | \\boldsymbol{\\theta}) \\mathbb{P}(\\boldsymbol{\\theta})}{\\mathbb{P}(\\mathcal{D})} $$ The bayesian paradigm boils down to the slogan: posterior $\\propto$ likelihood $\\times$ prior 3.1 Choice of prior distributions Conjugate priors the prior and the posterior lie in the same class of distributions. often chosen, because it leads to a well-known form of the posterior, which simplifies the calculations choose a prior that contains as little information about the parameter as possible at first choice would, of course, be a locally uniform prior. Under a uniform prior we have $\\mathbb{P}(\\boldsymbol{\\theta} \\vert \\boldsymbol{D}) \\propto \\mathcal{L}(\\boldsymbol{\\theta})$. Jeffrey’s prior, but often hard to come by 3.2 Bayesian point estimates and confidence intervals Bayesian point estimates: the posterior mean, mode and median $$ \\hat{\\theta}=\\mathbb{E}[\\theta | D]=\\int \\theta \\mathbb{P}(\\theta | \\mathcal{D}) \\mathrm{d} \\theta $$ confidence: highest posterior density (HPD) region for a threshold value $\\pi$, the region $\\mathcal{C}_{\\alpha}={\\theta: \\mathbb{P}(\\theta \\vert \\mathcal{D})\u003e\\pi}$, we get $$ \\int_{C_{\\alpha}} \\mathbb{P}(\\theta | \\mathcal{D}) \\mathrm{d} \\theta=1-\\alpha $$ This region $\\mathcal{C}_{\\alpha}$ is the HPD region. 3.3 Markov Chain Monte Carlo A common challenge in Bayesian inference is that the integral $$ \\mathbb{P}(D)=\\int \\mathbb{P}(D | \\theta) \\mathbb{P}(\\theta) d_{\\theta} $$ can’t be solved analytically. to be continued… 3.4 Empirical Bayes for Latent Variable Problems The first step is to infer point estimates for the parameters at higher levels by integrating out those at lower levels, and the infer posterior distributions for lower level parameters while setting those at a higher level to their point estimate. 3.5 Approximate Bayesian Computation Approximate Bayesian computation (ABC) is a class of simulation-based techniques to conduct Bayesian inference under models with intractable likelihoods 3.6 Model selection how to compare the several candidate models explaining the data $\\mathcal{D}$? the most commonly used methods: likelihood ratio statistic model posterior probabilities Bayes factors others: cross-validation, Akaike’s information criterion (AIC), Bayesian information criterion (BIC) ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:1:3","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"4. Naive Bayes and Bayesian estimation Naive Bayes and Bayesian estimation are two different concepts! Naive Bayes is a statistical learning method. For a give training set, learn the join probability distribution of $P(X,Y)$. Based on this model, for a given input $x$, output a $y$ with maximal posterior probability (Bayes theorem). Set prior prob distribution: $$ P\\left(Y=c_{k}\\right), \\quad k=1,2, \\cdots, K $$ Conditional prob distribution: $$ P\\left(X=x | Y=c_{k}\\right)=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right), \\quad k=1,2, \\cdots, K $$ Naive Bayes make a strong assumption that conditional prob distribution are all conditional independent, which is: $$ \\begin{aligned} P\\left(X=x | Y=c_{k}\\right) \u0026=P\\left(X^{(1)}=x^{(1)}, \\cdots, X^{(n)}=x^{(n)} | Y=c_{k}\\right) \\cr \u0026=\\prod_{j=1}^{n} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) \\end{aligned} $$ then, posterior prob is: $$ P\\left(Y=c_{k} | X=x\\right)=\\frac{P\\left(X=x | Y=c_{k}\\right) P\\left(Y=c_{k}\\right)}{\\sum_{k} P\\left(X=x | Y=c_{k}\\right) P\\left(Y=c_{k}\\right)} $$ If conditional probability of each input variable is not independent, then model become Baysian Network! Naive Bayes Classifier is: $$ y=f(x)=\\arg \\max_{c_{k}} \\frac{P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right) }{\\sum_{k} P\\left(Y=c_{k}\\right) \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)} $$ and it’s short form: $$ y=f(x)= \\arg \\max_{c_{k}} \\overbrace{P\\left(Y=c_{k}\\right)}^{\\text{prior}} \\overbrace{ \\prod_{j} P\\left(X^{(j)}=x^{(j)} | Y=c_{k}\\right)}^{\\text{likelihood}} $$ In sentiment analysis of NLP, the naive bayes classifiter make two assumptions. bag of words assumption: position doesn’t matter. Each feature only encode word identity not position. naive bayes assumption: conditional independence. ","date":"2020-01-30","objectID":"/2020-01-30-ml-bayes/:1:4","tags":["Naive Bayes","Bayesian Inference"],"title":"Statistical Modeling and Inference","uri":"/2020-01-30-ml-bayes/"},{"categories":["Machine Learning"],"content":"Multi-label classification, tasks commonly be seen on health record data (multi symptoms). Loss function design: Multi binary cross-entropy each class has a binary output Label smoothing, another regularization technique It’s designed to make the model a little bit less certain of it’s decision by changing a little bit its target: instead of wanting to predict 1 for the correct class and 0 for all the others, we ask it to predict 1-ε for the correct class and ε for all the others, with ε a (small) positive number and N the number of classes. This can be written as: $$ \\text {loss}=(1-\\varepsilon) c e(i)+\\varepsilon \\sum c e(j) / N $$ where ce(x) is cross-entropy of x (i.e. −log(px)), and i is the correct class. finally, for multi-label loss function: $$ (1-\\epsilon) \\sum_{i}\\left(-\\frac{\\log p_{i}}{n}\\right)+\\frac{\\epsilon}{N} \\sum\\left(-\\log p_{i}\\right) $$ See the fastai implementation here: LabelSmoothingCrossEntropy about line 285: class LabelSmoothingCrossEntropy(Module): y_int = True def __init__(self, eps:float=0.1, reduction='mean'): self.eps,self.reduction = eps,reduction def forward(self, output, target): c = output.size()[-1] log_preds = F.log_softmax(output, dim=-1) if self.reduction=='sum': loss = -log_preds.sum() else: loss = -log_preds.sum(dim=-1) if self.reduction=='mean': loss = loss.mean() return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target.long(), reduction=self.reduction) def activation(self, out): return F.softmax(out, dim=-1) def decodes(self, out): return out.argmax(dim=-1) ","date":"2020-01-29","objectID":"/2020-01-29-ml-lossfunc/:0:0","tags":["Pytorch"],"title":"Loss function for multi-label classification","uri":"/2020-01-29-ml-lossfunc/"},{"categories":["Machine Learning"],"content":"Just some basic notations ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:0:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Derivative $$ f^{\\prime} (x) = \\frac {df(x)} {dx} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:1:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Gradient Generalize the derivative to the multivariate functions. The first order derivative of a multivariate functions. $$ \\nabla f=\\left[\\frac{\\partial f\\left(x_{1}, x_{2}, x_{3}\\right)}{\\partial x_{1}}, \\frac{\\partial f\\left(x_{1}, x_{2}, x_{3}\\right)}{\\partial x_{2}}, \\frac{\\partial f\\left(x_{1}, x_{2}, x_{3}\\right)}{\\partial x_{3}}\\right] $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:2:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Jacobian a generalization of the derivate operator to the vector-valued functions $$ J=\\left(\\begin{array}{cccc} \\frac{\\partial f_{1}}{\\partial x_{1}} \u0026 \\frac{\\partial f_{1}}{\\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial f_{1}}{\\partial x_{n}} \\cr \\frac{\\partial f_{2}}{\\partial x_{1}} \u0026 \\frac{\\partial f_{2}}{\\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial f_{2}}{\\partial x_{n}} \\cr \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\cr \\frac{\\partial f_{m}}{\\partial x_{1}} \u0026 \\frac{\\partial f_{m}}{\\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial f_{m}}{\\partial x_{n}} \\end{array}\\right) $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:3:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Hessian the second order derivative of a multivariate function $$ H=\\left(\\begin{array}{cccc} \\frac{\\partial^{2} f}{\\partial x_{1}^{2}} \u0026 \\frac{\\partial^{2} f}{\\partial x_{1} \\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial^{2} f}{\\partial x_{1} \\partial x_{n}} \\cr \\frac{\\partial^{2} f}{\\partial x_{2} \\partial x_{1}} \u0026 \\frac{\\partial^{2} f}{\\partial x_{2}^{2}} \u0026 \\cdots \u0026 \\frac{\\partial^{2} f}{\\partial x_{2} \\partial x_{n}} \\cr \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\cr \\frac{\\partial^{2} f}{\\partial x_{n} \\partial x_{1}} \u0026 \\frac{\\partial^{2} f}{\\partial x_{n} \\partial x_{2}} \u0026 \\cdots \u0026 \\frac{\\partial^{2} f}{\\partial x_{n}^{2}} \\end{array}\\right) $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:4:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Laplacian The trace of the Hessian matrix is known as the Laplacian operator denoted by $\\nabla^2$: $$ \\nabla^2 f = \\operatorname{trace}(H) = \\frac{\\partial^{2} f}{\\partial x_{1}^{2}}+\\frac{\\partial^{2} f}{\\partial x_{2}^{2}}+\\cdots+\\frac{\\partial^{2} f}{\\partial x_{n}^{2}} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:5:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Laplace’s equation The second order partial differential equation In rectangular coordinates, $$ \\nabla^{2} f=\\frac{\\partial^{2} f}{\\partial x^{2}}+\\frac{\\partial^{2} f}{\\partial y^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}=0 $$ In cylindrical coordinates, $$ \\nabla^{2} f=\\frac{1}{r} \\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2}} \\frac{\\partial^{2} f}{\\partial \\phi^{2}}+\\frac{\\partial^{2} f}{\\partial z^{2}}=0 $$ In spherical coordinates, using the $(r, \\theta, \\varphi)$ convention, $$ \\nabla^{2} f=\\frac{1}{r^{2}} \\frac{\\partial}{\\partial r}\\left(r^{2} \\frac{\\partial f}{\\partial r}\\right)+\\frac{1}{r^{2} \\sin \\theta} \\frac{\\partial}{\\partial \\theta}\\left(\\sin \\theta \\frac{\\partial f}{\\partial \\theta}\\right)+\\frac{1}{r^{2} \\sin ^{2} \\theta} \\frac{\\partial^{2} f}{\\partial \\varphi^{2}}=0 $$ More generally, in curvilinear coordinates, $$ \\nabla^{2} f=\\frac{\\partial}{\\partial \\xi^{j}}\\left(\\frac{\\partial f}{\\partial \\xi^{k}} g^{k j}\\right)+\\frac{\\partial f}{\\partial \\xi^{j}} g^{j m} \\Gamma_{m n}^{n}=0 $$ or $$ \\nabla^{2} f=\\frac{1}{\\sqrt{|g|}} \\frac{\\partial}{\\partial \\xi^{i}}\\left(\\sqrt{|g|} g^{i j} \\frac{\\partial f}{\\partial \\xi^{j}}\\right)=0, \\quad\\left(g=\\operatorname{det}\\left{g_{i j}\\right}\\right) $$ Laplace’s equation ","date":"2020-01-26","objectID":"/2020-01-26-ml-gradient/:6:0","tags":["Statistical Learning"],"title":"Derivative, Gradient, Jacobian, Hessian, Laplacian","uri":"/2020-01-26-ml-gradient/"},{"categories":["Machine Learning"],"content":"Maximum Likelihood Estimation Gaussian Mixture Model Expectation Maximization ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:0:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"1. Probability and likelihood likehood \u0026 maximum likehood 在非正式场合似然（likelihood）和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。 概率: 在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性。 比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的； 似然: 刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数）。 假设随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上，那么两面朝上的概率均为50%。运用出现的结果来判断这个事情本身的性质（参数），也就是似然。 当结果和参数相互对应，似然和概率在数值上相等。 用 θ 表示环境对应的参数，x 表示结果，那么概率可以表示为： $$P(x | \\theta )$$ $p(x \\vert θ)$ 是条件概率的表示方法。θ 是前置条件，理解为在 θ 的前提下，事件 x 发生的概率，相对应的似然可以表示为: $$\\mathcal{L}(\\theta | x)$$ 可以理解为已知结果为 x ，参数为 θ (似然函数里 θ 是变量，这里说的参数和变量是相对与概率而言的)对应的概率，即： $$\\mathcal{L}(\\theta | x)=P(x | \\theta)$$ 两者在数值上相等，但是意义并不相同, $\\mathcal{L}$ 是关于 θ 的函数，而 P 则是关于 x 的函数。 ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:1:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"2. Maximum Likelihood Estimation 单高斯模型 $x \\sim \\mathcal{N}(\\mu, \\Sigma)$, $x_{i} \\in \\mathcal{D}$, 那么对参数 $\\mu$和 $\\Sigma$ 进行估计，只需要最大化log-likelihood函数： $$ \\begin{aligned} \\log p(X) \u0026=\\sum_{i=1}^{N} \\log \\mathcal{N}\\left(x_{i} | \\mu, \\Sigma\\right) \\cr \u0026=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma} e^{-\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}} \\cr \u0026=\\sum_{i=1}^{N} \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}+\\sum_{i=1}^{N}-\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}} \\cr \u0026=-\\frac{N}{2} \\log 2 \\pi-\\frac{N}{2} \\log \\sigma^{2}-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)^{2} \\end{aligned} $$ 求偏导数，得到参数估计： $$ \\begin{aligned} \\frac{\\partial \\log p(X)}{\\partial \\mu} \u0026=\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)=0 \\cr \u0026 \\Rightarrow \\mu=\\frac{1}{N} \\sum_{i=1}^{N} x_{i} \\cr \\frac{\\partial \\log p(X)}{\\partial \\sigma^{2}} \u0026=-\\frac{N}{2 \\sigma^{2}}+\\frac{1}{2 \\sigma^{4}} \\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)^{2}=0 \\cr \u0026 \\Rightarrow \\sigma^{2}=\\frac{1}{N} \\sum_{i=1}^{N}\\left(x_{i}-\\mu\\right)^{2} \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:2:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"3. Gaussian Mixture Model 如果有K个高斯线性叠加: $$ \\begin{aligned} p(x)=\u0026 \\sum_{k=1}^{K} \\pi_{k} \\mathcal{N}\\left(x | \\mu_{k}, \\Sigma_{k}\\right) \\cr \u0026 \\text { s.t. } \\sum_{k=1}^{K} \\pi_{k}=1 \\cr \u0026 0 \\leq \\pi_{k} \\leq 1 \\end{aligned} $$ 那么对数似然函数为 $$ \\log p(X)=\\sum_{i=1}^{N} \\log \\lbrace \\sum_{k=1}^{K} \\pi_{k} \\mathcal{N} (x_{i} | \\mu_{k}, \\Sigma_{k}) \\rbrace $$ 因为对数里有求和，因此无法无法直接通过最大似然估计方法进行参数估计。 其中，如果$\\pi_{k}$是每个高斯出现的概率$p(k)$，则高斯混合模型分解为以$p(k)$获得一个高斯分布，然后在分布中获得$x$，因此$x$边缘概率分布为： $$ p(x)=\\sum_{k=1}^{K} p(k) p(x | k) $$ 后验概率$p(k\\vert x)$表示$x$属于每个高斯的概率（离散值）: $$ \\begin{aligned} p(k | x) \u0026=\\frac{p(x | k) p(k)}{\\sum_{l} p(x | l) p(l)} \\cr \u0026=\\frac{\\pi_{k} \\mathcal{N}\\left(x | \\mu_{k}, \\Sigma_{k}\\right)}{\\sum_{l} \\pi_{l} \\mathcal{N}\\left(x | \\mu_{l}, \\Sigma_{l}\\right)} \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:3:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"4. Expectation Maximization 思想： 通过引入隐变量，运用迭代方法，求解混合高斯模型 $$ \\theta^{(t+1)}=\\underset{\\theta}{\\arg \\max } \\mathcal{L}(\\theta ; X) $$ 引入隐变量Zi(状态i）， z服从多项分布，选择zi的概率为p(zi),则高斯混合模型为： $$ \\begin{aligned} z_{i} \u0026 \\sim \\operatorname{Multinoimal}\\left(\\pi_{1}, \\cdots, \\pi_{k}\\right) \\cr x_{i} | z_{i} \u0026 \\sim \\mathcal{N}\\left(\\mu_{z_{i}}, \\Sigma_{z_{i}}\\right) \\end{aligned} $$ 步骤： E-Step: 在现有$\\theta^{(t)}$下最大化似然下界, 计算隐变量$z$的期望$Q\\left(z_{i}\\right)=p\\left(z_{i} \\vert x_{i}, \\theta\\right)$ 作为其下界 M-Step: 在上面$Q(z_{i})$下计算参数列表$\\theta$来最大化似然 ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:4:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(0) 理解EM的前提 凹凸函数: $\\forall_{x \\in \\mathbb{R}}, f^{\\prime \\prime}(x) \\geq 0$,则$f$为凸函数。 当$x$为向量，如果其hessian矩阵 $H$ 是半正定的($H \\geq 0$),则$f$为凸函数 如果$f^{\\prime \\prime}(x)\u003e0$或者$H\u003e0$, $f$是严格凸函数。 如果$f^{\\prime \\prime}(x)\u003c0$或者$H\u003e0$, $f$是凹函数。 Jensen 不等式: 如果$f$为凸函数, 则$E[f(X)] \\geq f(E [ X ])$。当且仅当$x$是常数时，$E[f(x)]=f(E[ x ])$。 如果$f$是凹函数, 则$E[f(X)] \\leq f(E[ X ])$。 引入隐变量后，变换对数似然函数: $$ \\begin{aligned} \\mathcal{L}(\\theta ; X) \u0026=\\sum_{i=1}^{N} \\log p\\left(x_{i} | \\theta\\right) \\cr \u0026=\\sum_{i=1}^{N} \\log \\sum_{z_{i}} p\\left(x_{i}, z_{i} | \\theta\\right) \\cr \u0026=\\sum_{i=1}^{N} \\log \\sum_{z_{i}} Q\\left(z_{i}\\right) \\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{Q\\left(z_{i}\\right)} \\cr \u0026 \\geq \\sum_{i=1}^{N} \\sum_{z_{i}} Q\\left(z_{i}\\right) \\log \\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{Q\\left(z_{i}\\right)} \\end{aligned} $$ 推导: 把式中的log函数体看成是一个整体，由于$\\log (x)$的二阶导数为$-\\frac{1}{x^2}$, 小于0，为凹函数。所以使用Jensen不等式时，应用第二条准则：$f(E [ X ] ) \\geq E[f(x)]$。 $$ f\\left(E_{z_{i} \\sim Q}\\left[\\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{Q\\left(z_{i}\\right)}\\right]\\right) \\geq E_{z_{i} \\sim Q}\\left[f\\left(\\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{Q\\left(z_{i}\\right)}\\right)\\right] $$ 这里，$Q\\left(z_{i}\\right)$是$z_{i}$的函数， 且$\\sum_{z_{i}} Q\\left(z_{i}\\right)=1$。 由数学期望$E_{x \\sim p}[g(X)]=\\sum_{x} g(x) p(x)$，上式可以理解为: $p(x)$对应$Q\\left(z_{i}\\right)$, g(x)对应$\\log \\frac{p\\left(x_{i}, z_{i} \\vert \\theta\\right)}{Q\\left(z_{i}\\right)}$表示$z_{i}$的函数。 似然函数: $\\mathcal{L}(\\theta) \\geq \\mathcal{J}(z,Q)$（$z$为隐含变量），那么我们可以通过不断的最大化$\\mathcal{J}$的下界，来使得$\\mathcal{L}(\\theta)$不断提高，最终达到它的最大值。 最大化$\\mathcal{L}(\\theta)$函数的下界，即让$g(x)$为常数c: $$ \\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{Q\\left(z_{i}\\right)}=c $$ Jensen不等式中说到，当自变量$X=E(X)$时，即为常数的时候，等式成立! 变换公式, 对所有$z$求和得: $$ \\begin{aligned} p\\left(x_{i}, z_{i} | \\theta\\right) \u0026=c \\cdot Q\\left(z_{i}\\right) \\cr \\sum_{z_{i}} p\\left(x_{i}, z_{i} | \\theta\\right) \u0026=c \\cdot \\sum_{z_{i}} Q\\left(z_{i}\\right) \\cr c \u0026=\\sum_{z_{i}} p\\left(x_{i}, z_{i} | \\theta\\right) \\end{aligned} $$ 其中，$\\sum_{z_{i}} Q\\left(z_{i}\\right) = 1$, 也得： $$ \\begin{aligned} Q\\left(z_{i}\\right) \u0026=\\frac{p\\left(x_{i}, z_{i} | \\theta\\right)}{\\sum_{z_{i}} p\\left(x_{i}, z_{i} | \\theta\\right)} \\cr \u0026=p\\left(z_{i} | x_{i}, \\theta\\right) \\end{aligned} $$ 至此，我们推出了在固定参数θ后，使下界拉升的$Q(z)$的计算公式就是后验概率（条件概率），一并解决了$Q(z)$如何选择的问题。此步就是EM算法的E-step。 执行E-Step后与下界重合，此时似然变为： $$ \\mathcal{L}\\left(\\theta^{(t)} ; X\\right)=\\sum_{i=1}^{N} \\sum_{z_{i}} Q^{(t)}\\left(z_{i}\\right) \\log \\frac{p\\left(x_{i}, z_{i} | \\theta^{(t)}\\right)}{Q^{(t)}\\left(z_{i}\\right)} $$ 这时，对公式求导 $$ \\theta^{(t+1)}=\\underset{\\theta}{\\arg \\max } \\mathcal{L}(\\theta ; X) $$ 得到 $t+1$ 步的似然函数 $\\mathcal{L}\\left(\\theta^{(t+1)} ; X\\right)$。 通过不断的迭代，可以得到使似然函数$\\mathcal{L}(\\theta)$最大化的参数 $\\theta$，直至函数收敛。 只需要证明$\\mathcal{L}\\left(\\theta^{(t+1)} ; X\\right) \\geq \\mathcal{L}\\left(\\theta^{(t)} ; X\\right)$, 则可证明EM的收敛性: $$ \\begin{aligned} \\mathcal{L}\\left(\\theta^{(t+1)} ; X\\right) \u0026=\\sum_{i=1}^{N} \\log \\sum_{z_{i}} Q^{(t)}\\left(z_{i}\\right) \\frac{p\\left(x_{i}, z_{i} | \\theta^{(t+1)}\\right)}{Q^{(t)}\\left(z_{i}\\right)} \\cr \u0026 \\geq \\sum_{i=1}^{N} \\sum_{z_{i}} Q^{(t)}\\left(z_{i}\\right) \\log \\frac{p\\left(x_{i}, z_{i} | \\theta^{(t+1)}\\right)}{Q^{(t)}\\left(z_{i}\\right)} \\cr \u0026 \\geq \\sum_{i=1}^{N} \\sum_{z_{i}} Q^{(t)}\\left(z_{i}\\right) \\log \\frac{p\\left(x_{i}, z_{i} | \\theta^{(t)}\\right)}{Q^{(t)}\\left(z_{i}\\right)} \\cr \u0026=\\mathcal{L}\\left(\\theta^{(t)} ; X\\right) \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:4:1","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"5. 求解GMM ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(1) GMM E-Step: 已知$\\theta^{(t)}$, 求$Q^{(t+1)}\\left(z_{i}\\right)$: $$ \\begin{aligned} Q^{(t+1)}\\left(z_{i}\\right) \u0026=\\frac{p\\left(x_{i}, z_{i} | \\theta^{(t)}\\right)}{p\\left(x_{i} | \\theta^{(t)}\\right)} \\cr \u0026=\\frac{p\\left(x_{i}, z_{i} | \\theta^{(t)}\\right)}{\\sum_{l \\in z_{i}} p\\left(x_{i}, l | \\theta^{(t)}\\right)} \\cr \u0026=\\frac{p\\left(x_{i} | z_{i}, \\theta^{(t)}\\right) p\\left(z_{i} | \\theta^{(t)}\\right)}{\\sum_{l \\in z_{i}} p\\left(x_{i} | l, \\theta^{(t)}\\right) p\\left(l | \\theta^{(t)}\\right)} \\cr \u0026=\\frac{\\mathcal{N}\\left(\\mu_{z_{i}}, \\Sigma_{z_{i}}\\right) \\pi_{z_{i}}}{\\sum_{l \\in z_{i}} \\mathcal{N}\\left(\\mu_{l}, \\Sigma_{l}\\right) \\pi_{l}} \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:1","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(2) GMM M-Step: 已知$Q^{(t+1)}\\left(z_{i}\\right)$, 求 $\\theta^{(t+1)}$: $$ \\begin{aligned} \\mathcal{L}(\\theta ; X) \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\frac{p\\left(x_{i}, l | \\theta\\right)}{Q_{i}(l)} \\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log p\\left(x_{i}, l | \\theta\\right)-\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log Q_{i}(l) \\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log p\\left(x_{i}, l | \\theta\\right)-\\text {Constant } \\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\pi_{l} \\mathcal{N}\\left(\\mu_{l}, \\Sigma_{l}\\right)-\\text {Constant } \\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\pi_{l}+\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\mathcal{N}\\left(\\mu_{l}, \\Sigma_{l}\\right)-\\text {Constant} \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:2","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(3) 求 $\\pi$: 令 $\\forall_{l \\in{1, \\cdots, K}}$ $$ \\begin{aligned} \\frac{\\partial \\mathcal{L}(\\theta ; X)}{\\partial \\pi_{l}} \u0026=0 \\cr \\text { s.t. } \\sum_{l}^{K} \\pi_{l} \u0026= 1 \\end{aligned} $$ 拉格朗日乘法约束 $$ \\begin{cases}\\begin{aligned} L_{\\pi_{l}} \u0026=\\frac{\\partial \\mathcal{L}(\\theta ; X)}{\\partial \\pi_{l}}+\\lambda(\\sum_{l}^{K} \\pi_{l}-1)=0 \\cr L_{\\lambda} \u0026=\\sum_{l}^{K} \\pi_{l}-1=0 \\end{aligned}\\end{cases} $$ 求导： $$ \\begin{cases}\\begin{array}{c} \\frac{1}{\\pi_{1}} \\sum_{i}^{N} Q_{i}(1)-\\lambda=0 \\cr \\vdots \\cr \\frac{1}{\\pi_{l}} \\sum_{i}^{N} Q_{i}(l)-\\lambda=0 \\end{array}\\end{cases} $$ 相加得： $$ \\sum_{l}^{K} \\sum_{i}^{N} Q_{i}(l)=\\lambda \\sum_{l}^{K} \\pi_{l}=\\lambda $$ 由 $Q_{i}(l)=p\\left(l \\vert x_{i}, \\theta\\right)$, 得 $$ \\begin{aligned} \\sum_{l}^{K} \\sum_{i}^{N} Q_{i}(l) \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} p\\left(l | x_{i}, \\theta\\right) \\cr \u0026=\\sum_{i}^{N} 1 \\cr \u0026=N \\end{aligned} $$ 则 $$ \\begin{aligned} \\pi_{l} \u0026=\\frac{1}{\\lambda} \\sum_{i}^{N} Q_{i}(l) \\cr \u0026=\\frac{1}{N} \\sum_{i}^{N} Q_{i}(l) \\cr \u0026=\\frac{1}{N} \\sum_{i}^{N} p\\left(l | x_{i}, \\theta\\right) \\end{aligned} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:3","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(4) 计算$\\mu$ $$ \\begin{aligned} \u0026\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\mathcal{N}\\left(\\mu_{l}, \\Sigma_{l}\\right)\\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma_{l}} e^{-\\frac{\\left(x_{i}-\\mu_{l}\\right)^{2}}{2 \\sigma_{l}^{2}}}\\cr \u0026=\\sum_{i}^{N} \\sum_{l}^{K} Q_{i}(l) \\lbrace -\\frac{1}{2} \\log 2 \\pi-\\frac{1}{2} \\log \\sigma_{l}^{2}-\\frac{\\left(x_{i}-\\mu_{l}\\right)^{2}}{2 \\sigma_{l}^{2}}\\rbrace \\end{aligned} $$ 求偏导： $$ \\begin{aligned} \\frac{\\partial \\mathcal{L}(\\theta ; X)}{\\partial \\mu_{l}} \u0026=\\sum_{i}^{N} Q_{i}(l) \\frac{x_{i}-\\mu_{l}}{\\sigma^{2}} \\cr \u0026=0 \\end{aligned} $$ 得$\\mu$： $$ \\mu_{l}=\\frac{\\sum_{i}^{N} Q_{i}(l) x_{i}}{\\sum_{i}^{N} Q_{i}(l)} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:4","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"(5) 计算$\\sigma$ $$ \\begin{aligned} \\frac{\\partial \\mathcal{L}(\\theta ; X)}{\\partial \\sigma_{l}^{2}} \u0026=\\sum_{i}^{N} Q_{i}(l) \\bigg\\lbrace -\\frac{1}{2 \\sigma_{l}^{2}}+\\frac{\\left(x_{i}-\\mu_{l}\\right)^{2}}{2 \\sigma_{l}^{4}} \\bigg\\rbrace \\cr \u0026=0 \\end{aligned} $$ 得到 $$ \\sigma_{l}=\\frac{\\sum_{i}^{N} Q_{i}(l)\\left(x_{i}-\\mu_{l}\\right)^{2}}{\\sum_{i}^{N} Q_{i}(l)} $$ ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:5:5","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Machine Learning"],"content":"6 从KL散度角度解释EM $$ \\begin{aligned} K L(q | p) \u0026=\\sum_{z} q(z) \\log \\frac{q(z)}{p(z | x, \\theta)} \\cr \u0026=\\sum_{z} q(z) \\log \\frac{q(z) p(x | \\theta)}{p(z, x | \\theta)} \\cr \u0026=-\\sum_{z} q(z) \\log \\frac{p(z, x | \\theta)}{q(z)}+\\sum_{z} q(z) \\log p(x | \\theta) \\cr \u0026=-\\sum_{z} q(z) \\log \\frac{p(z, x | \\theta)}{q(z)}+\\log p(x | \\theta) \\sum_{z} q(z) \\cr \u0026=-\\sum_{z} q(z) \\log \\frac{p(z, x | \\theta)}{q(z)}+\\log p(x | \\theta) \\cr \\log p(x | \\theta) \u0026=K L(q | p)+\\sum_{z} q(z) \\log \\frac{p(z, x | \\theta)}{q(z)} \\cr \u0026=K L(q | p)+\\mathcal{L}(q, \\theta) \\end{aligned} $$ 参考： 徐亦达-机器学习-EM ","date":"2020-01-26","objectID":"/2020-01-26-ml-em/:6:0","tags":["Expectation Maximization","Statistical Learning"],"title":"Expectation Maximization","uri":"/2020-01-26-ml-em/"},{"categories":["Make bioinfo uncool again"],"content":"Usefull tools","date":"2020-01-20","objectID":"/2020-01-20-begin/","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"usefull tools for linux command line ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:0","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"a. Make terminal cool, install OhMyZsh # install zsh sudo apt-get install zsh # ubuntu # change default shell to zsh chsh -s /usr/bin/zsh # install ohmyzsh sh -c \"$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" source ~/.zshrc ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:1","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"b. Terminal keyboard short cuts Jump to head: Ctrl + a Jump to end: Ctrl + e Delete strings ahead: Ctrl + u Delete strings follow: Ctrl + k ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:2","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"c. Program keeps running in the background 1. Run cmd using nohup nohup command [options] \u0026 2. Run cmd using Tmux Outside Tmux: Typically these are run outside, but you can also run them inside an existing session a. Start New Session tmux new -s myname b. Attach To Existing Session tmux attach -t myname #by name tmux attach 4 #by number (in this case 4) c. List Sessions tmux ls d. Kill Session tmux kill-session -t myname Inside Tmux Session: Start each command with CTRL + b, release, then press one of the following: Panes % vertical split \" horizontal split d detach from session (it keeps running in the background) x kill pane Up/Down/Left/Right move between panes PageUP/PageDown CTRL+c to exit the PageUp/Down mode Fn+Up/Down PageUp/Down: Mac keyboard : + resize-pane -D Resizes the current pane down : + resize-pane -U Resizes the current pane upward : + resize-pane -L Resizes the current pane left : + resize-pane -R Resizes the current pane right : + resize-pane -D 20 Resizes the current pane down by 20 cells ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:3","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"d. File compression and decompression Decompression File type Cmd e.g. *.tar tar -xvf *.tar.gz or *.tgz tar -xvzf *bz2 bzip2 -d or bunzip2 *.tar.bz2 tar -xjf *.Z uncompress *.tar.Z tar -xZf *.rar unrar e or rar x unrar e file.rar *.zip unzip *.gz gunzip Compression File type Cmd e.g. *.tar tar -cvf *.tar.gz or *.tgz tar -cvzf *bz2 bzip2 -z *.tar.bz2 tar -cjf *.Z compress *.tar.Z tar -cZf *.rar rar a rar a -ep1 newname /home/user/cpp *.zip zip *.gz gzip For rar installation sudo apt-get install rar ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:4","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"e. Handy tricks for handling filepath very useful to strip file sufix, path et.al. # e.g. var=./home/fastq/filename_R1.fq.gz # extract filename ${var#*/} # -\u003e home/fastq/filename_R1.fq.gz var1=${var##*/} # -\u003e filename_R1.fq.gz # remove file suffix ${var1%.*} # -\u003e filename_R1.fq ${var1%%.*} # -\u003e filename_R1 # get basebame var2=$(basename \"${var}\" .fq.gz) #-\u003e filename_R1 ","date":"2020-01-20","objectID":"/2020-01-20-begin/:0:5","tags":["Bioinformatics","Linux"],"title":"Cheatsheet for command line","uri":"/2020-01-20-begin/"},{"categories":["Make bioinfo uncool again"],"content":"hisat2-htseq-deseq2","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"hisat2-htseq-deseq2 ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:0:0","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"3.1 transcriptom mapping step 0: install tools conda install htseq hisat2 stringtie step 1: build index and extract splice sites build index hisat2-build -p {threads} genome/hg38.fa hisat2_index/hg38 extract known splice sites for alignmnet hisat2_extract_splice_sites.py gencode.gtf \u003e hisat2_index/splicesites.txt hisat2_extract_exons.py gencode.gtf \u003e histat2_index/exon.txt step2: mapping hisat2 --dta --threads ${threads} \\ -x hisat2_index/hg38 \\ --known-splicesite-infile hisat2_index/splicesites.txt \\ -1 R1.fq.gz \\ -2 R2.fq.gz \\ -S output.sam step 3: sam to bam samtools view -Sbh -q 25 \\ -@ ${threads} \\ -o ouput.bam \\ input.sam step 4: bam sort and index samtools sort -@ ${threads} input.bam \u003e output.sorted.bam samtools index input.sorted.bam #generate input.sorted.bam.bai step 5: bam to bigwig bamCoverage -p ${threads} \\ --normalizeUsing RPKM \\ # note: other normalization options -b input.sorted.bam \\ -o output.bw ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:0:1","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"3.2 Differentially expressed genes analysis step 1: count reads htseq-count -r pos -s no \\ --additional-attr gene_name \\ --additional-attr gene_type \\ -f bam input.sorted.bam gencode.gtf \u003e output.count step2: differentially expressed genes analysis (1) construct read count table option 1: HTSeq count file input library(\"DESeq2\") directory \u003c- \"/path/to/your/readCountFiles/\" sampleFiles \u003c- grep(\"count\", list.files(directory), value=TRUE) condition \u003c- factor(c(\"KO\",\"KO\", \"WT\",\"WT\"), levels = c(\"WT\", \"KO\")) # phenotable sampleTable \u003c- data.frame(sampleName = sampleFiles, fileName = sampleFiles, condition = condition) # construct read count table ddsHTSeq \u003c- DESeqDataSetFromHTSeqCount(sampleTable = sampleTable, directory = directory, design= ~ condition) option 2: combined read count file into a single table first, then run library(DESeq2) # read count table database \u003c- read.table(file = \"raw.counts.csv\", sep = \",\", header = TRUE, row.names = 1) database \u003c- round(as.matrix(database)) # set level condition \u003c- factor(c(\"KO\",\"KO\", \"WT\",\"WT\"), levels = c(\"WT\", \"KO\")) # build DESeq object coldata \u003c- data.frame(row.names = colnames(database), condition) dds \u003c- DESeqDataSetFromMatrix(countData=database, colData=coldata, design=~condition + treatmement) (2) run DESeq2 and get output library(DESeq2) dds \u003c- dds[ rowSums(counts(dds)) \u003e 1, ] # run statistical test dds \u003c- DESeq(dds) # get results res \u003c- results(dds) # summary(res) count_r \u003c- counts(dds, normalized=T) #normalized count matrix # export results res \u003c- res[order(res$padj),] diff_gene \u003c- subset(res, padj \u003c 0.05 \u0026 (log2FoldChange \u003e 1 | log2FoldChange \u003c -1)) diff_gene \u003c- row.names(diff_gene) resdata \u003c- merge(as.data.frame(res), as.data.frame(counts(dds, normalized=TRUE)), by=\"row.names\", sort=FALSE) write.csv(resdata, file = \"DEGs.csv\", row.names = FALSE) 3.3 Gene set enrichrment analysis GO clusterprofiler Enrichr (GSEApy) GSEA ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:0:2","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"3.4 Alternative splicing analysis ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:0:3","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"Other ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:1:0","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"GTF to bed one liner zcat gencode.vM28.annotation.gtf.gz | awk 'OFS=\"\\t\" {if ($3==\"gene\") {print $1,$4-1,$5,$14,$10,$7}}' | tr -d '\";' \u003e mm39.gene.bed ","date":"2020-01-20","objectID":"/2020-01-20-rnaseq/:1:1","tags":["RNA-seq","Bioinformatics"],"title":"Shortcut to bulk RNA-seq analysis","uri":"/2020-01-20-rnaseq/"},{"categories":["Make bioinfo uncool again"],"content":"bowtie2-macs2-deeptools","date":"2020-01-20","objectID":"/2020-01-20-chip/","tags":["ChIP-seq","Bioinformatics"],"title":"Shortcut to ChIP-seq analysis","uri":"/2020-01-20-chip/"},{"categories":["Make bioinfo uncool again"],"content":"bowtie2-macs2-deeptools ","date":"2020-01-20","objectID":"/2020-01-20-chip/:0:0","tags":["ChIP-seq","Bioinformatics"],"title":"Shortcut to ChIP-seq analysis","uri":"/2020-01-20-chip/"},{"categories":["Make bioinfo uncool again"],"content":"2.1 Genome mapping Step 0: install software # install miniconda, then call conda conda install -c bioconda bowtie2 hisat2 samtools deeptools step 1: build index bowtie2-build hg38.fa bowtie2_index/hg38 step 2: mapping Unpaired data bowtie2 -p ${threads} -x index/hg38 \\ -U input.fastq.gz \\ -S ouput.sam Paired data bowtie2 -p 4 -x index/hg38 \\ -1 input_R1.fastq.gz \\ -2 input_R2.fastq.gz \\ -S ouput.sam step 3: sam to bam samtools view -Sbh -q 25 \\ -@ ${threads} \\ -o ouput.bam \\ input.sam step 4: bam sort and index samtools sort -@ ${threads} input.bam \u003e output.sorted.bam samtools index input.sorted.bam #generate input.sorted.bam.bai step 5: bam to bigwig bamCoverage -p ${threads} \\ --normalizeUsing RPKM \\ # note: other normalization options --centerReads \\ -e 200 \\ -b input.sorted.bam \\ -o output.bw ","date":"2020-01-20","objectID":"/2020-01-20-chip/:0:1","tags":["ChIP-seq","Bioinformatics"],"title":"Shortcut to ChIP-seq analysis","uri":"/2020-01-20-chip/"},{"categories":["Make bioinfo uncool again"],"content":"2.2 Peaks analysis note:: macs2 (\u003ev2.2.x) supports python 3. step 0: install tools conda install macs2 bedtools pygenometracks step 1: callpeaks (1) narrow peaks, e.g. TFs, h3k4m3 # bam file input macs2 callpeak -t ChIP.elute.sorted.bam \\ -c ChIP.input.sorted.bam \\ -f BAM \\ -g hs # organism \\ -B -q 0.05 \\ -n ${outFileName}\\ --outdir macs_out (2) Broad peaks, e.g. h3k27me3 # sam file also works fine macs2 callpeak -t ./bowtie_out/WTme2ChIP.sam \\ -c ./bowtie_out/ESCInput.sam \\ -f SAM \\ -g mm \\ -B --SPMR \\ --nomodel --extsize 147 \\ --broad -n WTme2ChIP --outdir macs_out step 2: advanced analysis tools: bedtools, deeptools, pyGenomeTracks, igv genome algebra overlap with other peaks: bedtools visualization heatmap: deeptools signal tracks: pyGenomeTracks, igv ","date":"2020-01-20","objectID":"/2020-01-20-chip/:0:2","tags":["ChIP-seq","Bioinformatics"],"title":"Shortcut to ChIP-seq analysis","uri":"/2020-01-20-chip/"},{"categories":["Make bioinfo uncool again"],"content":"salmon-tximport-deseq2","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"salmon-tximport-deseq2 ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:0","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"Step 0: install salmon and download transcriptome cdna from gencode conda install salmon wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_32/gencode.v32.transcripts.fa.gz ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:1","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"Step 1. build salmon index salmon index -p 8 --gencode -t gencode.v32.transcripts.fa.gz -i salmonIndex_hg38 ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:2","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"Step 2: quantification salmon quant -i salmonIndex_hg38 -l A \\ -1 ${fn}/${samp}_1.fastq.gz \\ -2 ${fn}/${samp}_2.fastq.gz \\ -p 8 --validateMappings -o quants/${samp}_quant ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:3","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"Step 3: merge quantification outputs use tximport in R # R code library(tximport) library(readr) suppressMessages(library('EnsDb.Hsapiens.v86')) txdb \u003c- EnsDb.Hsapiens.v86 k \u003c- keys(txdb, keytype = \"GENEID\") df \u003c- select(txdb, keys = k, keytype = \"GENEID\", columns = c(\"TXID\",\"GENEID\")) tx2gene \u003c- df[, 2:1] # tx ID, then gene ID #tx2gene \u003c- read.table(tx2gene, header= T, sep=\"\\t\", stringsAsFactors = F) samples \u003c- unlist(strsplit(sample_ids,\",\")) salmon.files \u003c- file.path('salmon',samples, \"quant.sf\") names(salmon.files) \u003c- samples all(file.exists(salmon.files)) # get transcript level results txi.transcripts \u003c- tximport(salmon.files, type = \"salmon\", txOut = TRUE, tx2gene = tx2gene,) # ignoreTxVersion = TRUE) # get gene level results txi.salmon \u003c- summarizeToGene(txi.transcripts, tx2gene) #save raw counts salmon.counts\u003c- txi.salmon$counts salmon.counts\u003c- as.data.frame(salmon.counts) write.table(salmon.counts, out_counts, sep=\"\\t\", quote=F) #save gene tpms salmon.TPM\u003c- txi.salmon$abundance salmon.TPM\u003c- as.data.frame(salmon.TPM) write.table(salmon.TPM, out_tpm, sep=\"\\t\", quote=F) #save transcripts tpms salmon.trans.TPM\u003c- txi.transcripts$abundance salmon.trans.TPM\u003c- as.data.frame(salmon.trans.TPM) write.table(salmon.trans.TPM, outTrans_tpm, sep=\"\\t\", quote=F) save(txi.salmon, file=\"txi.salmon.RData\") ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:4","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":["Make bioinfo uncool again"],"content":"Step 4: Differentially expressed gene analysis DESeq2 pipeline demo load(\"txi.salmon.RData\") dds \u003c- DESeqDataSetFromTximport(txi.salmon, sampleTable, ~condition) dds$condition \u003c- relevel(dds$condition, ref=ctrl) dds \u003c- DESeq(dds, parallel=TRUE) res \u003c- results(dds, contrast=c(\"condition\", treat, ctrl)) resOrdered \u003c- res[order(res$padj),] resOrdered = as.data.frame(resOrdered) write.table(resOrdered, file=\"degs.txt\", quote=F, sep=\"\\t\") ","date":"2020-01-20","objectID":"/2020-01-23-rnaseqturbo/:0:5","tags":["RNA-seq","Bioinformatics"],"title":"SuperFast RNA-seq","uri":"/2020-01-23-rnaseqturbo/"},{"categories":null,"content":"My PhD thesis","date":"2019-12-10","objectID":"/publication/2019-12-10-sox21/","tags":null,"title":"SOX21 Ensures Rostral Forebrain Identity by Suppression of WNT8B during Neural Regionalization of Human Embryonic Stem Cells","uri":"/publication/2019-12-10-sox21/"},{"categories":null,"content":"My PhD thesis. Published in Stem Cell Reports, 2019 Highlights The transcriptomic analysis of rostrocaudal patterning of hESC-derived NPCs SOX21 KO leads to caudalized regional identity in rostral forebrain progenitors SOX21 represses Wnt signaling to ensure the rostral forebrain identity WNT8B is a major downstream target of SOX21 Download here ","date":"2019-12-10","objectID":"/publication/2019-12-10-sox21/:0:0","tags":null,"title":"SOX21 Ensures Rostral Forebrain Identity by Suppression of WNT8B during Neural Regionalization of Human Embryonic Stem Cells","uri":"/publication/2019-12-10-sox21/"},{"categories":null,"content":"Ding J, Fang Z, Liu X, Zhu Z, Wen C, Wang H, et al. CDK11 safeguards the identity of human embryonic stem cells via fine-tuning signaling pathways. J Cell Physiol. 2019 Download here ","date":"2019-10-15","objectID":"/publication/2019-10-15/:0:0","tags":null,"title":"CDK11 safeguards the identity of human embryonic stem cells via fine‐tuning signaling pathways","uri":"/publication/2019-10-15/"},{"categories":null,"content":"Liu X, Fang Z, Wen J, Tang F, Liao B, Jing N, Lai D, Jin Y. SOX1 Is Required for the Specification of Rostral Hindbrain Neural Progenitor Cells from Human Embryonic Stem Cells. iScience. 2020 Aug 20;23(9):101475. doi: 10.1016/j.isci.2020.101475. Epub ahead of print. PMID: 32905879; PMCID: PMC7486433. ","date":"2019-08-20","objectID":"/publication/2020-08-26/:0:0","tags":null,"title":"SOX1 Is Required for the Specification of Rostral Hindbrain Neural Progenitor Cells from Human Embryonic Stem Cells","uri":"/publication/2020-08-26/"},{"categories":null,"content":"Hu J, Li S, Sun X, Fang Z, Wang L, Xiao F, et al. Stk40 deletion elevates c-JUN protein level and impairs mesoderm differentiation. J Biol Chem. 2019;294(25):9959-72. Download here ","date":"2019-06-25","objectID":"/publication/2019-06-21/:0:0","tags":null,"title":"Stk40 deletion elevates c-JUN protein level and impairs mesoderm differentiation","uri":"/publication/2019-06-21/"},{"categories":null,"content":"Xu Y, Luo X, Fang Z, Zheng X, Zeng Y, Zhu C, et al. Transcription coactivator Cited1 acts as an inducer of trophoblast-like state from mouse embryonic stem cells through the activation of BMP signaling. Cell Death Dis. 2018;9(9):924. Download here ","date":"2018-09-11","objectID":"/publication/2018-09-11/:0:0","tags":null,"title":"Transcription coactivator Cited1 acts as an inducer of trophoblast-like state from mouse embryonic stem cells through the activation of BMP signaling","uri":"/publication/2018-09-11/"},{"categories":null,"content":"I’m honored to be one of the contributors. It is definitely worthy. Thanks for the Bioconda team, so we could install bioinformatic tools so easy! The open source Bioconda project is a milestone in computational biology. It saves lots of time when trying to install bioinfo tools. Download here ","date":"2018-07-02","objectID":"/publication/2018-07-02/:0:0","tags":null,"title":"Bioconda: sustainable and comprehensive software distribution for the life sciences","uri":"/publication/2018-07-02/"},{"categories":null,"content":"Single cell analysis of mouse E5.5, E6.5 embryos. In this work, I dissected the embryos and prepared the single cell cDNA libraries.","date":"2017-06-09","objectID":"/publication/2016-06-09/","tags":null,"title":"Single-cell analysis reveals lineage segregation in early post-implantation mouse embryos","uri":"/publication/2016-06-09/"},{"categories":null,"content":"Wen J, Zeng Y, Fang Z, Gu J, Ge L, et al. Single-cell analysis reveals lineage segregation in early post-implantation mouse embryos. The Journal of biological chemistry 2017;292:9840-54 Download here ","date":"2017-06-09","objectID":"/publication/2016-06-09/:0:0","tags":null,"title":"Single-cell analysis reveals lineage segregation in early post-implantation mouse embryos","uri":"/publication/2016-06-09/"},{"categories":null,"content":"Wang L, Yu H, Cheng H, He K, Fang Z, et al. Deletion of Stk40 impairs definitive erythropoiesis in the mouse fetal liver. Cell Death Dis. 2017;8:e2722 Download here ","date":"2017-03-30","objectID":"/publication/2017-03-30/:0:0","tags":null,"title":"Deletion of Stk40 impairs definitive erythropoiesis in the mouse fetal liver","uri":"/publication/2017-03-30/"},{"categories":null,"content":"Liao B, Zhong XM, Xu HM, Xiao F, Fang ZQ, et al. Itch, an E3 ligase of Oct4, is required for embryonic stem cell self-renewal and pluripotency induction. Journal of Cellular Physiology 2013;228:1443-51 Download here ","date":"2012-12-18","objectID":"/publication/2012-12-18/:0:0","tags":null,"title":"Itch, an E3 ligase of Oct4, is required for embryonic stem cell self-renewal and pluripotency induction","uri":"/publication/2012-12-18/"},{"categories":null,"content":"See github link GNNHap ","date":"0001-01-01","objectID":"/portfolio/protfolio-5/:0:0","tags":null,"title":"GNNHap: Graph neural network for Haplotype Prioritization","uri":"/portfolio/protfolio-5/"},{"categories":null,"content":"I would like to use pandas to explore my data, but I did not find a convenient tool to do gene set enrichment analysis in python. I want something like this: Ability to run inside python console without switching to R. User friendly for both wet and dry lab users. Produce or reproduce publishable figures. Perform batch jobs easy. Command line support (Win, Mac, Linux). That’s why GSEApy comes to play. See code here ","date":"0001-01-01","objectID":"/portfolio/portfolio-1/:0:0","tags":null,"title":"GSEApy","uri":"/portfolio/portfolio-1/"},{"categories":null,"content":"See github link haplomap ","date":"0001-01-01","objectID":"/portfolio/portfolio-4/:0:0","tags":null,"title":"Haplomap: Haplotype-based computational genetic mapping","uri":"/portfolio/portfolio-4/"},{"categories":null,"content":"My bioinformatic workflows using snakemake. I would update it if only I have more time. Why snakemake? Good: Community Easy to use and update Reusable workflows Scalable Support conda env Support slurm, qsub … python syntax Drawback: Hard to debug workflows. TODO: Integrate snakemake-wrappers to current workflows to make it more reproducible. See code here ","date":"0001-01-01","objectID":"/portfolio/portfolio-3/:0:0","tags":null,"title":"Snakeflow","uri":"/portfolio/portfolio-3/"},{"categories":null,"content":"My journey to object detection began with YOLOv3. I think it’s really a good starting point for someone like me without computer vison background to understand what’s going on behind the scence. While learning object detection, I made a simple modified C++ version (with LibTorch) based on others’ work 1 2 3. See code here ","date":"0001-01-01","objectID":"/portfolio/portfolio-2/:0:0","tags":null,"title":"YOLOv3 Inference Framework in C++","uri":"/portfolio/portfolio-2/"},{"categories":null,"content":"Performance test code: yolov3 models/yolov3.cfg models/yolov3.weights images Results: tested with CPU: Core i9 Windows MAC: average time (682 ms/image). tested with GPU: Tesla V100 Linux: average time (22 ms/image). ","date":"0001-01-01","objectID":"/portfolio/portfolio-2/:1:0","tags":null,"title":"YOLOv3 Inference Framework in C++","uri":"/portfolio/portfolio-2/"},{"categories":null,"content":"Features Supports NMS Soft NMS Weighted NMS ","date":"0001-01-01","objectID":"/portfolio/portfolio-2/:2:0","tags":null,"title":"YOLOv3 Inference Framework in C++","uri":"/portfolio/portfolio-2/"},{"categories":null,"content":"TODO Support training … ","date":"0001-01-01","objectID":"/portfolio/portfolio-2/:3:0","tags":null,"title":"YOLOv3 Inference Framework in C++","uri":"/portfolio/portfolio-2/"},{"categories":null,"content":"Credits YOLOv3_CPP repo is created based on the implementations below: weixu000. ↩︎ PyTorch-YOLOv3. ↩︎ YOLO_v3_tutorial_from_scratch. ↩︎ ","date":"0001-01-01","objectID":"/portfolio/portfolio-2/:4:0","tags":null,"title":"YOLOv3 Inference Framework in C++","uri":"/portfolio/portfolio-2/"}]