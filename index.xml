<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>My Computational Genomic Playground</title><link>https://zqfang.github.io/</link><description>My Computational Genomic Playground</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 15 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://zqfang.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Graph: Augmentation</title><link>https://zqfang.github.io/2025-03-16-graph-augmentation/</link><pubDate>Sat, 15 Mar 2025 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2025-03-16-graph-augmentation/</guid><description>Graph Augmentations using PyG
Graph Structure Agumentation Half-Hop HalfHop adds a “slow node” to all edges with some probability p . Note that these slow nodes have averaged features from the parent nodes, and additionally are undirected.
Virtual Node VirtualNode (Gilmer 2017) appends a virtual node to the given homogeneous graph that is connected to all other nodes.</description></item><item><title>RoPE: Rotary Positional Embeddings</title><link>https://zqfang.github.io/2024-07-29-nlp-rope/</link><pubDate>Mon, 29 Jul 2024 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2024-07-29-nlp-rope/</guid><description>Rotary Positional Embeddings, proposed in 2022, this innovation is swiftly making its way into prominent language models like Google&amp;rsquo;s PaLM and Meta&amp;rsquo;s LLaMa. RoPE is a new type of positional encoding that unifies absolute and relative positional encoding approaches Rotary Positional Encoding is a type of position encoding that encodes</description></item><item><title>SwiGLU</title><link>https://zqfang.github.io/2024-07-29-nlp-swiglu/</link><pubDate>Mon, 29 Jul 2024 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2024-07-29-nlp-swiglu/</guid><description>The most commonly used activation function in LLM.
1 2 3 4 5 6 7 8 9 10 11 12 class SwiGLU(nn.Module): def __init__(self, w1, w2, w3): super.__init__() self.w1 = w1 self.w2 = w2 slef.w3 = w3 def forward(self, x): x1 = F.linear(x, self.w1.weight) x2 = F.linear(x, self.w2.weight) hidden = F.</description></item><item><title>Convert Seurat to Scanpy h5ad</title><link>https://zqfang.github.io/2020-04-28-seurat2scanpy/</link><pubDate>Tue, 21 Feb 2023 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-04-28-seurat2scanpy/</guid><description>MuDataSeurat and sceasy are recommended
MuDataSeurat Recommended!!!
MuDataSeurat directly writes h5ad file without requiring Python runtime. All dependencies exist in R and can be easily installed and used.
Install I have added some extra features. Please Install my fork which works for anndata &amp;gt;=0.8 and Seurat V5.
Refer to MuDataSeurat</description></item><item><title>Bayesian Data Analysis: Basics</title><link>https://zqfang.github.io/2022-08-10-bda1/</link><pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2022-08-10-bda1/</guid><description>The three steps of Bayesian data analysis Setting up a full probability model—a joint probability distribution for all observable and unobservable quantities in a problem.
Conditioning on observed data: calculating and interpreting the appropriate posterior distribution—the conditional probability distribution of the unobserved quantities of ultimate interest, given the observed data.</description></item><item><title>Rust: Advanced Trait</title><link>https://zqfang.github.io/2022-02-16-rust-basics/</link><pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2022-02-16-rust-basics/</guid><description><![CDATA[Some codesnape for the usage of Trait
Trait A trait defines functionality a particular type has and can share with other types.
Defined and Implement a Trait 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  pubtraitSummary{fn summarize(&amp;self)-&gt; String;}pubstruct Tweet{pubusername: String,pubcontent: String,pubreply: bool,pubretweet: bool,}implSummaryforTweet{fn summarize(&amp;self)-&gt; String {format!]]></description></item><item><title>Graph: Train, valid, and test dataset split for link prediction</title><link>https://zqfang.github.io/2021-08-12-graph-linkpredict/</link><pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-08-12-graph-linkpredict/</guid><description>Link Prediction Link prediction is a common task in knowledgegraph&amp;rsquo;s link completeion. Link prediction is usually an unsupervised or self-supervised task, which means that sometimes we need to split the dataset and create corresponding labels on our own. How to prepare train, valid, test datasets ? For link prediction, we will split edges twice</description></item><item><title>Graph: Mini-batch sampling in large-scale graphs</title><link>https://zqfang.github.io/2021-08-11-graph-minibatch/</link><pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-08-11-graph-minibatch/</guid><description>Mini-batch Sampling Real world graphs can be very large with millions or even billions of nodes and edges. But the naive full-batch implementation of GNN cannot be feasible to these large-scale graphs.
Two frequently used methods are summarized here:
Neighbor Sampling (Hamilton et al. (2017)) torch_geometric.loader.NeighborLoader Cluster-GCN (Chiang et al.</description></item><item><title>Graph: Implement a MessagePassing layer in Pytorch Geometric</title><link>https://zqfang.github.io/2021-08-07-graph-pyg/</link><pubDate>Sat, 07 Aug 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-08-07-graph-pyg/</guid><description>How to implement a custom MessagePassing layer in Pytorch Geometric (PyG) ?
Before you start, something you need to know.
special_arguments: e.g. x_j, x_i, edge_index_j, edge_index_i aggregate: scatter_add, scatter_mean, scatter_min, scatter_max PyG MessagePassing framework only works for node_graph. 1 2 3 4 5 x = ... # Node features of shape [num_nodes, num_features] edge_index = .</description></item><item><title>Graph: Concepts</title><link>https://zqfang.github.io/2021-04-19-graph-foundation/</link><pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2021-04-19-graph-foundation/</guid><description>Basics.
Definition Graph: $G(V, E)$ Adjacency Matrix: $A$ Degree: $D$, the number of nodes that are adjacent to $v$. Neighbors: $N$, the number of $N_{v(i)}$ is equal to $D_{v(i)}$. Connectivity Walk A walk on a graph is an alternating sequence of nodes and edges, starting with a node and ending with a node where each edge is incident with the nodes immediately preceding and following it.</description></item></channel></rss>