<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>My Computational Genomic Playground</title><link>https://zqfang.github.io/</link><description>My Computational Genomic Playground</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 12 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://zqfang.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Graph: GraphRNN</title><link>https://zqfang.github.io/2020-12-12-dl-graph-generation/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-dl-graph-generation/</guid><description>Why is it interesting Drug discovery discovery highly drug-like molecules complete an existing molecule to optimize a desired property Discovering novel structures Network science Why is it hard Large and variable output Non-unique representations $n$-node graph can be represented in $n!$ ways Hard to compute/optimize objective functions Complex dependencies edge fprmation has long-range dependencies Graph Generative Model Given: Graphs sampled from $p_{data}(G)$</description></item><item><title>Graph: GCN and GAT</title><link>https://zqfang.github.io/2020-12-12-ml-gcn-gat/</link><pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-ml-gcn-gat/</guid><description>Graph Convolutional Network and Graph Attention
Why deep graph encoder ? Limitations of Shallow Encoders (e.g. node2vec)
$O( | V | )$ parameters are needed: No sharing of parameters between nodes Every node has its own unique embedding Inherently &amp;ldquo;transductive&amp;rdquo;: Can not generate embeddings for nodes that are not seen during training Do not incorporate node features Many graphs have features that we can and should leverage Graph Convolutional Network Could get embedding for unseen nodes!</description></item><item><title>Graph: Semi-supervised Node Classification</title><link>https://zqfang.github.io/2020-12-12-ml-node-classififcation/</link><pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-12-ml-node-classififcation/</guid><description>Problems: Given a network with labels on some nodes, how do we assign labels to all other nodes in the network?
classification label of an object $O$ in network may depend on:
Features of $O$ Labels of the objects in $O$'s neighborhood Features of objects in $O$'s neigborhood Collective classification models Reational clasifiers Iterative classifications Loopy belief propagation Intuition Simultaneous classification of interlinked nodes using correlations</description></item><item><title>Graph: Node2Vec</title><link>https://zqfang.github.io/2020-12-06-ml-node2vec/</link><pubDate>Sun, 06 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-06-ml-node2vec/</guid><description>Node Embedings are learnt in the same way as word2vec (skip-gram model)
However, graphs could be (un)directed, (un)weighted, (a)cyclic and are basically much more complex than the strucure of a sequence&amp;hellip;
So how do we generate &amp;ldquo;corpus&amp;rdquo; from a graph ?
Random walk on the graph Given a graph and a starting point, we select a neighbor of it at random; then we select a neigbor of this point at random, and move to it, etc.</description></item><item><title>NLP: Word2Vec</title><link>https://zqfang.github.io/2020-12-05-nlp-word2vec/</link><pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-12-05-nlp-word2vec/</guid><description>Word2Vec
CBOW Continuous Bag of Words Model (CBOW)
When trainning, use N-gram language model. That&amp;rsquo;s for a target word, select $m$ (window) words before and after.
Model
one-hot encoding get $2m$ vectors: $$X = (x^{c-m}, \cdots, x^{c-1}, x^{c+1}, \cdots, x^{c+m})$$
Embeding Vector $\mathcal{V} \in R^{n \times \mathcal{V}}$,</description></item><item><title>Probabilistic Graphical Model</title><link>https://zqfang.github.io/2020-11-20-ml-pgm/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-11-20-ml-pgm/</guid><description>概率图模型（probabilistic graphical model, PGM），是一种学习任务的框架描述，它将学习任务归结为计算</description></item><item><title>Deploy IGV webapp on linux server</title><link>https://zqfang.github.io/2020-11-16-igvweb/</link><pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-11-16-igvweb/</guid><description>Config IGV on the server.
I have to share the inteactive results with my colleague. But I don&amp;rsquo;t like to install UCSC genomebrower in local. Instead, a light-weight one is what I need.
1. Installation Install nodejs if you have conda, just
1 conda install -c conda-forge nodejs build igv-webapp 1 2 3 4 git clone https://github.</description></item><item><title>Canonical Correlation Analysis (CCA)</title><link>https://zqfang.github.io/2020-08-27-ml-cca/</link><pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-08-27-ml-cca/</guid><description>典型相关分析(CCA) ，一种常用降维算法，也可以用于多个线性空间相关性计算。比如同一对象的多模态数据</description></item><item><title>Complex number for biologist</title><link>https://zqfang.github.io/2020-08-15-ml-complexnumber/</link><pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-08-15-ml-complexnumber/</guid><description>A biologist like me might have never had a numerical computing training. I don&amp;rsquo;t even known what a complex number really means. Here are some useful basics to keep in mind.
Complex number complex number $a+bi$ lives in a 2d complex plane, including
real axis: $a$ imagnary axis: $i$ orthognal to real axis $i \rightarrow 90 \degree \text{rotation}$ 2 ways of representation $z = a + bi$ $z = r \cos(\phi) + r \sin(\phi) i = r e^{i \phi}$ 3 Facts about Multiplication $z \cdot 1 = z$ $z \cdot i = \operatorname{Rot90}(z)$ e.</description></item><item><title>Deploy snakemake pipeline on HPC</title><link>https://zqfang.github.io/2020-08-19-hpc-snakemake/</link><pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate><author>Author</author><guid>https://zqfang.github.io/2020-08-19-hpc-snakemake/</guid><description>The best part of snakemake is allowed you to run your pipeline on HPC automatically. It save you a lot of time.
How to run snakemake on HPC there are two ways to configure
use --cluster: works on different HPC system, e.g. slurm, SGE. assign resource in params directive explicitly.</description></item></channel></rss>